Search.setIndex({"docnames": ["deployment/1_tensorrt_llm_deployment", "examples/0_all_examples", "getting_started/1_overview", "getting_started/2_installation", "getting_started/3_quantization", "getting_started/6_sparsity", "guides/1_quantization", "guides/5_sparsity", "guides/_basic_quantization", "guides/_choosing_quant_methods", "guides/_onnx_quantization", "guides/_pytorch_quantization", "index", "reference/0_versions", "reference/1_modelopt_api", "reference/generated/modelopt.deploy", "reference/generated/modelopt.deploy.llm", "reference/generated/modelopt.deploy.llm.generate", "reference/generated/modelopt.deploy.llm.model_config_trt", "reference/generated/modelopt.deploy.llm.nemo_utils", "reference/generated/modelopt.onnx", "reference/generated/modelopt.onnx.op_types", "reference/generated/modelopt.onnx.quantization", "reference/generated/modelopt.onnx.quantization.calib_utils", "reference/generated/modelopt.onnx.quantization.graph_utils", "reference/generated/modelopt.onnx.quantization.gs_patching", "reference/generated/modelopt.onnx.quantization.int4", "reference/generated/modelopt.onnx.quantization.operators", "reference/generated/modelopt.onnx.quantization.ort_patching", "reference/generated/modelopt.onnx.quantization.ort_utils", "reference/generated/modelopt.onnx.quantization.partitioning", "reference/generated/modelopt.onnx.quantization.qdq_utils", "reference/generated/modelopt.onnx.quantization.quant_utils", "reference/generated/modelopt.onnx.quantization.quantize", "reference/generated/modelopt.onnx.utils", "reference/generated/modelopt.torch", "reference/generated/modelopt.torch.export", "reference/generated/modelopt.torch.export.distribute", "reference/generated/modelopt.torch.export.layer_utils", "reference/generated/modelopt.torch.export.model_config", "reference/generated/modelopt.torch.export.model_config_export", "reference/generated/modelopt.torch.export.model_config_utils", "reference/generated/modelopt.torch.export.postprocess", "reference/generated/modelopt.torch.export.scaling_factor_utils", "reference/generated/modelopt.torch.export.tensorrt_llm_utils", "reference/generated/modelopt.torch.export.transformer_engine", "reference/generated/modelopt.torch.opt", "reference/generated/modelopt.torch.opt.config", "reference/generated/modelopt.torch.opt.conversion", "reference/generated/modelopt.torch.opt.dynamic", "reference/generated/modelopt.torch.opt.hparam", "reference/generated/modelopt.torch.opt.mode", "reference/generated/modelopt.torch.opt.plugins", "reference/generated/modelopt.torch.opt.searcher", "reference/generated/modelopt.torch.opt.utils", "reference/generated/modelopt.torch.quantization", "reference/generated/modelopt.torch.quantization.calib", "reference/generated/modelopt.torch.quantization.calib.calibrator", "reference/generated/modelopt.torch.quantization.calib.histogram", "reference/generated/modelopt.torch.quantization.calib.max", "reference/generated/modelopt.torch.quantization.config", "reference/generated/modelopt.torch.quantization.conversion", "reference/generated/modelopt.torch.quantization.extensions", "reference/generated/modelopt.torch.quantization.mode", "reference/generated/modelopt.torch.quantization.model_calib", "reference/generated/modelopt.torch.quantization.model_quant", "reference/generated/modelopt.torch.quantization.nn", "reference/generated/modelopt.torch.quantization.nn.functional", "reference/generated/modelopt.torch.quantization.nn.modules", "reference/generated/modelopt.torch.quantization.nn.modules.clip", "reference/generated/modelopt.torch.quantization.nn.modules.quant_activations", "reference/generated/modelopt.torch.quantization.nn.modules.quant_batchnorm", "reference/generated/modelopt.torch.quantization.nn.modules.quant_conv", "reference/generated/modelopt.torch.quantization.nn.modules.quant_instancenorm", "reference/generated/modelopt.torch.quantization.nn.modules.quant_linear", "reference/generated/modelopt.torch.quantization.nn.modules.quant_module", "reference/generated/modelopt.torch.quantization.nn.modules.quant_pooling", "reference/generated/modelopt.torch.quantization.nn.modules.tensor_quantizer", "reference/generated/modelopt.torch.quantization.optim", "reference/generated/modelopt.torch.quantization.plugins", "reference/generated/modelopt.torch.quantization.quant_modules", "reference/generated/modelopt.torch.quantization.tensor_quant", "reference/generated/modelopt.torch.quantization.utils", "reference/generated/modelopt.torch.sparsity", "reference/generated/modelopt.torch.sparsity.config", "reference/generated/modelopt.torch.sparsity.magnitude", "reference/generated/modelopt.torch.sparsity.mode", "reference/generated/modelopt.torch.sparsity.module", "reference/generated/modelopt.torch.sparsity.plugins", "reference/generated/modelopt.torch.sparsity.searcher", "reference/generated/modelopt.torch.sparsity.sparsegpt", "reference/generated/modelopt.torch.sparsity.sparsification", "reference/generated/modelopt.torch.utils", "reference/generated/modelopt.torch.utils.cpp_extension", "reference/generated/modelopt.torch.utils.dataset_utils", "reference/generated/modelopt.torch.utils.distributed", "reference/generated/modelopt.torch.utils.graph", "reference/generated/modelopt.torch.utils.list", "reference/generated/modelopt.torch.utils.logging", "reference/generated/modelopt.torch.utils.network", "reference/generated/modelopt.torch.utils.perf", "reference/generated/modelopt.torch.utils.random", "reference/generated/modelopt.torch.utils.tensor", "support/1_contact", "support/2_faqs"], "filenames": ["deployment/1_tensorrt_llm_deployment.rst", "examples/0_all_examples.rst", "getting_started/1_overview.rst", "getting_started/2_installation.rst", "getting_started/3_quantization.rst", "getting_started/6_sparsity.rst", "guides/1_quantization.rst", "guides/5_sparsity.rst", "guides/_basic_quantization.rst", "guides/_choosing_quant_methods.rst", "guides/_onnx_quantization.rst", "guides/_pytorch_quantization.rst", "index.rst", "reference/0_versions.rst", "reference/1_modelopt_api.rst", "reference/generated/modelopt.deploy.rst", "reference/generated/modelopt.deploy.llm.rst", "reference/generated/modelopt.deploy.llm.generate.rst", "reference/generated/modelopt.deploy.llm.model_config_trt.rst", "reference/generated/modelopt.deploy.llm.nemo_utils.rst", "reference/generated/modelopt.onnx.rst", "reference/generated/modelopt.onnx.op_types.rst", "reference/generated/modelopt.onnx.quantization.rst", "reference/generated/modelopt.onnx.quantization.calib_utils.rst", "reference/generated/modelopt.onnx.quantization.graph_utils.rst", "reference/generated/modelopt.onnx.quantization.gs_patching.rst", "reference/generated/modelopt.onnx.quantization.int4.rst", "reference/generated/modelopt.onnx.quantization.operators.rst", "reference/generated/modelopt.onnx.quantization.ort_patching.rst", "reference/generated/modelopt.onnx.quantization.ort_utils.rst", "reference/generated/modelopt.onnx.quantization.partitioning.rst", "reference/generated/modelopt.onnx.quantization.qdq_utils.rst", "reference/generated/modelopt.onnx.quantization.quant_utils.rst", "reference/generated/modelopt.onnx.quantization.quantize.rst", "reference/generated/modelopt.onnx.utils.rst", "reference/generated/modelopt.torch.rst", "reference/generated/modelopt.torch.export.rst", "reference/generated/modelopt.torch.export.distribute.rst", "reference/generated/modelopt.torch.export.layer_utils.rst", "reference/generated/modelopt.torch.export.model_config.rst", "reference/generated/modelopt.torch.export.model_config_export.rst", "reference/generated/modelopt.torch.export.model_config_utils.rst", "reference/generated/modelopt.torch.export.postprocess.rst", "reference/generated/modelopt.torch.export.scaling_factor_utils.rst", "reference/generated/modelopt.torch.export.tensorrt_llm_utils.rst", "reference/generated/modelopt.torch.export.transformer_engine.rst", "reference/generated/modelopt.torch.opt.rst", "reference/generated/modelopt.torch.opt.config.rst", "reference/generated/modelopt.torch.opt.conversion.rst", "reference/generated/modelopt.torch.opt.dynamic.rst", "reference/generated/modelopt.torch.opt.hparam.rst", "reference/generated/modelopt.torch.opt.mode.rst", "reference/generated/modelopt.torch.opt.plugins.rst", "reference/generated/modelopt.torch.opt.searcher.rst", "reference/generated/modelopt.torch.opt.utils.rst", "reference/generated/modelopt.torch.quantization.rst", "reference/generated/modelopt.torch.quantization.calib.rst", "reference/generated/modelopt.torch.quantization.calib.calibrator.rst", "reference/generated/modelopt.torch.quantization.calib.histogram.rst", "reference/generated/modelopt.torch.quantization.calib.max.rst", "reference/generated/modelopt.torch.quantization.config.rst", "reference/generated/modelopt.torch.quantization.conversion.rst", "reference/generated/modelopt.torch.quantization.extensions.rst", "reference/generated/modelopt.torch.quantization.mode.rst", "reference/generated/modelopt.torch.quantization.model_calib.rst", "reference/generated/modelopt.torch.quantization.model_quant.rst", "reference/generated/modelopt.torch.quantization.nn.rst", "reference/generated/modelopt.torch.quantization.nn.functional.rst", "reference/generated/modelopt.torch.quantization.nn.modules.rst", "reference/generated/modelopt.torch.quantization.nn.modules.clip.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_activations.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_batchnorm.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_conv.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_instancenorm.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_linear.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_module.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_pooling.rst", "reference/generated/modelopt.torch.quantization.nn.modules.tensor_quantizer.rst", "reference/generated/modelopt.torch.quantization.optim.rst", "reference/generated/modelopt.torch.quantization.plugins.rst", "reference/generated/modelopt.torch.quantization.quant_modules.rst", "reference/generated/modelopt.torch.quantization.tensor_quant.rst", "reference/generated/modelopt.torch.quantization.utils.rst", "reference/generated/modelopt.torch.sparsity.rst", "reference/generated/modelopt.torch.sparsity.config.rst", "reference/generated/modelopt.torch.sparsity.magnitude.rst", "reference/generated/modelopt.torch.sparsity.mode.rst", "reference/generated/modelopt.torch.sparsity.module.rst", "reference/generated/modelopt.torch.sparsity.plugins.rst", "reference/generated/modelopt.torch.sparsity.searcher.rst", "reference/generated/modelopt.torch.sparsity.sparsegpt.rst", "reference/generated/modelopt.torch.sparsity.sparsification.rst", "reference/generated/modelopt.torch.utils.rst", "reference/generated/modelopt.torch.utils.cpp_extension.rst", "reference/generated/modelopt.torch.utils.dataset_utils.rst", "reference/generated/modelopt.torch.utils.distributed.rst", "reference/generated/modelopt.torch.utils.graph.rst", "reference/generated/modelopt.torch.utils.list.rst", "reference/generated/modelopt.torch.utils.logging.rst", "reference/generated/modelopt.torch.utils.network.rst", "reference/generated/modelopt.torch.utils.perf.rst", "reference/generated/modelopt.torch.utils.random.rst", "reference/generated/modelopt.torch.utils.tensor.rst", "support/1_contact.rst", "support/2_faqs.rst"], "titles": ["TensorRT-LLM Deployment", "All ModelOpt Examples", "Overview", "Installation", "Quick Start: Quantization", "Quick Start: Sparsity", "Quantization", "Sparsity", "Basic Concepts", "Best practices to choose the right quantization methods", "ONNX Quantization (Beta)", "PyTorch Quantization", "Welcome to Model Optimizer (ModelOpt) documentation!", "Model Optimizer Changelog", "modelopt API", "deploy", "llm", "generate", "model_config_trt", "nemo_utils", "onnx", "op_types", "quantization", "calib_utils", "graph_utils", "gs_patching", "int4", "operators", "ort_patching", "ort_utils", "partitioning", "qdq_utils", "quant_utils", "quantize", "utils", "torch", "export", "distribute", "layer_utils", "model_config", "model_config_export", "model_config_utils", "postprocess", "scaling_factor_utils", "tensorrt_llm_utils", "transformer_engine", "opt", "config", "conversion", "dynamic", "hparam", "mode", "plugins", "searcher", "utils", "quantization", "calib", "calibrator", "histogram", "max", "config", "conversion", "extensions", "mode", "model_calib", "model_quant", "nn", "functional", "modules", "clip", "quant_activations", "quant_batchnorm", "quant_conv", "quant_instancenorm", "quant_linear", "quant_module", "quant_pooling", "tensor_quantizer", "optim", "plugins", "quant_modules", "tensor_quant", "utils", "sparsity", "config", "magnitude", "mode", "module", "plugins", "searcher", "sparsegpt", "sparsification", "utils", "cpp_extension", "dataset_utils", "distributed", "graph", "list", "logging", "network", "perf", "random", "tensor", "Contact us", "FAQs"], "terms": {"pleas": [0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 17, 46, 48, 60, 65, 79, 91, 104], "read": [0, 37, 81], "workflow": [0, 2, 51, 53], "first": [0, 3, 7, 9, 11, 26, 34, 37, 93, 99], "befor": [0, 3, 8, 49, 53, 63, 75, 77, 101], "go": [0, 77], "through": [0, 5, 8, 11, 64, 65, 81], "thi": [0, 3, 5, 7, 9, 10, 11, 13, 18, 19, 21, 24, 26, 27, 28, 30, 32, 33, 34, 37, 38, 39, 41, 42, 44, 47, 48, 49, 50, 53, 58, 60, 61, 63, 64, 65, 67, 77, 79, 80, 81, 82, 85, 86, 87, 91, 94, 99, 101, 104], "section": [0, 7], "modelopt": [0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 16, 18, 21, 24, 29, 39, 46, 47, 48, 51, 56, 60, 61, 72, 74, 75, 77, 94, 101, 104], "toolkit": [0, 6], "automat": [0, 7, 11, 16, 49, 85, 91], "convers": [0, 9, 16, 21, 33, 49, 101], "engin": [0, 10, 16, 17, 18, 39, 40], "acceler": [0, 2, 4, 5, 7, 16], "inferenc": [0, 16], "i": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 16, 17, 18, 19, 21, 24, 26, 27, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 44, 47, 48, 49, 50, 51, 53, 54, 58, 59, 60, 61, 63, 64, 65, 67, 75, 77, 80, 81, 82, 84, 85, 86, 87, 91, 95, 99, 101, 104], "achiev": [0, 6, 7, 11, 49], "huggingfac": [0, 3, 4, 11, 17, 19, 36, 39, 79], "nemo": [0, 2, 4, 11, 19, 36, 39, 79], "build": [0, 10, 16, 18, 19, 24, 38, 39, 40, 81, 91], "from": [0, 2, 4, 7, 8, 9, 11, 13, 16, 17, 18, 19, 21, 23, 24, 28, 30, 31, 33, 34, 38, 39, 41, 43, 46, 47, 48, 49, 50, 53, 58, 60, 61, 77, 81, 85, 90, 91, 94, 97, 99, 101, 102], "after": [0, 7, 8, 10, 11, 13, 21, 37, 46, 48, 49, 51, 53, 64, 91], "can": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 18, 21, 24, 32, 39, 40, 46, 47, 48, 49, 51, 53, 60, 63, 79, 81, 84, 86, 94, 99, 100, 101], "format": [0, 2, 4, 6, 7, 9, 10, 11, 13, 37, 39, 40, 41, 53, 77, 94, 99], "store": [0, 7, 33, 40, 48, 49, 50, 53, 81], "A": [0, 7, 8, 9, 11, 17, 30, 31, 37, 40, 41, 47, 48, 49, 50, 51, 53, 58, 59, 61, 64, 65, 69, 77, 81, 82, 89, 91, 94, 99, 100], "singl": [0, 8, 10, 16, 18, 24, 32, 41, 42, 43, 50, 51, 77, 99], "json": [0, 37, 40, 41, 47, 60, 84], "file": [0, 10, 13, 18, 26, 32, 33, 34, 37, 38, 40, 44, 47, 48, 93], "record": [0, 48, 51], "structur": 0, "metadata": [0, 7, 48, 86], "config": [0, 4, 5, 7, 17, 19, 37, 38, 39, 40, 41, 42, 44, 48, 49, 53, 63, 65, 86, 89, 90, 91, 101], "group": [0, 9, 13, 37, 43, 77, 95], "safetensor": [0, 40], "each": [0, 7, 8, 11, 13, 18, 26, 37, 40, 43, 46, 48, 49, 50, 51, 60, 61, 82, 84, 91, 101], "local": [0, 37], "calibr": [0, 4, 5, 7, 9, 11, 13, 23, 26, 33, 40, 56, 58, 59, 60, 64, 65, 77, 81, 91, 94], "gpu": [0, 2, 7, 9, 18, 40, 58, 100, 101], "rank": [0, 18, 37, 39, 40, 42, 43, 77, 81, 82, 95, 100], "weight": [0, 2, 5, 7, 8, 9, 11, 18, 19, 26, 31, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 48, 49, 58, 60, 61, 64, 65, 75, 81, 82, 85, 87, 91], "scale": [0, 10, 18, 26, 31, 38, 39, 40, 41, 43, 64, 77, 81], "factor": [0, 9, 18, 26, 31, 38, 39, 40, 41, 43, 64, 81], "per": [0, 8, 9, 32, 40, 81, 91], "The": [0, 2, 4, 7, 8, 9, 10, 11, 13, 16, 17, 18, 19, 26, 31, 32, 33, 37, 39, 40, 41, 42, 47, 48, 49, 53, 60, 61, 63, 64, 65, 67, 77, 81, 82, 85, 86, 91, 94, 96, 99, 101], "api": [0, 2, 3, 4, 5, 7, 10, 11, 12, 13, 16, 17, 18, 19, 40, 64, 65, 80, 83, 91], "export_tensorrt_llm_checkpoint": [0, 18, 40], "us": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 16, 18, 21, 24, 26, 32, 33, 37, 40, 43, 46, 47, 48, 49, 53, 58, 59, 60, 63, 64, 65, 67, 69, 77, 80, 81, 84, 85, 87, 91, 93, 94, 95, 99, 100, 101, 104], "follow": [0, 3, 7, 8, 9, 10, 11, 13, 24, 33, 48, 53, 60, 63, 81, 91], "torch": [0, 2, 3, 4, 5, 7, 11, 13, 18, 29, 37, 38, 40, 41, 46, 48, 49, 53, 56, 58, 60, 61, 72, 74, 75, 77, 81, 93, 94, 95, 99, 101, 102], "import": [0, 3, 4, 5, 7, 8, 10, 11, 16, 47, 48, 50, 60, 61, 94, 101], "inference_mod": 0, "decoder_typ": [0, 38, 39, 40], "type": [0, 7, 10, 17, 19, 21, 24, 26, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 53, 54, 58, 61, 63, 64, 65, 75, 77, 81, 85, 86, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "str": [0, 17, 18, 19, 21, 23, 24, 26, 29, 30, 31, 33, 34, 37, 38, 39, 40, 41, 42, 44, 47, 48, 49, 53, 54, 58, 60, 61, 63, 64, 65, 77, 84, 85, 86, 89, 90, 91, 93, 94, 95, 97, 98, 99], "e": [0, 5, 7, 8, 9, 11, 13, 26, 40, 49, 51, 53, 81, 93, 99], "g": [0, 5, 7, 8, 11, 13, 40, 49, 51, 81, 93, 99], "gptj": [0, 40], "llama": [0, 40], "gptnext": [0, 40], "dtype": [0, 25, 31, 38, 39, 40, 81, 99], "data": [0, 4, 5, 7, 9, 10, 11, 13, 23, 32, 33, 34, 40, 56, 58, 64, 65, 91, 94, 95, 99, 102], "unquant": [0, 8, 40], "layer": [0, 7, 11, 24, 30, 37, 38, 39, 40, 50, 60, 84, 91, 99], "export_dir": [0, 40, 44], "directori": [0, 10, 17, 18, 33, 34, 37, 40], "where": [0, 7, 8, 11, 26, 53, 75, 81, 99], "inference_tensor_parallel": [0, 13, 40, 42], "number": [0, 18, 26, 43, 49, 50, 58, 59, 65, 69, 81, 94, 95, 98, 99, 101], "infer": [0, 2, 4, 5, 7, 9, 16, 29, 39, 40, 42, 48, 53, 94], "time": [0, 3, 9, 13, 16, 18, 40, 91, 93, 97], "tensor": [0, 7, 8, 9, 11, 13, 18, 23, 24, 26, 31, 34, 37, 38, 39, 40, 41, 42, 43, 49, 50, 58, 59, 60, 67, 69, 77, 81, 82, 85, 90, 95, 99], "parallel": [0, 7, 13, 37, 40, 42, 82, 95, 99], "inference_pipeline_parallel": [0, 40, 42], "pipelin": [0, 7, 11, 40, 65], "If": [0, 3, 7, 9, 10, 18, 23, 33, 37, 38, 39, 42, 43, 48, 49, 50, 58, 59, 61, 64, 69, 77, 81, 82, 84, 91, 99], "call": [0, 3, 7, 11, 16, 21, 32, 47, 49, 61, 75, 87, 91, 94], "success": [0, 3], "save": [0, 6, 10, 11, 18, 33, 34, 37, 39, 40, 46, 48, 53, 59, 63, 77, 81], "otherwis": [0, 33, 37, 38, 61, 81, 96], "state_dict": [0, 7, 11, 37, 48, 53], "instead": [0, 13, 32, 37, 49, 50, 51, 58, 80, 81, 84], "fp16": [0, 9, 10], "bf16": [0, 9], "fp8": [0, 2, 8, 9, 11, 13, 33, 38, 39, 40, 60, 81], "int8_sq": [0, 39], "int4_awq": 0, "gpt2": [0, 40], "ye": 0, "No": 0, "2": [0, 2, 5, 7, 13, 23, 24, 26, 32, 65, 81, 85], "3": [0, 3, 38, 60, 65, 81], "mistral": 0, "mixtral": 0, "8x7b": 0, "falcon": 0, "40b": 0, "180b": 0, "7b": 0, "rw": 0, "1b": 0, "mpt": 0, "30b": 0, "baichuan": 0, "1": [0, 3, 10, 11, 13, 17, 18, 23, 26, 38, 39, 40, 41, 42, 58, 60, 65, 81, 82, 94, 97, 99, 101], "qwen": 0, "14b": 0, "chatglm2": 0, "6b": [0, 7], "bloom": 0, "phi": [0, 44], "nemotron": 0, "8": [0, 2, 3, 9, 10, 11, 26, 38, 44, 58, 59, 60, 61, 81, 93, 99], "gemma": 0, "2b": 0, "onc": [0, 16, 21, 58], "avail": [0, 2, 3, 4, 8, 13, 23, 33, 50, 91], "deploi": [0, 3, 9, 13, 16], "visit": [1, 2], "tensorrt": [1, 4, 6, 9, 10, 11, 12, 13, 16, 17, 18, 24, 39, 40, 44], "model": [1, 6, 8, 9, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 30, 33, 34, 35, 37, 38, 39, 40, 42, 45, 46, 48, 49, 51, 53, 54, 58, 60, 61, 63, 64, 65, 77, 80, 86, 91, 94, 99, 101, 104], "optim": [1, 4, 6, 7, 11, 15, 16, 20, 22, 32, 33, 35, 40, 45, 46, 48, 51, 53, 54, 60, 91], "github": [1, 4, 5, 6, 17, 18, 19, 21, 40, 81, 99, 103], "repositori": [1, 2, 6], "minim": [2, 8, 13, 53], "cost": [2, 8], "present": [2, 16, 34], "signific": 2, "challeng": 2, "gener": [2, 8, 10, 16, 18, 21, 33, 34, 39, 41, 46, 47, 48, 49, 50, 54, 60, 85, 89, 101], "ai": 2, "continu": [2, 7, 91], "grow": 2, "complex": 2, "size": [2, 8, 9, 18, 32, 34, 37, 38, 39, 43, 49, 54, 77, 81, 85, 94, 95, 99], "refer": [2, 4, 6, 7, 10, 11, 13, 17, 19, 21, 24, 46, 50, 77, 91, 99], "librari": 2, "compris": [2, 9], "state": [2, 11, 37, 48, 51, 53, 63, 75, 77, 89, 99], "art": 2, "includ": [2, 3, 8, 13, 17, 39, 49, 81], "compress": [2, 7, 9], "It": [2, 11, 37, 51, 63, 65, 77, 81, 85, 91, 99], "accept": [2, 13, 81], "onnx": [2, 3, 4, 6, 9, 11, 13, 21, 22, 23, 24, 26, 30, 31, 32, 33, 34, 53, 80, 81, 99], "input": [2, 4, 5, 7, 10, 11, 13, 17, 18, 23, 24, 27, 30, 31, 32, 33, 34, 49, 58, 60, 61, 65, 67, 69, 73, 75, 77, 81, 82, 91, 94, 99, 102], "provid": [2, 5, 7, 8, 10, 11, 18, 23, 24, 29, 32, 33, 37, 43, 46, 47, 48, 49, 53, 56, 84, 91, 99], "python": [2, 3, 10, 16, 21, 41, 101], "user": [2, 4, 7, 9, 10, 11, 13, 21, 33, 37, 46, 48, 49, 50, 65, 81], "easili": 2, "stack": [2, 6, 63], "differ": [2, 6, 8, 9, 21, 33, 49, 91, 94], "produc": [2, 24, 34], "checkpoint": [2, 7, 18, 39, 40, 44, 46, 48, 53, 77], "seamlessli": 2, "integr": 2, "within": [2, 10, 51, 81, 82, 98], "softwar": [2, 6], "ecosystem": 2, "readi": [2, 4], "deploy": [2, 6, 9, 11, 15, 16, 35, 40], "downstream": 2, "framework": [2, 6, 11], "like": [2, 4, 6, 7, 8, 10, 11, 13, 23, 30, 33, 48, 49, 53, 59, 99], "llm": [2, 4, 6, 9, 11, 12, 17, 18, 36, 39, 40, 44, 60], "further": 2, "ar": [2, 3, 7, 8, 9, 11, 13, 18, 19, 24, 26, 30, 33, 34, 38, 39, 40, 41, 42, 44, 47, 48, 49, 53, 60, 61, 64, 65, 75, 77, 81, 82, 84, 91, 93, 99], "plan": 2, "megatron": [2, 79, 88], "lm": 2, "train": [2, 4, 13, 42, 77, 91, 104], "loop": [2, 4, 5, 11, 32, 53, 91, 94], "For": [2, 3, 7, 8, 9, 10, 11, 16, 17, 18, 40, 42, 47, 48, 49, 50, 51, 60, 81, 84, 99], "enterpris": 2, "bit": [2, 8, 9, 11, 32, 58, 59, 81], "stabl": 2, "diffus": [2, 79], "also": [2, 4, 7, 11, 41, 49, 51, 58, 60, 67, 99, 101], "nim": 2, "free": 2, "all": [2, 3, 7, 12, 13, 28, 30, 31, 33, 34, 37, 39, 40, 42, 47, 48, 49, 54, 58, 59, 65, 77, 81, 82, 84, 85, 87, 95, 99, 101], "develop": 2, "pypi": [2, 3], "end": [2, 4, 5, 24, 60, 65, 99, 100], "exampl": [2, 3, 4, 5, 6, 7, 8, 10, 11, 16, 17, 19, 33, 47, 48, 50, 51, 60, 61, 64, 65, 79, 81, 84, 94, 101], "script": [2, 19], "recip": 2, "an": [2, 4, 5, 7, 8, 10, 11, 13, 16, 24, 26, 29, 32, 33, 34, 37, 38, 40, 42, 48, 49, 50, 51, 58, 59, 61, 63, 64, 65, 67, 77, 81, 84, 86, 91, 99, 101, 103], "effect": [2, 4, 5, 8, 11, 81], "larg": [2, 9, 32], "2x": [2, 7], "4x": 2, "speed": [2, 4, 5, 7], "up": [2, 3, 4, 7, 9, 37, 46, 49, 53, 77, 91], "while": [2, 8, 11, 13, 49, 53, 80], "preserv": [2, 8, 48], "qualiti": [2, 11], "enabl": [2, 4, 7, 11, 18, 50, 60, 61, 65, 77, 82, 93], "highli": [2, 7, 11], "perform": [2, 4, 5, 9, 11, 17, 26, 33, 37, 41, 58, 60, 64, 65, 77, 81, 100], "int8": [2, 4, 9, 10, 33, 38, 60], "int4": [2, 9, 11, 33, 60], "etc": [2, 4, 10, 11, 24, 26, 33], "support": [2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 16, 19, 25, 26, 31, 33, 36, 38, 39, 48, 49, 53, 58, 60, 61, 63, 64, 66, 67, 68, 79, 80, 81, 82, 88, 91, 99], "advanc": [2, 4, 5, 8], "algorithm": [2, 4, 9, 10, 11, 13, 26, 46, 47, 48, 51, 53, 60, 64, 65, 83, 86, 89, 90, 91], "smoothquant": [2, 4, 8, 9, 11, 60, 64, 77], "awq": [2, 4, 8, 9, 11, 26, 39, 42, 60], "doubl": [2, 81], "easi": [2, 5, 7, 10, 16], "both": [2, 4, 7, 8, 9, 10, 13, 26, 49, 75], "post": [2, 4, 8, 13, 53], "ptq": [2, 5, 8, 13, 24, 33], "awar": [2, 4, 13, 26], "qat": [2, 4, 5, 13], "page": 2, "list": [2, 3, 8, 11, 17, 21, 24, 30, 33, 34, 37, 38, 39, 40, 42, 43, 48, 59, 60, 61, 77, 81, 91, 93, 102], "reduc": [2, 4, 5, 7, 8, 65, 82, 91, 101], "memori": [2, 4, 5, 6, 7, 9, 11, 18, 34, 40, 42, 99, 100], "footprint": [2, 4, 5, 7, 18], "deep": [2, 4, 5, 8], "learn": [2, 4, 5, 8, 11, 46, 60, 69, 77, 81, 82], "mt": [2, 5, 7], "sparsifi": [2, 5, 7, 13, 18, 91], "appli": [2, 5, 7, 9, 26, 48, 73, 77, 81, 85, 94], "given": [2, 5, 21, 24, 31, 33, 34, 43, 47, 49, 53, 60, 61, 65, 77, 82, 85, 90, 91, 94, 99, 101], "4": [2, 5, 7, 8, 9, 23, 32, 38, 60, 81, 85], "pattern": [2, 5, 7, 24, 30, 33, 84, 85, 91, 96], "variou": [2, 5, 31, 46, 48, 61, 91], "sparsif": [2, 13, 83, 86], "method": [2, 5, 6, 7, 11, 19, 24, 32, 33, 37, 47, 48, 49, 53, 58, 60, 61, 64, 65, 75, 77, 81, 99], "asp": [2, 5, 7, 85], "sparsegpt": [2, 5, 7, 86, 91], "fine": [2, 7, 8, 11, 53, 91], "tune": [2, 7, 8, 11, 18, 53, 91], "latter": 2, "recommend": [2, 3, 9, 11, 60, 81, 91], "accuraci": [2, 6, 7, 8, 9, 33], "degrad": [2, 9, 11], "nvidia": [3, 5, 6, 7, 11, 13, 17, 18, 19, 40, 81, 85], "current": [3, 6, 7, 10, 13, 26, 47, 48, 49, 50, 79, 86, 88, 91, 93, 95], "ha": [3, 9, 11, 18, 23, 24, 34, 37, 48, 49, 50, 53, 65, 69, 82], "o": 3, "linux": 3, "window": [3, 13, 21], "architectur": [3, 7, 40, 48, 49, 101], "x86_64": 3, "aarch64": 3, "win_amd64": [3, 13], "12": [3, 93], "pytorch": [3, 6, 7, 9, 46, 49, 61, 64, 65, 67, 69, 81, 82, 94, 99, 102], "11": [3, 93], "cuda": [3, 62, 81, 93, 100], "its": [3, 7, 44, 48, 49, 53, 60, 61, 65, 77, 81, 91, 99], "depend": [3, 13, 24, 49, 50], "via": [3, 7, 9, 26, 48, 49, 53, 63, 86, 87, 99, 101], "pip": [3, 13], "review": 3, "licens": 3, "term": [3, 7], "ani": [3, 13, 18, 24, 33, 37, 40, 41, 44, 47, 48, 49, 50, 53, 60, 63, 65, 77, 82, 84, 86, 87, 89, 90, 91, 93, 96, 97, 99, 101, 103], "quick": [3, 12, 81], "detail": [3, 4, 6, 8, 9, 10, 11, 18, 33, 53, 61, 65, 77, 81, 84, 91], "instruct": 3, "set": [3, 4, 7, 11, 13, 17, 18, 21, 25, 30, 31, 37, 38, 40, 44, 46, 47, 48, 49, 50, 53, 58, 61, 63, 77, 86, 87, 91, 95, 99], "virtual": 3, "environ": 3, "we": [3, 4, 7, 8, 9, 11, 24, 26, 38, 39, 40, 42, 47, 48, 49, 50, 51, 53, 58, 63, 77, 79, 81, 87, 88, 91, 99, 101], "you": [3, 6, 7, 9, 10, 11, 13, 18, 47, 48, 60, 79, 80, 84, 91, 99, 103], "don": [3, 53, 63, 81], "t": [3, 30, 53, 58, 63, 67, 81, 82, 101], "have": [3, 7, 8, 9, 11, 23, 37, 47, 49, 60, 61, 65, 81, 99, 103], "one": [3, 8, 38, 39, 42, 48, 49, 58, 61, 79, 81, 82, 85], "alreadi": [3, 30, 48], "run": [3, 10, 11, 16, 19, 53, 58, 65, 77, 91, 99], "command": [3, 10], "activ": [3, 8, 9, 26, 38, 39, 49, 50, 60, 65, 70, 81, 87, 99], "conda": 3, "name": [3, 10, 13, 24, 30, 31, 33, 34, 47, 49, 53, 54, 60, 61, 63, 65, 81, 82, 84, 86, 93, 94, 99, 100], "creat": [3, 7, 10, 11, 24, 29, 31, 37, 40, 48, 58, 60, 77, 85, 90, 94], "n": [3, 85], "option": [3, 7, 13, 24, 30, 33, 38, 43, 48, 49, 50, 53, 91, 101], "desir": [3, 4, 31, 48, 91], "version": [3, 11, 21, 32, 39, 44, 49, 74, 76, 81, 82, 93], "By": [3, 10, 13, 27, 81], "default": [3, 10, 11, 13, 21, 27, 33, 38, 40, 47, 49, 50, 53, 58, 60, 69, 77, 81, 82, 84, 85, 89, 90, 91, 99, 101], "latest": 3, "want": [3, 7, 11, 37, 48, 49, 53, 60, 63, 77, 81, 84, 91, 101], "specif": [3, 7, 9, 24, 49, 51, 60, 81, 84, 94], "your": [3, 7, 9, 11, 13, 60, 79, 91], "extra": [3, 13, 19, 77, 99], "index": [3, 77], "url": 3, "http": [3, 17, 18, 19, 21, 40, 67, 81, 99], "download": [3, 10], "org": [3, 67], "whl": 3, "cu118": 3, "identifi": [3, 30], "correct": [3, 61, 65, 75], "partial": [3, 24], "note": [3, 11, 19, 21, 24, 27, 30, 34, 37, 48, 49, 50, 63, 84, 87], "when": [3, 7, 9, 18, 24, 33, 37, 47, 48, 49, 50, 58, 77, 81, 87, 94, 104], "without": [3, 7, 33, 40, 49, 99], "onli": [3, 5, 7, 8, 9, 10, 11, 13, 18, 21, 24, 26, 27, 30, 31, 33, 36, 39, 41, 44, 47, 49, 58, 60, 67, 69, 81, 87, 98, 99], "barebon": 3, "none": [3, 18, 19, 24, 26, 33, 34, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 54, 58, 59, 60, 63, 64, 65, 77, 81, 82, 84, 86, 87, 89, 91, 93, 94, 95, 99, 100, 101], "modul": [3, 7, 13, 15, 16, 19, 20, 22, 25, 26, 27, 28, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 86, 88, 91, 92, 93, 94, 96, 99], "work": [3, 8, 10, 24, 37, 79], "appropri": [3, 4, 5, 50], "below": [3, 4, 6, 7, 8, 9, 10, 11, 49, 60, 65, 99], "need": [3, 8, 11, 13, 37, 38, 39, 44, 48, 49, 50, 60, 65, 80, 81, 99], "correctli": [3, 7, 11, 47, 77, 79], "correspond": [3, 48, 49, 50, 60, 63, 86, 99, 101], "_deploi": [3, 13], "addition": [3, 24, 48], "3rd": 3, "parti": [3, 52, 79, 88], "plugin": 3, "third": [3, 52, 79, 88], "packag": [3, 13, 15, 16, 36, 55, 82], "transform": [3, 7, 10, 38, 39, 41], "hf": [3, 13, 19], "cach": [3, 9, 11, 17, 18, 100], "dir": [3, 19, 37], "com": [3, 17, 18, 19, 21, 40, 81, 99], "": [3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 21, 26, 37, 47, 48, 49, 51, 59, 63, 67, 81, 86, 91, 94, 97, 99], "quantiz": [3, 12, 13, 16, 21, 24, 26, 27, 30, 31, 32, 38, 39, 40, 41, 42, 43, 45, 51, 56, 58, 59, 61, 63, 64, 65, 66, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 94], "compil": [3, 10, 18, 30, 33, 93], "fast": [3, 65], "kernel": [3, 9, 18, 30, 33, 99], "mai": [3, 7, 8, 11, 48, 49, 81, 91, 93, 103], "take": [3, 7, 11, 47, 50, 58, 61, 64, 65, 77, 81, 91, 93, 99], "few": [3, 65, 93], "minut": [3, 9], "subsequ": [3, 7, 53, 93], "much": [3, 11], "faster": [3, 50], "To": [3, 6, 7, 11, 13, 84], "invok": [3, 98], "now": [3, 13, 30, 63], "c": [3, 62, 93], "extens": [3, 19, 81, 93], "ext": 3, "print": [3, 11, 16, 24, 33, 65, 91, 98], "cuda_ext": 3, "cuda_ext_fp8": 3, "techniqu": [4, 5, 7, 8, 11, 13], "mtq": [4, 11, 60, 61, 80, 94], "case": [4, 5, 7, 9, 10, 11, 42, 49, 60], "requir": [4, 5, 7, 9, 11, 13, 39, 63, 65, 77, 93], "configur": [4, 5, 7, 11, 47, 49, 50, 51, 53, 54, 60, 65, 84, 91, 94, 101], "forward": [4, 5, 8, 11, 24, 44, 53, 61, 64, 65, 67, 69, 75, 77, 81, 90, 91, 94, 99], "here": [4, 5, 11, 30, 32, 49, 50, 60, 61, 65, 99], "setup": [4, 5, 11, 61], "get_model": [4, 5, 11], "show": [4, 11, 47, 60, 84], "rough": 4, "how": [4, 9, 19, 46, 50, 79, 81, 99], "loader": [4, 5, 11, 65, 91, 99], "calib_s": [4, 5, 11], "data_load": [4, 5, 7, 11, 65, 91, 99], "get_dataload": [4, 11], "num_sampl": [4, 5, 11, 94], "defin": [4, 5, 7, 8, 11, 30, 39, 46, 51, 53, 61, 67, 81, 86, 101], "forward_loop": [4, 5, 11, 53, 60, 64, 65, 91, 94], "function": [4, 11, 18, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 53, 54, 58, 60, 61, 64, 65, 69, 77, 78, 80, 81, 82, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "should": [4, 10, 11, 13, 18, 21, 23, 24, 30, 32, 33, 39, 47, 48, 49, 50, 61, 64, 65, 81, 91], "wrap": [4, 11, 47, 48, 99], "insid": [4, 91], "def": [4, 11, 61, 65], "batch": [4, 9, 11, 16, 17, 18, 26, 34, 49, 65, 71, 91, 94, 99], "int8_smoothquant_cfg": [4, 11, 60], "just": [4, 39, 63, 99], "regular": [4, 7, 8, 11, 33, 46, 49, 50, 86, 91], "evalu": [4, 19, 53, 65], "export": [4, 6, 7, 11, 13, 16, 18, 38, 40, 42, 44, 46, 49, 51, 53, 63, 77, 80, 82, 86, 91, 99], "see": [4, 9, 10, 11, 19, 49, 58, 59, 60, 61, 65, 81, 91, 99], "guid": [4, 5, 11], "more": [4, 5, 6, 7, 9, 11, 18, 46, 47, 49, 60, 61, 65, 67, 77, 81, 91, 99], "next": [4, 5, 23, 24, 86], "step": [4, 5, 7, 10, 48, 51, 53, 60, 77], "about": [4, 5, 7, 46, 60, 77], "usag": [4, 5, 7, 11, 18, 47, 94, 100], "checkout": [4, 5], "out": [4, 5, 7, 32, 79], "featur": [5, 7, 13, 18, 50, 53, 77], "get_train_dataload": 5, "sparsity_config": [5, 7], "collect_func": [5, 7, 91, 99], "lambda": [5, 7], "x": [5, 7, 11, 26, 58, 59, 85, 97, 99], "mode": [5, 13, 33, 47, 48, 53, 60, 81, 82, 84, 91], "driven": [5, 7], "sparse_magnitud": [5, 7, 84, 91], "doe": [5, 7, 9, 27, 33, 48, 49, 50, 63, 65], "pure": [5, 47], "base": [5, 6, 7, 9, 11, 17, 19, 23, 26, 27, 33, 37, 39, 47, 48, 49, 50, 53, 57, 58, 59, 60, 61, 63, 64, 67, 69, 72, 73, 74, 75, 76, 77, 81, 84, 85, 86, 87, 89, 90, 98, 99, 100], "substitut": 5, "iter": [5, 17, 23, 40, 48, 49, 65, 77, 91, 94, 99], "dataset": [5, 65, 94], "hardwar": [6, 7], "simul": [6, 11], "origin": [6, 7, 8, 9, 10, 11, 33, 41, 48, 49, 50, 61, 75, 99, 101], "precis": [6, 9, 10, 11, 33], "test": [6, 16], "best": [6, 10, 17, 53, 85], "trade": 6, "off": 6, "between": [6, 18, 58], "low": [6, 8, 9, 11, 33], "actual": [6, 9, 48, 49, 50, 53, 99], "speedup": [6, 10, 11], "find": [6, 7, 11, 26, 30, 34, 85], "document": [6, 60, 91], "basic": [6, 7, 23, 29, 32, 49, 53, 81], "concept": [6, 46], "practic": [6, 17], "choos": [6, 60, 91, 101], "right": [6, 60, 63], "beta": 6, "describ": [7, 11, 48, 49, 60, 63, 65, 81, 86, 91], "obtain": 7, "either": [7, 18, 21, 33, 49, 99], "exist": [7, 37, 38, 48, 49], "load": [7, 9, 10, 16, 18, 19, 34, 37, 41, 42, 48, 53, 62, 77, 93, 94], "pre": [7, 11, 30, 43, 53], "re": [7, 49], "mto": [7, 11, 48], "relat": [7, 24, 30, 34], "process": [7, 8, 10, 18, 33, 37, 40, 42, 48, 49, 53, 84, 91, 94, 95, 98, 99, 101], "convert": [7, 11, 13, 16, 18, 32, 33, 38, 39, 40, 41, 44, 45, 48, 49, 53, 63, 84, 86, 91, 98, 99, 101, 102, 104], "dens": [7, 39], "retrain": 7, "simplest": [7, 8, 11], "wai": [7, 8, 11, 49, 99], "return": [7, 11, 17, 19, 21, 23, 24, 26, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 53, 54, 58, 59, 61, 63, 64, 65, 77, 81, 82, 85, 86, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "dictionari": [7, 10, 11, 23, 24, 26, 34, 47, 48, 49, 53, 60, 61, 64, 65, 81, 84, 91, 99], "specifi": [7, 11, 18, 34, 48, 49, 51, 58, 60, 61, 63, 64, 65, 81, 82, 84, 85, 86, 91, 93, 94, 100, 102], "dataload": [7, 11, 94], "magnitud": [7, 86, 91], "respect": [7, 8, 47, 60, 65, 81], "automodelforcausallm": 7, "from_pretrain": [7, 11], "eleutherai": 7, "gpt": 7, "j": 7, "calib_dataload": 7, "sparse_model": 7, "threshold": 7, "futur": [7, 11, 91], "modelopt_sparse_model": 7, "pth": 7, "along": [7, 8, 81, 82], "mask": [7, 85, 87, 89, 90, 91], "later": [7, 9, 84], "opt": [7, 9, 11, 13, 48], "initi": [7, 11, 17, 23, 24, 26, 31, 48, 49, 50, 58, 59, 61, 69, 75, 77, 80, 81, 87, 94, 99, 100], "unmodifi": [7, 48, 49], "plain": 7, "enforc": [7, 47, 48, 49, 50, 91], "access": [7, 21, 37, 47, 49, 60], "remov": [7, 24, 34, 37, 49, 85, 90, 99], "longer": [7, 11, 42, 49, 80, 91], "dure": [7, 8, 11, 33, 48, 77, 91, 104], "do": [7, 30, 37, 49, 63, 81], "overview": [7, 8, 12], "well": [7, 9, 11, 49, 84, 99, 100], "terminologi": 7, "fraction": 7, "zero": [7, 31, 58, 81, 85], "broadli": 7, "categor": [7, 21], "randomli": 7, "distribut": [7, 13], "across": [7, 8, 37, 39, 42, 49, 77, 101], "matrix": [7, 85, 90], "flexibl": 7, "lead": 7, "poor": 7, "util": [7, 13, 19, 21, 23, 24, 29, 30, 31, 32, 37, 38, 41, 42, 43, 44, 48, 51, 61, 64, 90, 93, 94, 95, 96, 97, 98, 99, 100, 102], "other": [7, 8, 13, 19, 33, 37, 42, 49, 64, 81], "hand": 7, "effici": 7, "exploit": 7, "higher": [7, 18], "math": [7, 8], "throughput": [7, 9, 10], "usual": [7, 48, 49, 53], "special": [7, 11, 49, 81], "grain": [7, 8], "block": [7, 9, 11, 26, 38, 43, 49, 81, 91, 101], "contigu": [7, 41, 42], "element": [7, 24, 32, 85, 97, 99, 101], "most": [7, 8, 9, 33], "nonzero": 7, "due": [7, 11], "implement": [7, 8, 30, 37, 46, 49, 53, 67, 69, 77, 81], "benefit": 7, "bandwidth": [7, 8, 9], "smaller": 7, "than": [7, 11, 19, 49, 81], "core": [7, 13], "deliv": 7, "multipli": [7, 81], "oper": [7, 8, 9, 13, 21, 33, 34, 97], "argument": [7, 21, 48, 49, 50, 53, 58, 60, 64, 65, 81, 91, 93, 94, 99], "allow": [7, 10, 11, 13, 49, 53], "On": 7, "amper": [7, 9], "four": 7, "two": [7, 10, 32, 34, 38, 40, 81, 99], "There": [7, 81], "mani": [7, 33, 81], "commonli": [7, 8], "approach": 7, "largest": 7, "retain": [7, 82], "rest": 7, "simpl": [7, 10, 11, 69, 81, 100], "brain": 7, "surgeon": 7, "better": [7, 10], "consist": [8, 19, 47, 49], "found": [8, 24, 47, 49], "topic": 8, "width": [8, 17, 18], "valu": [8, 10, 32, 34, 39, 47, 49, 50, 59, 60, 63, 64, 65, 75, 77, 81, 82, 86, 87, 91, 99], "integ": [8, 9, 26, 58, 59, 77, 81], "sign": [8, 32, 77, 81], "mantissa": [8, 81], "float": [8, 17, 26, 32, 38, 39, 50, 53, 58, 65, 81, 90, 97, 98, 99, 100, 101], "point": [8, 9, 11, 31, 81], "expon": [8, 81], "FOR": 8, "explan": 8, "unscal": 8, "map": [8, 24, 30, 31, 40, 44, 60, 61, 65, 81], "rang": [8, 50, 67, 77, 81, 82], "share": [8, 34, 37, 40], "same": [8, 13, 18, 33, 34, 37, 39, 48, 49, 81, 84, 91, 99, 101], "calcul": [8, 43, 53, 81, 82, 85], "divid": 8, "common": [8, 11, 19, 30, 32, 34, 41], "whole": [8, 51, 77], "global": [8, 31, 59], "channel": [8, 9, 10, 49, 58, 81, 82, 99], "separ": [8, 11, 48, 58], "fix": [8, 13, 30, 51, 77, 91], "dimens": [8, 26, 32, 34, 82], "typic": [8, 9, 10, 11, 33], "gptq": 8, "stai": 8, "high": [8, 9, 17, 91], "help": [8, 27, 99], "constrain": 8, "scenario": [8, 9], "comput": [8, 9, 11, 26, 50, 58, 77, 81, 82, 85, 91, 96, 97, 102], "potenti": 8, "adjust": [8, 11, 43, 61, 64], "maxim": [8, 53, 85], "max": [8, 9, 11, 17, 18, 26, 39, 50, 60, 64, 67, 69, 81, 97], "which": [8, 11, 18, 24, 30, 46, 47, 48, 50, 53, 58, 60, 61, 64, 65, 67, 75, 81, 82, 84, 85, 99, 101], "maximum": [8, 59, 82, 94], "unchang": [8, 49], "round": [8, 26, 39], "nearest": [8, 26], "entropi": [8, 33, 58], "view": 8, "updat": [8, 11, 26, 38, 44, 47, 48, 49, 61, 63, 77, 86, 91], "loss": [8, 26, 91], "compar": [8, 99], "must": [8, 11, 26, 48, 49, 50, 63, 81, 82, 99], "backward": [8, 13, 24, 40, 44, 67, 81], "pass": [8, 11, 37, 49, 64, 67, 77, 81, 82, 99], "straight": [8, 81], "estim": [8, 13, 50, 81], "ste": 8, "clip": [8, 33, 67, 77, 81], "behind": 8, "explicit": [8, 10, 33], "graph": [8, 13, 24, 30, 31, 34, 102], "represent": [8, 40, 63, 86], "qdq": [8, 10, 24, 27, 30, 31, 33], "node": [8, 10, 11, 13, 18, 24, 30, 31, 33, 34, 40], "network": [8, 37, 77, 90], "three": 9, "primari": 9, "compon": 9, "context": [9, 18, 39, 49, 75, 80, 81, 82, 98], "small": [9, 11], "often": [9, 11, 30], "bound": [9, 18, 53, 69], "In": [9, 10, 49, 60, 81, 99], "limit": [9, 18], "regim": 9, "give": [9, 33, 99], "superior": 9, "improv": 9, "serv": 9, "16": [9, 23, 50], "densiti": 9, "becom": 9, "crucial": 9, "consequ": [9, 49], "lower": [9, 33, 47, 69], "choic": [9, 49, 50, 101], "suggest": 9, "priorit": [9, 47], "caus": [9, 30], "veri": 9, "littl": 9, "strong": 9, "meet": [9, 82], "could": [9, 11, 16, 17, 49, 50], "try": [9, 102], "earlier": [9, 84], "sq": 9, "might": [9, 11, 48, 49, 81, 99], "toler": 9, "tabl": [9, 60], "summar": 9, "tradeoff": 9, "consid": [9, 21], "medium": 9, "min": [9, 50, 67, 69, 93, 97], "50": 9, "ada": 9, "hopper": 9, "variant": [9, 19, 32], "w4a16": [9, 60], "wise": [9, 11, 24], "25": 9, "ten": 9, "w4a8": [9, 39, 60], "impact": 9, "measur": [9, 41, 100], "10": [9, 11], "popular": 9, "ll": 9, "subject": [9, 21], "togeth": [10, 11, 39, 48, 49], "eq": 10, "kei": [10, 11, 41, 47, 48, 49, 60, 64, 65, 81, 84, 91, 99], "advantag": [10, 11], "offer": [10, 11, 16], "non": [10, 19, 21, 24, 30, 48, 49, 85, 99], "expert": [10, 11, 38, 39], "white": 10, "box": 10, "design": 10, "custom": [10, 19, 31, 47, 49, 60, 61], "vision": 10, "new": [10, 13, 31, 47, 49, 63, 82], "rule": [10, 11, 24, 47, 49, 87], "real": [10, 11], "6": [10, 26], "9": [10, 26, 44], "prefer": 10, "link": [10, 13, 41], "done": [10, 11, 32, 91], "random": [10, 13, 23, 34], "imag": [10, 99], "numpi": [10, 23, 31, 33, 34, 59, 102], "multi": [10, 37], "arrai": [10, 31, 32, 33, 59, 102], "calib_data": 10, "np": [10, 41, 58], "randn": 10, "batch_siz": [10, 34, 94], "h": [10, 85], "w": [10, 26, 49, 85], "npy": 10, "dict": [10, 17, 18, 23, 24, 30, 31, 33, 34, 37, 40, 41, 44, 47, 48, 49, 51, 53, 60, 61, 63, 64, 65, 77, 81, 84, 86, 89, 90, 91, 97, 99], "match": [10, 11, 24, 30, 47, 60, 61, 65, 84, 96], "input_nam": [10, 24, 34], "shape": [10, 17, 21, 23, 31, 34, 39, 42, 59, 77, 81], "input_name2": 10, "shape2": 10, "savez": 10, "npz": [10, 40, 44], "moq": 10, "calibration_data": [10, 23, 33], "calibration_data_path": 10, "onnx_path": [10, 23, 29, 33, 34], "output_path": [10, 33], "quant": [10, 33, 63], "quantize_mod": [10, 26, 33], "altern": 10, "line": 10, "m": [10, 81, 85], "path": [10, 13, 17, 18, 19, 23, 24, 33, 34, 37, 40, 42, 44, 93], "output": [10, 11, 16, 17, 18, 24, 30, 31, 33, 34, 38, 49, 77, 81], "calibraton": 10, "tool": [10, 19, 21, 33, 46], "insert": [10, 11, 31, 33, 48], "friendli": [10, 33], "chang": [10, 13, 21, 48, 59], "behavior": [10, 48, 49, 60, 65, 67], "tweak": 10, "param": 10, "op_types_to_quant": [10, 21, 33], "op_types_to_exclud": [10, 33], "trtexec": 10, "usr": 10, "src": [10, 24], "bin": [10, 58], "previou": 10, "saveengin": 10, "check": [10, 11, 19, 24, 34, 42, 47, 48, 49, 53, 54, 79, 82, 96, 99], "report": [10, 100], "latenc": [10, 53], "field": [10, 39, 41, 47, 60, 84], "replac": [10, 11, 29, 49, 60, 61, 65, 77, 82], "flag": [10, 18, 33, 48], "implicit": 10, "refactor": 11, "pytorch_quant": 11, "nativ": [11, 13, 30], "hug": 11, "face": [11, 65], "fake": [11, 48, 77, 81], "mean": [11, 18, 40, 91, 97], "cover": 11, "128": [11, 58, 60, 81], "512": [11, 23, 94], "sampl": [11, 17, 23, 49, 94, 99, 101], "callabl": [11, 48, 50, 53, 60, 61, 63, 64, 65, 86, 91, 94, 99], "own": [11, 42, 49, 60, 79, 81], "order": [11, 19, 48, 49, 50, 84, 99], "collect": [11, 19, 24, 30, 37, 56, 58, 59, 90], "statist": [11, 56, 65, 77, 82], "around": 11, "select": [11, 21, 26, 33, 36, 49, 64, 85, 101], "look": [11, 30, 47, 49], "verifi": 11, "place": [11, 30, 47, 48, 49, 91, 101], "let": [11, 49], "summari": [11, 65], "successfulli": 11, "print_quantization_summari": 11, "normal": [11, 21, 27, 50, 71, 73, 91, 99], "flow": [11, 21], "sample_input": 11, "onnx_fil": 11, "direct": 11, "recov": 11, "resourc": [11, 18], "directli": [11, 49, 77, 81], "frozen": [11, 87], "int8_default_cfg": [11, 60], "calib_set": 11, "rate": 11, "durat": 11, "train_load": 11, "schedul": 11, "epoch": 11, "even": [11, 26], "less": 11, "suffici": [11, 27], "resum": [11, 46], "modelopt_st": [11, 48, 77], "pt": [11, 48], "trainer": 11, "save_model": 11, "restor": [11, 41, 46, 48, 61, 63, 86], "restore_from_modelopt_st": [11, 48], "un": [11, 61], "load_state_dict": [11, 48], "under": [11, 18, 40], "hood": 11, "linear": [11, 21, 24, 33, 34, 38, 39, 41, 74, 75, 82, 84], "conv": [11, 30, 33], "patch": [11, 25, 28, 49], "instanc": [11, 17, 41, 48, 49, 54, 60, 61, 65, 73, 77, 81, 91, 94], "quantdescriptor": [11, 58, 59, 61, 77, 81], "paramet": [11, 13, 17, 18, 19, 21, 23, 24, 26, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 53, 54, 56, 58, 59, 61, 64, 65, 69, 77, 81, 82, 85, 86, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 101, 102], "axi": [11, 58, 59, 60, 61, 77, 81, 82], "tensor_qu": [11, 61, 72, 74, 75, 77], "nn": [11, 48, 49, 53, 58, 61, 74, 76, 77, 84, 99], "descriptor": [11, 63, 81, 86], "quant_desc": [11, 77], "num_bit": [11, 38, 58, 59, 60, 61, 77, 81], "unsign": [11, 32, 58, 59, 77, 81], "true": [11, 17, 26, 34, 39, 40, 42, 44, 48, 49, 53, 58, 60, 61, 69, 77, 81, 82, 96, 99], "quant_x": 11, "disabl": [11, 13, 65, 77, 82], "who": 11, "wildcard": [11, 60, 61, 65], "filter": [11, 60, 61, 65], "copi": [11, 13, 21, 60], "quant_cfg": [11, 60, 61, 65, 94], "bmm": 11, "output_quant": [11, 38, 75], "howev": [11, 49], "regist": [11, 13, 47, 49, 50, 61, 81, 90], "them": [11, 32, 39, 42, 46, 49, 77, 99], "handl": [11, 13, 48, 49, 52, 79, 88], "unsupport": 11, "subclass": [11, 49], "kv": [11, 17], "attent": [11, 38, 39], "layernorm": [11, 38, 39, 61], "class": [11, 17, 19, 23, 26, 27, 37, 39, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 61, 63, 67, 69, 72, 73, 74, 75, 76, 77, 81, 85, 86, 87, 89, 90, 99, 100], "quantlayernorm": [11, 61], "__init__": [11, 17, 19, 23, 26, 27, 37, 39, 48, 49, 50, 53, 58, 59, 61, 69, 77, 81, 100], "self": [11, 48, 49, 50, 61, 75], "normalized_shap": [11, 61], "super": [11, 61], "_setup": [11, 49, 61], "input_quant": [11, 60, 61, 65, 75], "weight_quant": [11, 58, 60, 61, 65, 75], "anywher": 11, "f": [11, 48, 61], "layer_norm": [11, 61], "bia": [11, 39, 61, 81], "ep": [11, 39, 61], "so": [11, 36, 39, 47, 49, 58, 59], "instanti": [11, 19], "attribut": [11, 49, 60, 61, 65, 77, 81, 99], "code": [11, 32, 40, 63, 79, 86, 101], "original_cl": [11, 49, 61], "quantized_cl": [11, 61], "fold": [11, 49, 65], "avoid": [11, 104], "repeat": [11, 97], "inferec": 11, "fold_weight": [11, 65], "quantized_model": 11, "user_evaluate_func": 11, "instal": [12, 13, 82], "sparsiti": [12, 13, 18, 84, 85, 86, 87, 88, 89, 91], "changelog": 12, "contact": 12, "u": 12, "faq": 12, "break": 13, "wa": [13, 53, 99], "renam": 13, "ammo": 13, "full": [13, 18, 37, 38, 39, 47, 48], "product": 13, "being": [13, 49], "deprec": [13, 58, 78, 80, 98], "inference_gpu": 13, "arg": [13, 19, 48, 49, 53, 75, 77, 78, 80, 87, 98, 99, 101, 102], "model_config_export": 13, "torch_to_tensorrt_llm_checkpoint": [13, 18, 40], "experiment": [13, 64, 77, 81], "sat": 13, "chain": [13, 63], "set_data_parallel_group": [13, 95], "set_tensor_parallel_group": [13, 95], "multipl": [13, 16, 42, 43, 48, 49, 60, 77, 99], "modif": [13, 46, 48], "float8": 13, "fsdp": 13, "fulli": [13, 49], "shard": 13, "ad": [13, 48, 49, 77, 81, 91], "releas": 13, "wheel": 13, "submodul": [13, 49, 84], "bug": 13, "compat": [13, 38, 40, 44, 48, 49, 99], "issu": [13, 99, 103, 104], "dynam": [13, 25, 27, 47, 54, 81, 87, 91, 99], "dim": 13, "opset": 13, "neg": 13, "pb": 13, "tmp": [13, 40], "folder": 13, "tensorrt_llm": [16, 17, 18, 19, 39, 40, 44], "stage": [16, 77], "top": [16, 27, 48, 49], "build_tensorrt_llm": [16, 18], "pretrained_config": [16, 18], "pretrained_config_json_path": 16, "engine_dir": [16, 17, 18], "max_input_len": [16, 17, 18], "max_output_len": [16, 18], "max_batch_s": [16, 18], "max_beam_width": [16, 17, 18], "max_num_beam": 16, "num_build_work": [16, 18], "offlin": 16, "built": [16, 18], "host_context": 16, "token": [16, 17, 18, 19, 94], "num_beam": 16, "long": 16, "input_text": 16, "wrapper": [17, 48, 77, 99], "over": [17, 26, 34, 47, 49, 53, 65, 73, 94], "level": [17, 24, 49, 91], "runner": 17, "hlapi": 17, "profil": [17, 99], "valid": [17, 34, 42, 47, 49], "kv_cache_config": 17, "tokenizerbas": 17, "int": [17, 18, 26, 31, 34, 37, 38, 39, 40, 42, 43, 44, 49, 50, 54, 58, 77, 81, 82, 85, 94, 95, 97, 99], "blob": [17, 18, 19, 21, 40, 81, 99], "main": [17, 18, 19, 21, 27, 40, 77], "doc": [17, 18, 40, 47, 81], "sourc": [17, 18, 40, 63, 79, 86, 93], "perf": 17, "md": [17, 18, 40, 81], "generate_text": 17, "prompt": [17, 18], "max_new_token": 17, "temperatur": 17, "0": [17, 18, 26, 34, 39, 40, 44, 58, 60, 61, 77, 81, 99, 100, 101], "keep_input_prompt": 17, "text": [17, 19, 94], "string": [17, 48, 58, 61, 64, 81, 85, 91, 98, 99], "length": [17, 18, 50, 82, 94], "bool": [17, 18, 24, 26, 32, 33, 34, 38, 39, 40, 42, 47, 48, 49, 53, 54, 58, 63, 85, 86, 95, 96, 99], "prommpt": 17, "2d": [17, 72], "beam": [17, 18], "properti": [17, 19, 37, 39, 47, 48, 49, 50, 53, 59, 63, 77, 81, 86, 89, 90], "get": [17, 37, 47, 49, 51, 53, 77, 81, 85, 89, 90, 94, 95, 99, 100], "200": 18, "max_num_token": 18, "enable_spars": 18, "fals": [18, 26, 33, 34, 39, 40, 47, 48, 49, 58, 59, 60, 61, 69, 77, 81, 96, 99, 104], "max_prompt_embedding_table_s": 18, "target": [18, 37, 40, 41, 42, 48, 49, 94, 99], "sequenc": [18, 21, 31, 32, 50, 51, 96, 101], "search": [18, 46, 48, 49, 53, 54, 86, 89, 90, 91, 101], "phase": 18, "count": [18, 99], "ones": [18, 85], "been": [18, 48, 65], "fall": 18, "inflight": 18, "alloc": 18, "perf_best_practic": 18, "worker": 18, "concern": 18, "increas": 18, "num": [18, 98], "At": 18, "lost": 18, "higer": 18, "cpu": [18, 42, 58], "conserv": 18, "switch": 18, "trt": [18, 31, 44], "With": 18, "tactic": 18, "spars": [18, 84, 85, 86, 87, 89, 90, 91], "significantli": [18, 91], "prepend": 18, "concaten": 18, "embed": [18, 38, 39, 42, 58], "multimod": 18, "build_tensorrt_llm_rank": 18, "customsentencepiecetoken": 19, "pretrainedtoken": [19, 94], "sentencepiecetoken": 19, "make": [19, 32, 42, 49, 82], "nemo_exampl": 19, "sh": 19, "kwarg": [19, 47, 48, 49, 64, 75, 77, 78, 80, 87, 98, 99, 101, 102], "constructor": [19, 99], "legaci": 19, "batch_decod": 19, "id": [19, 41], "introduc": 19, "batch_encode_plu": 19, "ignor": [19, 81], "decod": [19, 38, 39, 40], "mmethod": 19, "encod": 19, "return_tensor": 19, "max_length": 19, "eos_token": 19, "eos_token_id": 19, "pad_token": 19, "pad_token_id": 19, "get_nemo_token": 19, "tokenizer_cfg_path": 19, "logic": [19, 32, 38, 44, 53], "get_nmt_token": 19, "nlp": 19, "tokenizer_util": 19, "py": [19, 21, 40, 99], "get_tokenzi": 19, "tokenizer_dir_or_path": 19, "subpackag": [20, 22, 35], "op": [21, 27, 30, 33, 48], "get_quantizable_op_typ": 21, "_configure_ort": 21, "suppli": [21, 81], "is_binary_op": 21, "whether": [21, 24, 31, 32, 37, 38, 40, 48, 49, 50, 53, 63, 81, 91, 95, 99], "binari": 21, "is_control_flow_op": 21, "control": 21, "categori": 21, "is_conversion_op": 21, "is_copy_op": 21, "is_default_quantizable_op_by_ort": 21, "ort": [21, 27, 28, 29], "nodes_to_quant": [21, 30, 33], "microsoft": 21, "onnxruntim": [21, 29], "registri": [21, 47, 48, 49], "is_fusible_reduction_op": 21, "reduct": 21, "fusibl": [21, 30], "myelin": 21, "is_generator_op": 21, "is_irregular_mem_access_op": 21, "irreggular": 21, "mem": 21, "is_linear_op": 21, "is_modifier_op": 21, "modifi": [21, 24, 27, 31, 34, 47, 48, 49, 87], "is_multiclass_op": 21, "multiclass": 21, "is_non_reshape_copy_op": 21, "reshap": [21, 85], "is_normalization_op": 21, "is_pointwise_or_elementwise_op": 21, "pointwis": [21, 30], "elementwis": 21, "is_pooling_or_window_op": 21, "pool": [21, 76], "is_recurrent_op": 21, "recurr": 21, "is_selection_op": 21, "is_sequence_op": 21, "is_shape_op": 21, "is_unary_op": 21, "unari": 21, "calibrationdataprovid": 23, "calibrationdataread": [23, 26], "intial": [23, 37], "ndarrai": [23, 26, 31, 32, 33, 34, 41, 44, 81, 102], "ex": [23, 24], "64": [23, 42], "timestep": 23, "encoder_hidden_st": 23, "768": 23, "1024": [23, 60], "get_next": 23, "reader": 23, "randomdataprovid": 23, "placement": 24, "build_non_residual_input_map": 24, "residu": [24, 30], "add": [24, 30, 33, 48, 99], "assum": [24, 38, 99], "subgraph": [24, 30], "convolut": [24, 72], "sum": [24, 85], "anoth": [24, 48, 49], "constant": [24, 31, 38, 41, 44, 81], "becaus": [24, 26, 44, 93, 99], "occur": [24, 38, 44], "modern": 24, "convnet": 24, "connect": 24, "v": [24, 39, 99], "classify_partition_nod": 24, "partit": [24, 33], "outsid": 24, "algo": 24, "info": [24, 47, 99], "dst": 24, "tupl": [24, 30, 34, 37, 38, 40, 48, 49, 50, 53, 54, 58, 59, 63, 81, 82, 85, 86, 90, 91, 97, 99], "filter_quantizable_kgen_head": 24, "cask_fusible_partit": 24, "kgen_partit": 24, "quantizable_op_typ": [24, 30], "kgen": [24, 30], "head": 24, "cask": [24, 30], "get_fusible_backbon": 24, "backbon": [24, 30], "fuse": [24, 30], "bn": 24, "relu": 24, "some": [24, 30, 32, 38, 44, 51, 59, 67, 81], "tri": 24, "those": [24, 30, 81, 84], "biasadd": 24, "constmul": 24, "start": [24, 41, 100], "has_const_input": 24, "has_path_typ": 24, "path_typ": 24, "is_forward": 24, "wild_card_typ": 24, "path_nod": 24, "wrt": 24, "travers": [24, 30], "wild": 24, "card": 24, "skip": [24, 49, 58, 60], "accumul": 24, "is_const_input": 24, "const": 24, "foldabl": 24, "print_stat": 24, "verbos": [24, 33, 91], "stat": [24, 53, 91, 97], "remove_partial_input_qdq": 24, "no_quantize_input": 24, "mark": 24, "onnx_graphsurgeon": 25, "explicitli": [25, 47, 49], "patch_gs_modul": 25, "graphsurgeon": [25, 31], "woq": 26, "write": [26, 33, 37, 79], "back": [26, 46, 49], "disk": 26, "awqcliphelp": 26, "object": [26, 31, 37, 39, 48, 49, 50, 72, 74, 75, 77, 81, 99], "helper": [26, 32], "block_siz": [26, 60, 77, 81], "alpha_step": [26, 60], "05": [26, 39], "alpha": 26, "5": [26, 30], "55": 26, "65": 26, "7": 26, "75": 26, "85": 26, "95": 26, "min_alpha": 26, "update_best_param": 26, "dq_tensor": 26, "dequant": [26, 31, 81], "find_scal": 26, "quant_tensor": 26, "quantize_int4": 26, "onnx_model": [26, 34], "calibration_data_read": 26, "use_external_data_format": [26, 33], "gemm_io_typ": 26, "gemm": [26, 33], "modelproto": [26, 34], "googl": [26, 31, 81], "protobuf": [26, 31], "intern": [26, 31, 49, 101], "enum_type_wrapp": [26, 31], "enumtypewrapp": [26, 31], "0x7f7a18433710": [26, 31], "quantize_int4_awq_clip": 26, "data_read": 26, "k": [26, 39], "quantize_int4_rtn": 26, "dq_onli": [26, 31], "rtn": 26, "ab": [26, 67], "q": [26, 31, 39], "round_to_even": 26, "denot": 26, "ti": 26, "alwai": 26, "cin": 26, "plug": 26, "rh": 26, "y": [26, 99], "broken": 26, "addit": [27, 47, 48, 49, 53, 81, 91], "qdqconvtranspos": 27, "qdqoperatorbas": 27, "convtranspos": [27, 33], "onnx_quant": 27, "onnx_nod": 27, "init": 27, "qdqnormal": 27, "intend": [27, 49], "contain": [28, 46, 47, 48, 49, 53, 63, 77, 91, 99], "patch_ort_modul": 28, "shoul": 29, "ort_client": 29, "create_inference_sess": 29, "inferencesess": 29, "find_fusible_partit": 30, "partitioned_nod": 30, "non_residual_input": 30, "matmul": [30, 33], "find_hardcoded_pattern": 30, "tail": 30, "mtl_v1": 30, "reducesum": 30, "div": 30, "mul": [30, 33], "sub": [30, 46, 53], "pow": 30, "sqrt": 30, "find_layer_norm_partit": 30, "norm": 30, "find_mha_partit": 30, "mha": 30, "softmax": 30, "least": [30, 47], "find_non_quantizable_partitions_from_pattern": 30, "certain": [30, 48, 49], "counterpart": [30, 49, 65], "expect": [30, 44], "find_quantizable_nod": 30, "yet": [30, 77], "get_skiped_output_lay": 30, "paritially_quantizable_nod": 30, "dq": 31, "insert_dq_nod": 31, "quantized_weight": 31, "insert_qdq_nod": 31, "weight_map": 31, "make_gs_dequantize_nod": 31, "_basename_": 31, "make_gs_dequantize_output": 31, "variabl": [31, 34, 77, 99], "repres": [31, 49, 50, 81, 99], "make_gs_quantize_nod": 31, "make_gs_quantize_output": 31, "make_gs_quantized_weight": 31, "wq": 31, "make_gs_scal": 31, "make_gs_zp": 31, "use_trt_qdq_op": 31, "pack_float32_to_4bit_optim": 32, "float32": [32, 77, 81], "4bit": 32, "pack": [32, 41], "everi": 32, "concecut": 32, "byte": [32, 34, 100], "pack_float32_to_4bit": 32, "mainli": 32, "reli": 32, "move": [32, 58, 77, 102], "therebi": 32, "remain": [32, 49], "ceil": 32, "farrai": 32, "calib": [33, 77], "boost": 33, "But": [33, 58], "aka": 33, "drop": 33, "averagepool": 33, "batchnorm": 33, "globalaveragepool": 33, "maxpool": 33, "calibration_method": 33, "nodes_to_exclud": 33, "keep_intermediate_fil": 33, "minmax": 33, "indic": [33, 48, 50, 53, 63, 81, 91, 99, 101], "express": [33, 84], "exclud": 33, "conv__224": 33, "conv__252": 33, "keep": 33, "intermedi": 33, "filenam": 33, "suffix": [33, 98], "throughout": 33, "One": [33, 58, 81], "int4_rtn": 33, "int4_rtn_dq": 33, "int4_rtn_trt": 33, "int4_rtn_trt_dq": 33, "int4_awq_clip": 33, "int4_awq_clip_trt": 33, "model_nam": [33, 39], "duplicate_shared_linear_weight": 34, "duplic": [34, 49, 85], "thei": [34, 49, 60, 65, 84, 91, 99], "graphproto": 34, "find_lowest_common_ancestor": 34, "node1": 34, "node2": 34, "lowest": 34, "ancestor": 34, "second": 34, "lca": 34, "distanc": 34, "gen_random_input": 34, "get_all_input_nam": 34, "get_batch_s": 34, "assert": [34, 48], "fail": 34, "get_batch_size_from_byt": 34, "onnx_byt": 34, "get_child_nod": 34, "consum": 34, "get_input_nam": 34, "external_inputs_onli": 34, "extern": 34, "external_input_nam": 34, "initializer_nam": 34, "get_input_names_from_byt": 34, "model_byt": 34, "get_input_shap": 34, "get_input_shapes_from_byt": 34, "get_node_nam": 34, "get_node_names_from_byt": 34, "get_output_nam": 34, "get_output_names_from_byt": 34, "get_output_shap": 34, "get_parent_nod": 34, "get_variable_input": 34, "is_valid_onnx_model": 34, "file_path": 34, "name_onnx_nod": 34, "assign": [34, 49], "statu": 34, "randomize_weight": 34, "randomize_weights_onnx_byt": 34, "seed": [34, 101], "remove_weights_data": 34, "raw": 34, "save_onnx": 34, "save_as_external_data": 34, "save_onnx_bytes_to_dir": 34, "onnx_dir": 34, "onnx_nam": 34, "validate_batch_s": 34, "equal": [34, 50], "validate_onnx": 34, "els": [34, 38], "far": [36, 59], "nfsworkspac": 37, "workspac": [37, 40], "storag": 37, "nf": [37, 40], "modifit": 37, "involv": 37, "commun": [37, 40], "nor": 37, "barrier": [37, 95], "respons": 37, "synchron": [37, 77, 95, 101], "serial": [37, 81, 99], "workspace_path": [37, 40, 42], "postprocess": [37, 40, 64], "cross": [37, 40], "sharedmemori": 37, "clean": [37, 77], "is_initi": 37, "read_configs_and_weights_from_rank": 37, "target_rank": 37, "write_configs_and_weight": 37, "config_json": 37, "get_configs_parallel": 37, "gather": [37, 65], "shm": 37, "nullabl": 37, "sync": 37, "yield": [37, 40, 48, 49, 54, 77, 81, 91], "empti": [37, 42, 81, 84, 99], "destroi": [37, 91], "consumpt": 37, "get_group": 37, "get_rank": 37, "safe": 37, "get_tensors_parallel": 37, "get_world_s": 37, "world": 37, "model_config": [38, 40, 41, 42, 44], "empir": [38, 44], "except": [38, 44, 77, 81, 84, 98], "build_attention_config": 38, "model_metadata_config": 38, "ext_config": 38, "decoderlayerconfig": [38, 39], "attentionconfig": [38, 39], "build_decoder_config": 38, "build_embedding_config": 38, "normalization_const": 38, "embeddingconfig": [38, 39], "build_layernorm_config": 38, "layernormconfig": [38, 39], "build_linear_config": 38, "linear_typ": [38, 39], "linearconfig": [38, 39, 41], "build_mlp_config": 38, "mlp": [38, 39], "mlpconfig": [38, 39], "build_moe_config": 38, "moe": [38, 60], "moeconfig": [38, 39], "build_qkv": 38, "qkv_modul": 38, "qkv": [38, 39, 41], "qkvconfig": [38, 39, 41], "build_stacked_expert": 38, "experts_weight_1": 38, "experts_weight_2": 38, "check_model_compat": 38, "module_list": 38, "And": [38, 39, 77], "posit": [38, 81], "assembl": 38, "modulelist": 38, "final": [38, 49, 53], "get_activation_scaling_factor": 38, "get_kv_cache_dtyp": 38, "kv_cach": 38, "get_kv_cache_scaling_factor": 38, "get_prequant_scaling_factor": 38, "prequant": [38, 39], "get_scaling_factor": 38, "tensorquant": [38, 60, 61, 65, 75, 77], "get_transformer_lay": 38, "root": [38, 48], "get_weight_block_s": 38, "get_weight_scaling_factor": 38, "get_weight_scaling_factor_2": 38, "secondari": 38, "is_attent": 38, "is_decoder_list": 38, "is_embed": 38, "is_layernorm": 38, "is_linear": 38, "is_mlp": 38, "is_mo": 38, "kv_cache_scaling_factor": 39, "kv_cache_dtyp": 39, "rotary_dim": 39, "inf": 39, "clip_qkv": 39, "input_layernorm": 39, "mlp_layernorm": 39, "post_layernorm": 39, "num_attention_head": 39, "attention_head_s": 39, "num_kv_head": 39, "max_position_embed": 39, "rotary_pct": 39, "use_alibi": 39, "new_decoder_architectur": 39, "parallel_attent": 39, "apply_residual_connection_post_layernorm": 39, "use_cach": 39, "rope_ratio": 39, "seq_length": 39, "rotary_bas": 39, "partial_rotary_factor": 39, "moe_num_expert": 39, "moe_top_k": 39, "moe_tp_mod": 39, "moe_renorm_mod": 39, "alibi_bias_max": 39, "residual_layernorm": 39, "residual_mlp": 39, "ffn_hidden_size_loc": 39, "ffn": 39, "hidden": 39, "hidden_s": 39, "local_vocab_s": 39, "vocab_s": 39, "expertconfig": 39, "fc": 39, "proj": 39, "layernorm_typ": 39, "1e": 39, "column": [39, 82], "activation_scaling_factor": 39, "weights_scaling_factor": [39, 41], "weights_scaling_factor_2": 39, "prequant_scaling_factor": 39, "awq_block_s": 39, "gate": [39, 60], "hidden_act": 39, "merged_fc1_g": 39, "mixtur": 39, "router": [39, 60], "modelconfig": [39, 41, 42, 44], "inform": [39, 48, 77, 85, 91], "pipeline_parallel": 39, "float16": [39, 40], "tensor_parallel": 39, "vocab_embed": 39, "position_embed": 39, "ln_emb": 39, "factori": 39, "ln_f": 39, "lm_head": [39, 41, 42, 60, 84], "share_embedding_t": 39, "num_key_value_head": 39, "vocab_size_pad": 39, "pad": [39, 41, 42, 99], "merg": [39, 40, 41, 42, 43], "concat": 39, "fit": 39, "quanitz": 39, "weight_scaling_factor_2": 39, "export_npz": 40, "naive_fp8_quant": 40, "use_nfs_workspac": 40, "split": [40, 41, 42, 58], "manual": 40, "old": 40, "naiv": 40, "nest": [40, 41], "pretrainedconfig": 40, "modeling_util": 40, "uniqu": [40, 49, 85, 99], "tensorrt_llm_config": [40, 44], "from_quantized_weight": 41, "torch_dtyp": 41, "merge_fc1_g": 41, "merge_qkv": 41, "model_config_from_dict": 41, "d": [41, 77], "model_config_to_dict": 41, "naive_quant": 41, "debug": 41, "pack_linear_weight": 41, "pad_weight": 41, "tp_size": [41, 44], "restore_model_config": 41, "recurs": [41, 49, 54, 61, 102], "split_config_and_weight": 41, "prefix": [41, 77, 81], "to_quantized_weight": 41, "check_weight_shape_valid": 42, "training_tensor_parallel": 42, "tp": [42, 44], "recurisv": 42, "pad_embedding_lm_head": 42, "padding_factor": 42, "postprocess_model_config": 42, "training_pipeline_parallel": 42, "pp": 42, "item": [42, 47], "postprocess_tensor": 42, "force_cpu": 42, "force_contigu": 42, "force_non_view": 42, "get_weights_scaling_factor": 43, "group_siz": 43, "facotr": 43, "resmooth_and_get_scal": 43, "merged_weight": 43, "pre_quant_scal": [43, 77], "avg_pre_quant_scal": 43, "resmooth": 43, "averag": 43, "weight_scaling_factor": 43, "convert_to_tensorrt_llm_config": 44, "tp_size_overwrit": 44, "overwrit": [44, 49, 84], "builder": 44, "unshard": 44, "is_tensorrt_llm_0_8_or_9": 44, "weights_to_npz": 44, "convert_to_transformer_engin": 45, "transformers_engin": 45, "purpos": [46, 81], "infrastructur": 46, "ingest": 46, "procedur": [46, 47, 53], "manag": [46, 48, 49, 80, 82], "individu": [46, 49, 77, 91], "wihin": 46, "pydant": 47, "basemodel": 47, "modeloptconfig": [47, 60, 84], "modeloptbaseconfig": [47, 48, 60, 63, 84, 86], "our": 47, "extend": [47, 49], "capabl": 47, "easier": [47, 58], "manipul": 47, "alia": [47, 50, 72, 74, 76, 81], "get_field_name_from_kei": 47, "alias": 47, "possibl": [47, 49, 85], "itemsview": 47, "keysview": 47, "model_dump": 47, "dump": 47, "warn": [47, 99], "model_dump_json": 47, "valuesview": 47, "modeloptbaserul": 47, "what": 47, "govern": 47, "classmethod": [47, 48, 49], "customize_rul": 47, "construct": [47, 49, 81], "accord": [47, 49, 67, 91, 99], "get_rule_typ": 47, "wrapped_onli": 47, "typealia": 47, "validate_rul": 47, "cl": 47, "unwrap": [47, 48, 99], "modeloptbaseruleconfig": [47, 84], "made": 47, "register_default": 47, "extra_default": 47, "unregister_default": 47, "unregist": [47, 61], "modeloptfield": 47, "pydanticundefin": 47, "get_kwargs_for_create_model_with_rul": 47, "default_rul": 47, "create_model": 47, "auto": 47, "relev": 47, "rule_field": 47, "docstr": 47, "pertain": 47, "myruleconfig": 47, "get_create_model_kwargs_for_rule_model": 47, "sparsemagnitudeconfig": [47, 84, 91], "conveni": 47, "sinc": [47, 58, 63], "autodoc": 47, "workaround": 47, "burden": 47, "standard": [48, 49, 50, 53, 91, 99], "interfac": [48, 51, 53, 89], "histori": [48, 53], "modeloptstatemanag": 48, "correspondig": 48, "task": [48, 53, 65], "init_st": 48, "add_mod": 48, "_state": 48, "therefor": [48, 49], "recal": 48, "_modedescriptor": [48, 63, 86, 91], "check_mod": 48, "propos": 48, "static": [48, 67, 75, 77, 81], "get_config_class": 48, "has_stat": 48, "trivial": 48, "is_convert": 48, "is_root": 48, "rais": [48, 59, 69, 81, 82, 103], "detect": 48, "last_mod": 48, "last": [48, 81, 99], "modes_with_st": 48, "transfer_state_dict": 48, "model_from": 48, "model_to": [48, 99], "transfer": [48, 58], "update_last_state_before_new_mod": 48, "update_last_state_before_sav": 48, "apply_mod": 48, "form": [48, 99], "model_cl": 48, "quantizemodedescriptor": [48, 63], "_moderegistrycl": 48, "retriev": [48, 99], "error": [48, 63, 78, 80, 98], "bias": 48, "model_weight": 48, "pathlik": 48, "binaryio": 48, "locat": [48, 61], "distributeddataparallel": 48, "previous": [48, 86], "hparam": [49, 54], "dynamicmodul": [49, 50, 75, 87, 99], "famili": 49, "searchabl": 49, "unit": [49, 51, 99], "space": [49, 53, 54, 101], "candid": 49, "dynamicconv2d": 49, "callback": [49, 50], "out_channel": 49, "upon": 49, "temporari": [49, 77], "ensur": [49, 99], "expos": 49, "outermost": 49, "child": [49, 58], "dynamiclinear": 49, "inherit": 49, "__class__": 49, "henc": [49, 87], "simultan": 49, "inject": 49, "rigoruo": 49, "fashion": 49, "vanilla": 49, "still": 49, "sever": 49, "mechan": 49, "parent": 49, "mutual": 49, "exlus": 49, "append": 49, "dyanmic": 49, "anymor": 49, "affect": [49, 99], "simpli": 49, "underli": 49, "revert": 49, "kept": 49, "until": [49, 99], "resultign": 49, "extra_repr": [49, 77], "sure": 49, "__dict__": [49, 81], "heavili": 49, "temporarili": 49, "again": 49, "afterward": 49, "force_assign": 49, "forc": 49, "overwritt": 49, "buffer": [49, 77], "circumst": 49, "freez": 49, "restrict": 49, "tbe": 49, "orgin": 49, "although": [49, 50], "get_hparam": 49, "get_paramet": 49, "scalabl": 49, "overriden": 49, "out_features_ratio": 49, "system": 49, "keyword": [49, 58, 93, 99], "_dmregistrycl": 49, "fly": 49, "leav": 49, "intact": 49, "some_dynamic_modul": 49, "named_hparam": [49, 54], "accordingli": [49, 61], "symbol": [49, 50, 81], "reset_dynamic_attribut": 49, "interf": 49, "getattr": 49, "setattr": 49, "delattr": 49, "exit": 49, "dynamicspac": 49, "hyperparamet": [49, 50, 53], "hp": 49, "parameter_nam": 49, "subnet": [49, 53, 86, 101], "convert_to_dynam": 49, "dm_registri": 49, "result": [49, 101], "is_configur": [49, 50, 54], "is_dynam": [49, 54], "named_dynamic_modul": 49, "strict": [49, 77], "exact": 49, "ident": 50, "activeslic": 50, "union": 50, "slice": 50, "longtensor": 50, "importanceestim": 50, "active_slic": 50, "sort": 50, "enforce_ord": 50, "32": [50, 81], "equival": 50, "_order": 50, "todo": 50, "ever": [50, 63], "cycl": 50, "detector": 50, "among": 50, "1d": [50, 72, 85], "in_channel": 50, "conv2d": [50, 72, 81, 84], "score": [50, 53, 91], "associ": 50, "notion": 50, "is_sort": 50, "sortabl": 50, "register_import": 50, "importance_estim": 50, "prune": 51, "prepar": [51, 90, 94], "constitut": 51, "arbitrari": 51, "whenev": 53, "conjunct": [53, 104], "entrypoint": [53, 63, 86], "basesearch": [53, 86, 89], "abc": 53, "overrid": 53, "after_search": [53, 90], "before_search": [53, 90], "constraint": 53, "construct_forward_loop": 53, "silent": 53, "runnabl": 53, "default_search_config": [53, 89, 90], "abstract": [53, 57, 81], "default_state_dict": [53, 89], "dummy_input": [53, 99], "eval_scor": 53, "has_scor": 53, "load_search_checkpoint": 53, "reset_search": 53, "reset": [53, 58, 59, 77], "begin": 53, "run_search": [53, 89], "sanitize_search_config": [53, 89], "sanit": [53, 89], "save_search_checkpoint": 53, "prunabl": 53, "net": [53, 99], "score_func": 53, "satisfi": [53, 93], "upper": [53, 69], "metric": 53, "flop": 53, "convent": [53, 81], "search_space_s": 54, "determin": [56, 101], "histogramcalibr": 58, "_calibr": [58, 59], "unifi": 58, "compute_amax": [58, 59, 77], "percentil": 58, "mse": 58, "boolean": [58, 59, 69, 77, 81, 82], "num_bin": 58, "2048": [58, 60], "grow_method": 58, "skip_zero": 58, "torch_hist": 58, "histc": 58, "stride": 58, "start_bin": 58, "99": 58, "amax": [58, 59, 64, 77, 81, 82], "100": 58, "calibrate_weight": 58, "perchannel": 58, "ideal": 58, "would": [58, 91], "collector": 58, "haven": 58, "decoupl": 58, "decid": [58, 81], "NOT": [58, 81], "everyth": 58, "neuron": 58, "absolut": [59, 81, 82], "maxcalibr": 59, "track": 59, "calib_desc": 59, "maxcalibdescriptor": 59, "readonli": [59, 77], "plot": 59, "track_amax": 59, "runtimeerror": 59, "definit": [60, 65], "cnn": 60, "fp8_default_cfg": 60, "int4_awq_cfg": 60, "w4a8_awq_beta_cfg": 60, "against": [60, 61, 65], "sequentialquant": [60, 61, 75, 77], "sequenti": [60, 77, 84], "block_sparse_mo": 60, "int4_blockwise_weight_only_cfg": 60, "awq_lit": [60, 64], "awq_ful": [60, 64], "max_co_batch_s": [60, 64], "awq_clip": [60, 64], "These": 60, "custom_int4_awq_cfg": 60, "deepcopi": 60, "quantizeconfig": 60, "null": [60, 84], "replace_quant_modul": 61, "set_quantizer_attribut": 61, "quant_model": 61, "wildcard_or_filter_func": [61, 65], "finegrain": 61, "set_from_attribute_dict": [61, 77], "set_quantizer_by_cfg": [61, 65], "quantizeexportmodedescriptor": 63, "placehold": [63, 78, 80], "throw": [63, 78, 80], "properli": 63, "config_class": [63, 86], "is_export_mod": [63, 86], "inspect": [63, 86], "export_mod": [63, 86], "next_mod": [63, 86], "immedi": 63, "update_for_new_mod": [63, 86], "update_for_sav": [63, 86], "pair": 64, "4096": 64, "postprocess_amax": 64, "post_process_fn": 64, "disable_quant": 65, "enable_quant": 65, "print_quant_summari": 65, "anyth": 65, "entir": 65, "subsampl": 65, "clipfunct": 67, "univers": [67, 81], "clamp": [67, 69], "scalar": 67, "doesn": [67, 82], "broadcast": [67, 81], "genar": 67, "gradient": [67, 81, 82, 91, 99], "ibm": 67, "pact": 67, "paper": [67, 91], "arxiv": 67, "1805": 67, "06085": 67, "tensorflow": [67, 81, 99], "clip_by_valu": 67, "ctx": [67, 81], "grad_output": [67, 81], "clip_value_min": [67, 69], "clip_value_max": [67, 69], "learn_min": 69, "learn_max": 69, "similar": [69, 77], "valueerror": [69, 81, 82], "conv1d": 72, "quantconv1d": 72, "quantconv2d": 72, "conv3d": 72, "quantconv3d": 72, "convtranspose1d": 72, "quantconvtranspose1d": 72, "convtranspose2d": 72, "quantconvtranspose2d": 72, "convtranspose3d": 72, "quantconvtranspose3d": 72, "_legacyquantlinearconvbasemixin": [72, 74], "default_quant_desc_weight": [72, 74, 75], "scaledquantdescriptor": [72, 74, 75, 77, 81], "3d": [72, 73], "transpos": 72, "quantinstancenorm1d": 73, "_legacyquantinputbasemixin": [73, 76], "instancenorm1d": 73, "quantinstancenorm2d": 73, "instancenorm2d": 73, "4d": 73, "quantinstancenorm3d": 73, "instancenorm3d": 73, "5d": 73, "quantlinear": 74, "quantinputbas": 75, "default_quant_desc_input": 75, "default_quant_desc_output": 75, "quantlinearconvbas": 75, "initialize_quantizer_with_dummy_st": 75, "dummi": 75, "devic": [75, 94, 99, 100], "quantize_weight": 75, "adaptiveavgpool1d": 76, "quantadaptiveavgpool1d": 76, "adaptiveavgpool2d": 76, "quantadaptiveavgpool2d": 76, "adaptiveavgpool3d": 76, "quantadaptiveavgpool3d": 76, "avgpool1d": 76, "quantavgpool1d": 76, "avgpool2d": 76, "quantavgpool2d": 76, "avgpool3d": 76, "quantavgpool3d": 76, "maxpool1d": 76, "quantmaxpool1d": 76, "maxpool2d": 76, "quantmaxpool2d": 76, "maxpool3d": 76, "quantmaxpool3d": 76, "container": 77, "get_modelopt_st": 77, "meta": [77, 86], "replace_sequential_quantizer_with_single_quant": 77, "indx": 77, "attribute_dict": 77, "tensor_quantizer_iter": 77, "itself": 77, "fake_tensor_qu": 77, "if_quant": 77, "bodi": 77, "if_clip": 77, "if_calib": 77, "Not": 77, "probabl": 77, "fake_qu": [77, 81], "step_siz": 77, "mutabl": 77, "clean_up_after_set_from_modelopt_st": 77, "set_from_modelopt_st": 77, "bypass": 77, "neither": 77, "disable_calib": 77, "disable_clip": 77, "disable_qu": 77, "enable_calib": 77, "enable_clip": 77, "enable_qu": 77, "export_amax": 77, "output_dtyp": [77, 81], "init_learn_amax": 77, "is_en": 77, "load_calib_amax": 77, "necessari": [77, 87], "maxbound": 77, "narrow_rang": [77, 81], "symmetr": [77, 81], "reset_amax": 77, "sync_amax_across_distributed_group": 77, "parallel_group": 77, "distributedprocessgroup": [77, 95], "freeze_paramet": 78, "group_paramet": 78, "match_paramet": 78, "quant_weight_inplac": 78, "apex": 79, "deactiv": [80, 84, 99], "enable_onnx_export": 80, "fakeaffinetensorquantfunct": 81, "affin": 81, "gemmlowp": 81, "style": 81, "shift": 81, "master": [81, 95, 98, 99], "reason": 81, "cancel": 81, "come": 81, "penalti": 81, "grad_input": 81, "min_rang": 81, "max_rang": 81, "As": 81, "granular": [81, 82], "faketensorquantfunct": 81, "tensorquantfunct": 81, "legacyfaketensorquantfunct": 81, "comment": 81, "scalede4m3funct": 81, "e4m3fi": 81, "emul": 81, "fpx": 81, "seem": 81, "nice": 81, "thing": 81, "ax": 81, "input_tensor": [81, 82], "kcr": 81, "quant_axi": 81, "scale_bit": 81, "scheme": 81, "learn_amax": 81, "learnabl": 81, "scale_amax": 81, "experi": 81, "calib_method": 81, "histogram": 81, "protect": 81, "_": 81, "exactli": [81, 99], "get_block_quant_axes_and_s": 81, "interpret": [81, 99], "127": 81, "grad_scal": 81, "though": 81, "natur": 81, "int32": 81, "255": 81, "scaled_e4m3_abstract": 81, "scaled_e4m3": 81, "export_torch_mod": 82, "is_quant": 82, "is_quantized_column_parallel_linear": 82, "is_quantized_layer_with_weight": 82, "is_quantized_row_parallel_linear": 82, "row": 82, "is_torch_library_support": 82, "exce": 82, "reduce_amax": 82, "keepdim": 82, "unless": 82, "entri": 82, "never": 82, "meant": 82, "deprect": 82, "sens": 82, "unknown": 82, "replace_funct": 82, "new_func": 82, "exportsparseconfig": [84, 86], "export_spars": [84, 86], "sparsegptconfig": [84, 91], "sparse_gpt": 84, "sparseconv2dconfig": 84, "shown": 84, "glob": 84, "unnest": 84, "short": 84, "sparselinearconfig": 84, "inspir": 85, "magnitudesearch": 85, "basesparsesearch": [85, 89, 90], "searcher": [85, 90], "compute_valid_1d_pattern": 85, "vector": 85, "permut": 85, "create_asp_mask": 85, "m4n2_1d": 85, "booltensor": [85, 87], "fill": 85, "ratio": 85, "get_nmprune_info": 85, "mat": 85, "mn_1d_best": 85, "reshape_1d": 85, "dimension": 85, "hw": 85, "exportsparsemodedescriptor": 86, "sparsegptmodedescriptor": 86, "sparsemagnitudemodedescriptor": 86, "search_algorithm": 86, "convert_sparse_model": 86, "restore_export_spars": 86, "restore_sparse_model": 86, "update_sparse_metadata": 86, "sparsemodul": 87, "set_mask": 87, "sparsegptsearch": 90, "hessian": [90, 91], "artifcat": 90, "hook": 90, "create_sgpt_mask": 90, "invert": 90, "hessian_damp": 90, "invers": 90, "finish": 91, "approxim": [91, 101], "carefulli": 91, "runtim": 91, "cannot": [91, 99], "fewer": 91, "run_forward_loop": [91, 99], "thu": 91, "cpp": 93, "load_cpp_extens": 93, "cuda_version_specifi": 93, "fail_msg": 93, "load_kwarg": 93, "instantan": 93, "create_forward_loop": 94, "dataset_nam": 94, "cnn_dailymail": 94, "max_sample_length": 94, "tailor": 94, "feed": [94, 99], "predict": 94, "preprocess": 94, "suitabl": 94, "pretrainedtokenizerfast": 94, "get_dataset_dataload": 94, "tokniz": 94, "instancn": 94, "hugginfac": 94, "backend": 95, "get_data_parallel_group": 95, "get_tensor_parallel_group": 95, "is_mast": 95, "processgroup": 95, "list_closest_to_median": 97, "closest": [97, 101], "val": 97, "avg": 97, "std": 97, "val2list": 97, "repeat_tim": 97, "val2tupl": 97, "min_len": 97, "idx_repeat": 97, "deprecatederror": 98, "notimplementederror": 98, "no_stdout": 98, "silenc": 98, "stdout": 98, "num2hrb": 98, "big": 98, "human": 98, "readabl": 98, "print_rank_0": 98, "compare_dict": 99, "dict1": 99, "dict2": 99, "unmatch": 99, "get_model_attribut": 99, "get_module_devic": 99, "get_same_pad": 99, "kernel_s": 99, "init_model_from_model_lik": 99, "model_cls_or_cal": 99, "is_channels_last": 99, "is_parallel": 99, "make_divis": 99, "divisor": 99, "min_val": 99, "taken": 99, "tf": 99, "repo": 99, "divis": 99, "seen": 99, "research": 99, "slim": 99, "mobilenet": 99, "target_model": 99, "layout": 99, "param_num": 99, "trainable_onli": 99, "1000000": 99, "trainabl": 99, "1e6": 99, "million": 99, "param_num_from_forward": 99, "circumv": 99, "appear": 99, "remove_bn": 99, "max_it": 99, "progress_bar": 99, "infiinit": 99, "exhaust": 99, "z": 99, "label": 99, "descript": 99, "progress": 99, "bar": 99, "set_submodul": 99, "target_submodul": 99, "complement": 99, "get_submodul": 99, "standardize_constructor_arg": 99, "constructor_arg": 99, "standardize_model_arg": 99, "model_or_fw_or_sig": 99, "use_kwarg": 99, "signatur": 99, "mtn": [99, 101], "matter": 99, "were": 99, "kw_only_arg": 99, "standardize_model_like_tupl": 99, "standardize_named_model_arg": 99, "args_norm": 99, "args_with_default": 99, "unwrap_model": 99, "raise_error": 99, "msg": 99, "zero_grad": 99, "timer": 100, "contextdecor": 100, "decor": 100, "stop": 100, "clear_cuda_cach": 100, "clear": 100, "get_cuda_memory_stat": 100, "report_memori": 100, "determinist": 101, "centroid": 101, "seq": 101, "prod": 101, "aim": 101, "cheapli": 101, "median": 101, "na": 101, "recogn": 101, "popul": 101, "shuffl": 101, "mutablesequ": 101, "numpy_to_torch": 102, "np_output": 102, "torch_detach": 102, "detach": 102, "torch_to": 102, "torch_to_numpi": 102, "question": 103}, "objects": {"modelopt": [[15, 0, 0, "-", "deploy"], [20, 0, 0, "-", "onnx"], [35, 0, 0, "-", "torch"]], "modelopt.deploy": [[16, 0, 0, "-", "llm"]], "modelopt.deploy.llm": [[17, 0, 0, "-", "generate"], [18, 0, 0, "-", "model_config_trt"], [19, 0, 0, "-", "nemo_utils"]], "modelopt.deploy.llm.generate": [[17, 1, 1, "", "LLM"]], "modelopt.deploy.llm.generate.LLM": [[17, 2, 1, "", "__init__"], [17, 2, 1, "", "generate_text"], [17, 3, 1, "", "max_beam_width"], [17, 3, 1, "", "max_input_len"]], "modelopt.deploy.llm.model_config_trt": [[18, 4, 1, "", "build_tensorrt_llm"], [18, 4, 1, "", "build_tensorrt_llm_rank"]], "modelopt.deploy.llm.nemo_utils": [[19, 1, 1, "", "CustomSentencePieceTokenizer"], [19, 4, 1, "", "get_nemo_tokenizer"], [19, 4, 1, "", "get_tokenzier"]], "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer": [[19, 2, 1, "", "__init__"], [19, 2, 1, "", "batch_decode"], [19, 2, 1, "", "batch_encode_plus"], [19, 2, 1, "", "decode"], [19, 2, 1, "", "encode"], [19, 3, 1, "", "eos_token"], [19, 3, 1, "", "eos_token_id"], [19, 3, 1, "", "pad_token"], [19, 3, 1, "", "pad_token_id"]], "modelopt.onnx": [[21, 0, 0, "-", "op_types"], [22, 0, 0, "-", "quantization"], [34, 0, 0, "-", "utils"]], "modelopt.onnx.op_types": [[21, 4, 1, "", "get_quantizable_op_types"], [21, 4, 1, "", "is_binary_op"], [21, 4, 1, "", "is_control_flow_op"], [21, 4, 1, "", "is_conversion_op"], [21, 4, 1, "", "is_copy_op"], [21, 4, 1, "", "is_default_quantizable_op_by_ort"], [21, 4, 1, "", "is_fusible_reduction_op"], [21, 4, 1, "", "is_generator_op"], [21, 4, 1, "", "is_irregular_mem_access_op"], [21, 4, 1, "", "is_linear_op"], [21, 4, 1, "", "is_modifier_op"], [21, 4, 1, "", "is_multiclass_op"], [21, 4, 1, "", "is_non_reshape_copy_op"], [21, 4, 1, "", "is_normalization_op"], [21, 4, 1, "", "is_pointwise_or_elementwise_op"], [21, 4, 1, "", "is_pooling_or_window_op"], [21, 4, 1, "", "is_recurrent_op"], [21, 4, 1, "", "is_selection_op"], [21, 4, 1, "", "is_sequence_op"], [21, 4, 1, "", "is_shape_op"], [21, 4, 1, "", "is_unary_op"]], "modelopt.onnx.quantization": [[23, 0, 0, "-", "calib_utils"], [24, 0, 0, "-", "graph_utils"], [25, 0, 0, "-", "gs_patching"], [26, 0, 0, "-", "int4"], [27, 0, 0, "-", "operators"], [28, 0, 0, "-", "ort_patching"], [29, 0, 0, "-", "ort_utils"], [30, 0, 0, "-", "partitioning"], [31, 0, 0, "-", "qdq_utils"], [32, 0, 0, "-", "quant_utils"], [33, 0, 0, "-", "quantize"]], "modelopt.onnx.quantization.calib_utils": [[23, 1, 1, "", "CalibrationDataProvider"], [23, 1, 1, "", "RandomDataProvider"]], "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider": [[23, 2, 1, "", "__init__"], [23, 2, 1, "", "get_next"]], "modelopt.onnx.quantization.calib_utils.RandomDataProvider": [[23, 2, 1, "", "__init__"], [23, 2, 1, "", "get_next"]], "modelopt.onnx.quantization.graph_utils": [[24, 4, 1, "", "build_non_residual_input_map"], [24, 4, 1, "", "classify_partition_nodes"], [24, 4, 1, "", "filter_quantizable_kgen_heads"], [24, 4, 1, "", "get_fusible_backbone"], [24, 4, 1, "", "has_const_input"], [24, 4, 1, "", "has_path_type"], [24, 4, 1, "", "is_const_input"], [24, 4, 1, "", "print_stat"], [24, 4, 1, "", "remove_partial_input_qdq"]], "modelopt.onnx.quantization.gs_patching": [[25, 4, 1, "", "patch_gs_modules"]], "modelopt.onnx.quantization.int4": [[26, 1, 1, "", "AWQClipHelper"], [26, 4, 1, "", "dq_tensor"], [26, 4, 1, "", "find_scales"], [26, 4, 1, "", "quant_tensor"], [26, 4, 1, "", "quantize_int4"], [26, 4, 1, "", "quantize_int4_awq_clip"], [26, 4, 1, "", "quantize_int4_rtn"], [26, 4, 1, "", "rtn"]], "modelopt.onnx.quantization.int4.AWQClipHelper": [[26, 2, 1, "", "__init__"], [26, 5, 1, "", "alpha_step"], [26, 5, 1, "", "alphas"], [26, 5, 1, "", "min_alpha"], [26, 2, 1, "", "update_best_params"]], "modelopt.onnx.quantization.operators": [[27, 1, 1, "", "QDQConvTranspose"], [27, 1, 1, "", "QDQNormalization"]], "modelopt.onnx.quantization.operators.QDQConvTranspose": [[27, 2, 1, "", "__init__"], [27, 2, 1, "", "quantize"]], "modelopt.onnx.quantization.operators.QDQNormalization": [[27, 2, 1, "", "__init__"], [27, 2, 1, "", "quantize"]], "modelopt.onnx.quantization.ort_patching": [[28, 4, 1, "", "patch_ort_modules"]], "modelopt.onnx.quantization.ort_utils": [[29, 4, 1, "", "create_inference_session"]], "modelopt.onnx.quantization.partitioning": [[30, 4, 1, "", "find_fusible_partitions"], [30, 4, 1, "", "find_hardcoded_patterns"], [30, 4, 1, "", "find_layer_norm_partitions"], [30, 4, 1, "", "find_mha_partitions"], [30, 4, 1, "", "find_non_quantizable_partitions_from_patterns"], [30, 4, 1, "", "find_quantizable_nodes"], [30, 4, 1, "", "get_skiped_output_layers"]], "modelopt.onnx.quantization.qdq_utils": [[31, 4, 1, "", "insert_dq_nodes"], [31, 4, 1, "", "insert_qdq_nodes"], [31, 4, 1, "", "make_gs_dequantize_node"], [31, 4, 1, "", "make_gs_dequantize_output"], [31, 4, 1, "", "make_gs_quantize_node"], [31, 4, 1, "", "make_gs_quantize_output"], [31, 4, 1, "", "make_gs_quantized_weight"], [31, 4, 1, "", "make_gs_scale"], [31, 4, 1, "", "make_gs_zp"], [31, 4, 1, "", "use_trt_qdq_ops"]], "modelopt.onnx.quantization.quant_utils": [[32, 4, 1, "", "pack_float32_to_4bit_optimized"]], "modelopt.onnx.quantization.quantize": [[33, 4, 1, "", "quantize"]], "modelopt.onnx.utils": [[34, 4, 1, "", "duplicate_shared_linear_weights"], [34, 4, 1, "", "find_lowest_common_ancestor"], [34, 4, 1, "", "gen_random_inputs"], [34, 4, 1, "", "get_all_input_names"], [34, 4, 1, "", "get_batch_size"], [34, 4, 1, "", "get_batch_size_from_bytes"], [34, 4, 1, "", "get_child_nodes"], [34, 4, 1, "", "get_input_names"], [34, 4, 1, "", "get_input_names_from_bytes"], [34, 4, 1, "", "get_input_shapes"], [34, 4, 1, "", "get_input_shapes_from_bytes"], [34, 4, 1, "", "get_node_names"], [34, 4, 1, "", "get_node_names_from_bytes"], [34, 4, 1, "", "get_output_names"], [34, 4, 1, "", "get_output_names_from_bytes"], [34, 4, 1, "", "get_output_shapes"], [34, 4, 1, "", "get_parent_nodes"], [34, 4, 1, "", "get_variable_inputs"], [34, 4, 1, "", "is_valid_onnx_model"], [34, 4, 1, "", "name_onnx_nodes"], [34, 4, 1, "", "randomize_weights"], [34, 4, 1, "", "randomize_weights_onnx_bytes"], [34, 4, 1, "", "remove_weights_data"], [34, 4, 1, "", "save_onnx"], [34, 4, 1, "", "save_onnx_bytes_to_dir"], [34, 4, 1, "", "validate_batch_size"], [34, 4, 1, "", "validate_onnx"]], "modelopt.torch": [[36, 0, 0, "-", "export"], [46, 0, 0, "-", "opt"], [55, 0, 0, "-", "quantization"], [83, 0, 0, "-", "sparsity"], [92, 0, 0, "-", "utils"]], "modelopt.torch.export": [[37, 0, 0, "-", "distribute"], [38, 0, 0, "-", "layer_utils"], [39, 0, 0, "-", "model_config"], [40, 0, 0, "-", "model_config_export"], [41, 0, 0, "-", "model_config_utils"], [42, 0, 0, "-", "postprocess"], [43, 0, 0, "-", "scaling_factor_utils"], [44, 0, 0, "-", "tensorrt_llm_utils"], [45, 0, 0, "-", "transformer_engine"]], "modelopt.torch.export.distribute": [[37, 1, 1, "", "NFSWorkspace"], [37, 4, 1, "", "barrier"], [37, 4, 1, "", "get_configs_parallel"], [37, 4, 1, "", "get_group"], [37, 4, 1, "", "get_rank"], [37, 4, 1, "", "get_tensors_parallel"], [37, 4, 1, "", "get_world_size"]], "modelopt.torch.export.distribute.NFSWorkspace": [[37, 2, 1, "", "__init__"], [37, 3, 1, "", "is_initialized"], [37, 2, 1, "", "read_configs_and_weights_from_rank"], [37, 2, 1, "", "write_configs_and_weights"]], "modelopt.torch.export.layer_utils": [[38, 4, 1, "", "build_attention_config"], [38, 4, 1, "", "build_decoder_config"], [38, 4, 1, "", "build_embedding_config"], [38, 4, 1, "", "build_layernorm_config"], [38, 4, 1, "", "build_linear_config"], [38, 4, 1, "", "build_mlp_config"], [38, 4, 1, "", "build_moe_config"], [38, 4, 1, "", "build_qkv"], [38, 4, 1, "", "build_stacked_experts"], [38, 4, 1, "", "check_model_compatibility"], [38, 4, 1, "", "get_activation_scaling_factor"], [38, 4, 1, "", "get_kv_cache_dtype"], [38, 4, 1, "", "get_kv_cache_scaling_factor"], [38, 4, 1, "", "get_prequant_scaling_factor"], [38, 4, 1, "", "get_scaling_factor"], [38, 4, 1, "", "get_transformer_layers"], [38, 4, 1, "", "get_weight_block_size"], [38, 4, 1, "", "get_weight_scaling_factor"], [38, 4, 1, "", "get_weight_scaling_factor_2"], [38, 4, 1, "", "is_attention"], [38, 4, 1, "", "is_decoder_list"], [38, 4, 1, "", "is_embedding"], [38, 4, 1, "", "is_layernorm"], [38, 4, 1, "", "is_linear"], [38, 4, 1, "", "is_mlp"], [38, 4, 1, "", "is_moe"]], "modelopt.torch.export.model_config": [[39, 1, 1, "", "AttentionConfig"], [39, 1, 1, "", "DecoderLayerConfig"], [39, 1, 1, "", "EmbeddingConfig"], [39, 1, 1, "", "ExpertConfig"], [39, 1, 1, "", "LayernormConfig"], [39, 1, 1, "", "LinearConfig"], [39, 1, 1, "", "MLPConfig"], [39, 1, 1, "", "MOEConfig"], [39, 1, 1, "", "ModelConfig"], [39, 1, 1, "", "QKVConfig"]], "modelopt.torch.export.model_config.AttentionConfig": [[39, 2, 1, "", "__init__"], [39, 5, 1, "", "clip_qkv"], [39, 5, 1, "", "dense"], [39, 5, 1, "", "kv_cache_dtype"], [39, 5, 1, "", "kv_cache_scaling_factor"], [39, 5, 1, "", "qkv"], [39, 5, 1, "", "rotary_dim"]], "modelopt.torch.export.model_config.DecoderLayerConfig": [[39, 2, 1, "", "__init__"], [39, 5, 1, "", "alibi_bias_max"], [39, 5, 1, "", "apply_residual_connection_post_layernorm"], [39, 5, 1, "", "attention"], [39, 5, 1, "", "attention_head_size"], [39, 5, 1, "", "decoder_type"], [39, 3, 1, "", "ffn_hidden_size_local"], [39, 3, 1, "", "hidden_size"], [39, 5, 1, "", "input_layernorm"], [39, 5, 1, "", "max_position_embeddings"], [39, 5, 1, "", "mlp"], [39, 5, 1, "", "mlp_layernorm"], [39, 5, 1, "", "model_name"], [39, 5, 1, "", "moe_num_experts"], [39, 5, 1, "", "moe_renorm_mode"], [39, 5, 1, "", "moe_top_k"], [39, 5, 1, "", "moe_tp_mode"], [39, 5, 1, "", "new_decoder_architecture"], [39, 5, 1, "", "num_attention_heads"], [39, 5, 1, "", "num_kv_heads"], [39, 5, 1, "", "parallel_attention"], [39, 5, 1, "", "partial_rotary_factor"], [39, 5, 1, "", "post_layernorm"], [39, 5, 1, "", "quantization"], [39, 5, 1, "", "residual_layernorm"], [39, 5, 1, "", "residual_mlp"], [39, 5, 1, "", "rope_ratio"], [39, 5, 1, "", "rotary_base"], [39, 5, 1, "", "rotary_pct"], [39, 5, 1, "", "seq_length"], [39, 5, 1, "", "use_alibi"], [39, 5, 1, "", "use_cache"]], "modelopt.torch.export.model_config.EmbeddingConfig": [[39, 2, 1, "", "__init__"], [39, 3, 1, "", "hidden_size"], [39, 3, 1, "", "local_vocab_size"], [39, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.ExpertConfig": [[39, 2, 1, "", "__init__"], [39, 5, 1, "", "fc"], [39, 5, 1, "", "proj"]], "modelopt.torch.export.model_config.LayernormConfig": [[39, 2, 1, "", "__init__"], [39, 5, 1, "", "bias"], [39, 5, 1, "", "eps"], [39, 5, 1, "", "layernorm_type"], [39, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.LinearConfig": [[39, 2, 1, "", "__init__"], [39, 5, 1, "", "activation_scaling_factor"], [39, 5, 1, "", "awq_block_size"], [39, 5, 1, "", "bias"], [39, 5, 1, "", "linear_type"], [39, 5, 1, "", "prequant_scaling_factor"], [39, 5, 1, "", "weight"], [39, 5, 1, "", "weights_scaling_factor"], [39, 5, 1, "", "weights_scaling_factor_2"]], "modelopt.torch.export.model_config.MLPConfig": [[39, 2, 1, "", "__init__"], [39, 5, 1, "", "fc"], [39, 5, 1, "", "gate"], [39, 5, 1, "", "hidden_act"], [39, 5, 1, "", "merged_fc1_gate"], [39, 5, 1, "", "proj"]], "modelopt.torch.export.model_config.MOEConfig": [[39, 2, 1, "", "__init__"], [39, 5, 1, "", "experts"], [39, 3, 1, "", "fc"], [39, 5, 1, "", "hidden_act"], [39, 5, 1, "", "router"]], "modelopt.torch.export.model_config.ModelConfig": [[39, 2, 1, "", "__init__"], [39, 5, 1, "", "dtype"], [39, 3, 1, "", "hidden_act"], [39, 3, 1, "", "hidden_size"], [39, 5, 1, "", "layers"], [39, 5, 1, "", "lm_head"], [39, 5, 1, "", "ln_embed"], [39, 5, 1, "", "ln_f"], [39, 3, 1, "", "max_position_embeddings"], [39, 3, 1, "", "num_attention_heads"], [39, 3, 1, "", "num_kv_heads"], [39, 5, 1, "", "pipeline_parallel"], [39, 5, 1, "", "position_embedding"], [39, 5, 1, "", "quantization"], [39, 5, 1, "", "rank"], [39, 5, 1, "", "share_embedding_table"], [39, 5, 1, "", "tensor_parallel"], [39, 5, 1, "", "version"], [39, 5, 1, "", "vocab_embedding"], [39, 5, 1, "", "vocab_size"], [39, 3, 1, "", "vocab_size_padded"]], "modelopt.torch.export.model_config.QKVConfig": [[39, 2, 1, "", "__init__"], [39, 3, 1, "", "activation_scaling_factor"], [39, 3, 1, "", "awq_block_size"], [39, 3, 1, "", "bias"], [39, 5, 1, "", "k"], [39, 3, 1, "", "prequant_scaling_factor"], [39, 5, 1, "", "q"], [39, 5, 1, "", "v"], [39, 3, 1, "", "weight"], [39, 3, 1, "", "weights_scaling_factor"], [39, 3, 1, "", "weights_scaling_factor_2"]], "modelopt.torch.export.model_config_export": [[40, 4, 1, "", "export_tensorrt_llm_checkpoint"], [40, 4, 1, "", "torch_to_tensorrt_llm_checkpoint"]], "modelopt.torch.export.model_config_utils": [[41, 4, 1, "", "from_quantized_weight"], [41, 4, 1, "", "merge_fc1_gate"], [41, 4, 1, "", "merge_qkv"], [41, 4, 1, "", "model_config_from_dict"], [41, 4, 1, "", "model_config_to_dict"], [41, 4, 1, "", "naive_quantization"], [41, 4, 1, "", "pack_linear_weights"], [41, 4, 1, "", "pad_weights"], [41, 4, 1, "", "restore_model_config"], [41, 4, 1, "", "split_config_and_weights"], [41, 4, 1, "", "to_quantized_weight"]], "modelopt.torch.export.postprocess": [[42, 4, 1, "", "check_weight_shape_valid"], [42, 4, 1, "", "pad_embedding_lm_head"], [42, 4, 1, "", "postprocess_model_config"], [42, 4, 1, "", "postprocess_tensors"]], "modelopt.torch.export.scaling_factor_utils": [[43, 4, 1, "", "get_weights_scaling_factor"], [43, 4, 1, "", "resmooth_and_get_scale"]], "modelopt.torch.export.tensorrt_llm_utils": [[44, 4, 1, "", "convert_to_tensorrt_llm_config"], [44, 4, 1, "", "is_tensorrt_llm_0_8_or_9"], [44, 4, 1, "", "weights_to_npz"]], "modelopt.torch.export.transformer_engine": [[45, 4, 1, "", "convert_to_transformer_engine"]], "modelopt.torch.opt": [[47, 0, 0, "-", "config"], [48, 0, 0, "-", "conversion"], [49, 0, 0, "-", "dynamic"], [50, 0, 0, "-", "hparam"], [51, 0, 0, "-", "mode"], [52, 0, 0, "-", "plugins"], [53, 0, 0, "-", "searcher"], [54, 0, 0, "-", "utils"]], "modelopt.torch.opt.config": [[47, 6, 1, "", "ModeloptBaseConfig"], [47, 6, 1, "", "ModeloptBaseRule"], [47, 6, 1, "", "ModeloptBaseRuleConfig"], [47, 4, 1, "", "ModeloptField"], [47, 4, 1, "", "get_kwargs_for_create_model_with_rules"]], "modelopt.torch.opt.config.ModeloptBaseConfig": [[47, 2, 1, "", "get"], [47, 2, 1, "", "get_field_name_from_key"], [47, 2, 1, "", "items"], [47, 2, 1, "", "keys"], [47, 2, 1, "", "model_dump"], [47, 2, 1, "", "model_dump_json"], [47, 2, 1, "", "update"], [47, 2, 1, "", "values"]], "modelopt.torch.opt.config.ModeloptBaseRule": [[47, 2, 1, "", "customize_rule"], [47, 2, 1, "", "get_rule_type"], [47, 2, 1, "", "validate_rule"]], "modelopt.torch.opt.config.ModeloptBaseRuleConfig": [[47, 2, 1, "", "register_default"], [47, 2, 1, "", "unregister_default"]], "modelopt.torch.opt.conversion": [[48, 1, 1, "", "ModeloptStateManager"], [48, 4, 1, "", "apply_mode"], [48, 4, 1, "", "modelopt_state"], [48, 4, 1, "", "restore"], [48, 4, 1, "", "restore_from_modelopt_state"], [48, 4, 1, "", "save"]], "modelopt.torch.opt.conversion.ModeloptStateManager": [[48, 2, 1, "", "__init__"], [48, 2, 1, "", "add_mode"], [48, 2, 1, "", "check_mode"], [48, 2, 1, "", "get_config_class"], [48, 3, 1, "", "has_state"], [48, 2, 1, "", "is_converted"], [48, 3, 1, "", "last_mode"], [48, 2, 1, "", "load_state_dict"], [48, 2, 1, "", "modes_with_states"], [48, 2, 1, "", "state_dict"], [48, 2, 1, "", "transfer_state_dict"], [48, 2, 1, "", "update_last_state_before_new_mode"], [48, 2, 1, "", "update_last_state_before_save"]], "modelopt.torch.opt.dynamic": [[49, 1, 1, "", "DynamicModule"], [49, 1, 1, "", "DynamicSpace"]], "modelopt.torch.opt.dynamic.DynamicModule": [[49, 2, 1, "", "__init__"], [49, 2, 1, "", "convert"], [49, 2, 1, "", "export"], [49, 2, 1, "", "extra_repr"], [49, 2, 1, "", "force_assign"], [49, 2, 1, "", "freeze"], [49, 2, 1, "", "get_hparam"], [49, 2, 1, "", "modify"], [49, 2, 1, "", "named_hparams"], [49, 3, 1, "", "original_cls"], [49, 2, 1, "", "reset_dynamic_attributes"]], "modelopt.torch.opt.dynamic.DynamicSpace": [[49, 2, 1, "", "__init__"], [49, 2, 1, "", "config"], [49, 2, 1, "", "convert_to_dynamic"], [49, 2, 1, "", "export"], [49, 2, 1, "", "get_hparam"], [49, 2, 1, "", "is_configurable"], [49, 2, 1, "", "is_dynamic"], [49, 2, 1, "", "named_dynamic_modules"], [49, 2, 1, "", "named_hparams"], [49, 2, 1, "", "select"], [49, 2, 1, "", "size"]], "modelopt.torch.opt.hparam": [[50, 1, 1, "", "Hparam"]], "modelopt.torch.opt.hparam.Hparam": [[50, 5, 1, "", "ActiveSlice"], [50, 5, 1, "", "Importance"], [50, 5, 1, "", "ImportanceEstimator"], [50, 2, 1, "", "__init__"], [50, 3, 1, "", "active"], [50, 3, 1, "", "active_slice"], [50, 3, 1, "", "choices"], [50, 2, 1, "", "enforce_order"], [50, 3, 1, "", "importance"], [50, 3, 1, "", "is_configurable"], [50, 3, 1, "", "is_sortable"], [50, 3, 1, "", "max"], [50, 3, 1, "", "min"], [50, 3, 1, "", "original"], [50, 2, 1, "", "register_importance"]], "modelopt.torch.opt.searcher": [[53, 1, 1, "", "BaseSearcher"]], "modelopt.torch.opt.searcher.BaseSearcher": [[53, 2, 1, "", "__init__"], [53, 2, 1, "", "after_search"], [53, 2, 1, "", "before_search"], [53, 5, 1, "", "config"], [53, 5, 1, "", "constraints"], [53, 2, 1, "", "construct_forward_loop"], [53, 3, 1, "", "default_search_config"], [53, 3, 1, "", "default_state_dict"], [53, 5, 1, "", "dummy_input"], [53, 2, 1, "", "eval_score"], [53, 5, 1, "", "forward_loop"], [53, 3, 1, "", "has_score"], [53, 2, 1, "", "load_search_checkpoint"], [53, 5, 1, "", "model"], [53, 2, 1, "", "reset_search"], [53, 2, 1, "", "run_search"], [53, 2, 1, "", "sanitize_search_config"], [53, 2, 1, "", "save_search_checkpoint"], [53, 2, 1, "", "search"], [53, 2, 1, "", "state_dict"]], "modelopt.torch.opt.utils": [[54, 4, 1, "", "is_configurable"], [54, 4, 1, "", "is_dynamic"], [54, 4, 1, "", "named_hparams"], [54, 4, 1, "", "search_space_size"]], "modelopt.torch.quantization": [[56, 0, 0, "-", "calib"], [60, 0, 0, "-", "config"], [61, 0, 0, "-", "conversion"], [62, 0, 0, "-", "extensions"], [63, 0, 0, "-", "mode"], [64, 0, 0, "-", "model_calib"], [65, 0, 0, "-", "model_quant"], [66, 0, 0, "-", "nn"], [78, 0, 0, "-", "optim"], [79, 0, 0, "-", "plugins"], [80, 0, 0, "-", "quant_modules"], [81, 0, 0, "-", "tensor_quant"], [82, 0, 0, "-", "utils"]], "modelopt.torch.quantization.calib": [[57, 0, 0, "-", "calibrator"], [58, 0, 0, "-", "histogram"], [59, 0, 0, "-", "max"]], "modelopt.torch.quantization.calib.histogram": [[58, 1, 1, "", "HistogramCalibrator"], [58, 4, 1, "", "calibrate_weights"]], "modelopt.torch.quantization.calib.histogram.HistogramCalibrator": [[58, 2, 1, "", "__init__"], [58, 2, 1, "", "collect"], [58, 2, 1, "", "compute_amax"], [58, 2, 1, "", "reset"]], "modelopt.torch.quantization.calib.max": [[59, 1, 1, "", "MaxCalibrator"]], "modelopt.torch.quantization.calib.max.MaxCalibrator": [[59, 2, 1, "", "__init__"], [59, 3, 1, "", "amaxs"], [59, 2, 1, "", "collect"], [59, 2, 1, "", "compute_amax"], [59, 2, 1, "", "reset"]], "modelopt.torch.quantization.config": [[60, 6, 1, "", "QuantizeConfig"]], "modelopt.torch.quantization.config.QuantizeConfig": [[60, 7, 1, "", "algorithm"], [60, 7, 1, "", "quant_cfg"]], "modelopt.torch.quantization.conversion": [[61, 4, 1, "", "register"], [61, 4, 1, "", "replace_quant_module"], [61, 4, 1, "", "set_quantizer_attribute"], [61, 4, 1, "", "set_quantizer_by_cfg"], [61, 4, 1, "", "unregister"]], "modelopt.torch.quantization.mode": [[63, 1, 1, "", "QuantizeExportModeDescriptor"], [63, 1, 1, "", "QuantizeModeDescriptor"]], "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor": [[63, 3, 1, "", "config_class"], [63, 3, 1, "", "convert"], [63, 3, 1, "", "is_export_mode"], [63, 3, 1, "", "name"], [63, 3, 1, "", "restore"]], "modelopt.torch.quantization.mode.QuantizeModeDescriptor": [[63, 3, 1, "", "config_class"], [63, 3, 1, "", "convert"], [63, 3, 1, "", "export_mode"], [63, 3, 1, "", "name"], [63, 3, 1, "", "next_modes"], [63, 3, 1, "", "restore"], [63, 3, 1, "", "update_for_new_mode"], [63, 3, 1, "", "update_for_save"]], "modelopt.torch.quantization.model_calib": [[64, 4, 1, "", "calibrate"], [64, 4, 1, "", "postprocess_amax"]], "modelopt.torch.quantization.model_quant": [[65, 4, 1, "", "disable_quantizer"], [65, 4, 1, "", "enable_quantizer"], [65, 4, 1, "", "fold_weight"], [65, 4, 1, "", "print_quant_summary"], [65, 4, 1, "", "quantize"]], "modelopt.torch.quantization.nn": [[67, 0, 0, "-", "functional"], [68, 0, 0, "-", "modules"]], "modelopt.torch.quantization.nn.functional": [[67, 1, 1, "", "ClipFunction"]], "modelopt.torch.quantization.nn.functional.ClipFunction": [[67, 2, 1, "", "backward"], [67, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules": [[69, 0, 0, "-", "clip"], [70, 0, 0, "-", "quant_activations"], [71, 0, 0, "-", "quant_batchnorm"], [72, 0, 0, "-", "quant_conv"], [73, 0, 0, "-", "quant_instancenorm"], [74, 0, 0, "-", "quant_linear"], [75, 0, 0, "-", "quant_module"], [76, 0, 0, "-", "quant_pooling"], [77, 0, 0, "-", "tensor_quantizer"]], "modelopt.torch.quantization.nn.modules.clip": [[69, 1, 1, "", "Clip"]], "modelopt.torch.quantization.nn.modules.clip.Clip": [[69, 2, 1, "", "__init__"], [69, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules.quant_conv": [[72, 5, 1, "", "Conv1d"], [72, 5, 1, "", "Conv2d"], [72, 5, 1, "", "Conv3d"], [72, 5, 1, "", "ConvTranspose1d"], [72, 5, 1, "", "ConvTranspose2d"], [72, 5, 1, "", "ConvTranspose3d"], [72, 1, 1, "", "QuantConv1d"], [72, 1, 1, "", "QuantConv2d"], [72, 1, 1, "", "QuantConv3d"], [72, 1, 1, "", "QuantConvTranspose1d"], [72, 1, 1, "", "QuantConvTranspose2d"], [72, 1, 1, "", "QuantConvTranspose3d"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d": [[72, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d": [[72, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d": [[72, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d": [[72, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d": [[72, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d": [[72, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_instancenorm": [[73, 1, 1, "", "QuantInstanceNorm1d"], [73, 1, 1, "", "QuantInstanceNorm2d"], [73, 1, 1, "", "QuantInstanceNorm3d"]], "modelopt.torch.quantization.nn.modules.quant_linear": [[74, 5, 1, "", "Linear"], [74, 1, 1, "", "QuantLinear"]], "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear": [[74, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_module": [[75, 1, 1, "", "QuantInputBase"], [75, 1, 1, "", "QuantLinearConvBase"]], "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase": [[75, 5, 1, "", "default_quant_desc_input"], [75, 5, 1, "", "default_quant_desc_output"], [75, 2, 1, "", "forward"], [75, 5, 1, "", "input_quantizer"], [75, 5, 1, "", "output_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase": [[75, 5, 1, "", "default_quant_desc_weight"], [75, 2, 1, "", "forward"], [75, 2, 1, "", "initialize_quantizer_with_dummy_states"], [75, 2, 1, "", "quantize_weight"], [75, 5, 1, "", "weight_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_pooling": [[76, 5, 1, "", "AdaptiveAvgPool1d"], [76, 5, 1, "", "AdaptiveAvgPool2d"], [76, 5, 1, "", "AdaptiveAvgPool3d"], [76, 5, 1, "", "AvgPool1d"], [76, 5, 1, "", "AvgPool2d"], [76, 5, 1, "", "AvgPool3d"], [76, 5, 1, "", "MaxPool1d"], [76, 5, 1, "", "MaxPool2d"], [76, 5, 1, "", "MaxPool3d"], [76, 1, 1, "", "QuantAdaptiveAvgPool1d"], [76, 1, 1, "", "QuantAdaptiveAvgPool2d"], [76, 1, 1, "", "QuantAdaptiveAvgPool3d"], [76, 1, 1, "", "QuantAvgPool1d"], [76, 1, 1, "", "QuantAvgPool2d"], [76, 1, 1, "", "QuantAvgPool3d"], [76, 1, 1, "", "QuantMaxPool1d"], [76, 1, 1, "", "QuantMaxPool2d"], [76, 1, 1, "", "QuantMaxPool3d"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer": [[77, 1, 1, "", "SequentialQuantizer"], [77, 1, 1, "", "TensorQuantizer"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer": [[77, 2, 1, "", "__init__"], [77, 2, 1, "", "disable"], [77, 2, 1, "", "get_modelopt_state"], [77, 2, 1, "", "replace_sequential_quantizer_with_single_quantizer"], [77, 2, 1, "", "set_from_attribute_dict"], [77, 2, 1, "", "tensor_quantizer_iterator"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer": [[77, 2, 1, "", "__init__"], [77, 3, 1, "", "amax"], [77, 3, 1, "", "axis"], [77, 3, 1, "", "block_sizes"], [77, 2, 1, "", "clean_up_after_set_from_modelopt_state"], [77, 2, 1, "", "disable"], [77, 2, 1, "", "disable_calib"], [77, 2, 1, "", "disable_clip"], [77, 2, 1, "", "disable_quant"], [77, 2, 1, "", "enable"], [77, 2, 1, "", "enable_calib"], [77, 2, 1, "", "enable_clip"], [77, 2, 1, "", "enable_quant"], [77, 2, 1, "", "export_amax"], [77, 2, 1, "", "extra_repr"], [77, 3, 1, "", "fake_quant"], [77, 2, 1, "", "forward"], [77, 2, 1, "", "get_modelopt_state"], [77, 2, 1, "", "init_learn_amax"], [77, 3, 1, "", "is_enabled"], [77, 2, 1, "", "load_calib_amax"], [77, 3, 1, "", "maxbound"], [77, 3, 1, "", "narrow_range"], [77, 3, 1, "", "num_bits"], [77, 3, 1, "", "pre_quant_scale"], [77, 2, 1, "", "reset_amax"], [77, 3, 1, "", "scale"], [77, 2, 1, "", "set_from_attribute_dict"], [77, 2, 1, "", "set_from_modelopt_state"], [77, 3, 1, "", "step_size"], [77, 2, 1, "", "sync_amax_across_distributed_group"], [77, 3, 1, "", "unsigned"]], "modelopt.torch.quantization.optim": [[78, 4, 1, "", "freeze_parameters"], [78, 4, 1, "", "group_parameters"], [78, 4, 1, "", "match_parameters"], [78, 4, 1, "", "quant_weight_inplace"]], "modelopt.torch.quantization.quant_modules": [[80, 4, 1, "", "deactivate"], [80, 4, 1, "", "enable_onnx_export"], [80, 4, 1, "", "initialize"]], "modelopt.torch.quantization.tensor_quant": [[81, 1, 1, "", "FakeAffineTensorQuantFunction"], [81, 1, 1, "", "FakeTensorQuantFunction"], [81, 1, 1, "", "LegacyFakeTensorQuantFunction"], [81, 5, 1, "", "QuantDescriptor"], [81, 1, 1, "", "ScaledE4M3Function"], [81, 1, 1, "", "ScaledQuantDescriptor"], [81, 1, 1, "", "TensorQuantFunction"], [81, 4, 1, "", "scaled_e4m3_abstract"]], "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction": [[81, 2, 1, "", "backward"], [81, 2, 1, "", "forward"]], "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction": [[81, 2, 1, "", "backward"], [81, 2, 1, "", "forward"], [81, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction": [[81, 2, 1, "", "backward"], [81, 2, 1, "", "forward"]], "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function": [[81, 2, 1, "", "backward"], [81, 2, 1, "", "forward"], [81, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor": [[81, 2, 1, "", "__init__"], [81, 3, 1, "", "amax"], [81, 3, 1, "", "axis"], [81, 3, 1, "", "block_sizes"], [81, 3, 1, "", "calib_method"], [81, 2, 1, "", "dict"], [81, 3, 1, "", "fake_quant"], [81, 2, 1, "", "get_block_quant_axes_and_sizes"], [81, 3, 1, "", "learn_amax"], [81, 3, 1, "", "name"], [81, 3, 1, "", "narrow_range"], [81, 3, 1, "", "num_bits"], [81, 3, 1, "", "scale_amax"], [81, 3, 1, "", "unsigned"]], "modelopt.torch.quantization.tensor_quant.TensorQuantFunction": [[81, 2, 1, "", "backward"], [81, 2, 1, "", "forward"], [81, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.utils": [[82, 4, 1, "", "export_torch_mode"], [82, 4, 1, "", "is_quantized"], [82, 4, 1, "", "is_quantized_column_parallel_linear"], [82, 4, 1, "", "is_quantized_layer_with_weight"], [82, 4, 1, "", "is_quantized_row_parallel_linear"], [82, 4, 1, "", "is_torch_library_supported"], [82, 4, 1, "", "reduce_amax"], [82, 4, 1, "", "replace_function"]], "modelopt.torch.sparsity": [[84, 0, 0, "-", "config"], [85, 0, 0, "-", "magnitude"], [86, 0, 0, "-", "mode"], [87, 0, 0, "-", "module"], [88, 0, 0, "-", "plugins"], [89, 0, 0, "-", "searcher"], [90, 0, 0, "-", "sparsegpt"], [91, 0, 0, "-", "sparsification"]], "modelopt.torch.sparsity.config": [[84, 6, 1, "", "ExportSparseConfig"], [84, 6, 1, "", "SparseGPTConfig"], [84, 6, 1, "", "SparseMagnitudeConfig"]], "modelopt.torch.sparsity.config.SparseGPTConfig": [[84, 7, 1, "", "nn_conv2d"], [84, 7, 1, "", "nn_linear"]], "modelopt.torch.sparsity.config.SparseMagnitudeConfig": [[84, 7, 1, "", "nn_conv2d"], [84, 7, 1, "", "nn_linear"]], "modelopt.torch.sparsity.magnitude": [[85, 1, 1, "", "MagnitudeSearcher"], [85, 4, 1, "", "compute_valid_1d_patterns"], [85, 4, 1, "", "create_asp_mask"], [85, 4, 1, "", "fill"], [85, 4, 1, "", "get_nmprune_info"], [85, 4, 1, "", "m4n2_1d"], [85, 4, 1, "", "mn_1d_best"], [85, 4, 1, "", "reshape_1d"]], "modelopt.torch.sparsity.mode": [[86, 1, 1, "", "ExportSparseModeDescriptor"], [86, 1, 1, "", "SparseGPTModeDescriptor"], [86, 1, 1, "", "SparseMagnitudeModeDescriptor"], [86, 4, 1, "", "convert_sparse_model"], [86, 4, 1, "", "export_sparse"], [86, 4, 1, "", "restore_export_sparse"], [86, 4, 1, "", "restore_sparse_model"], [86, 4, 1, "", "update_sparse_metadata"]], "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor": [[86, 3, 1, "", "config_class"], [86, 3, 1, "", "convert"], [86, 3, 1, "", "is_export_mode"], [86, 3, 1, "", "name"], [86, 3, 1, "", "restore"]], "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor": [[86, 3, 1, "", "config_class"], [86, 3, 1, "", "name"], [86, 3, 1, "", "search_algorithm"]], "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor": [[86, 3, 1, "", "config_class"], [86, 3, 1, "", "convert"], [86, 3, 1, "", "export_mode"], [86, 3, 1, "", "name"], [86, 3, 1, "", "next_modes"], [86, 3, 1, "", "restore"], [86, 3, 1, "", "search_algorithm"], [86, 3, 1, "", "update_for_new_mode"], [86, 3, 1, "", "update_for_save"]], "modelopt.torch.sparsity.module": [[87, 1, 1, "", "SparseModule"]], "modelopt.torch.sparsity.module.SparseModule": [[87, 2, 1, "", "modify"], [87, 2, 1, "", "set_mask"]], "modelopt.torch.sparsity.searcher": [[89, 1, 1, "", "BaseSparseSearcher"]], "modelopt.torch.sparsity.searcher.BaseSparseSearcher": [[89, 3, 1, "", "default_search_config"], [89, 3, 1, "", "default_state_dict"], [89, 2, 1, "", "run_search"], [89, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.sparsity.sparsegpt": [[90, 1, 1, "", "SparseGPTSearcher"], [90, 4, 1, "", "create_sgpt_mask"], [90, 4, 1, "", "invert"], [90, 4, 1, "", "prepare"]], "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher": [[90, 2, 1, "", "after_search"], [90, 2, 1, "", "before_search"], [90, 3, 1, "", "default_search_config"]], "modelopt.torch.sparsity.sparsification": [[91, 4, 1, "", "export"], [91, 4, 1, "", "sparsify"]], "modelopt.torch.utils": [[93, 0, 0, "-", "cpp_extension"], [94, 0, 0, "-", "dataset_utils"], [95, 0, 0, "-", "distributed"], [96, 0, 0, "-", "graph"], [97, 0, 0, "-", "list"], [98, 0, 0, "-", "logging"], [99, 0, 0, "-", "network"], [100, 0, 0, "-", "perf"], [101, 0, 0, "-", "random"], [102, 0, 0, "-", "tensor"]], "modelopt.torch.utils.cpp_extension": [[93, 4, 1, "", "load_cpp_extension"]], "modelopt.torch.utils.dataset_utils": [[94, 4, 1, "", "create_forward_loop"], [94, 4, 1, "", "get_dataset_dataloader"]], "modelopt.torch.utils.distributed": [[95, 4, 1, "", "backend"], [95, 4, 1, "", "barrier"], [95, 4, 1, "", "get_data_parallel_group"], [95, 4, 1, "", "get_tensor_parallel_group"], [95, 4, 1, "", "is_master"], [95, 4, 1, "", "rank"], [95, 4, 1, "", "set_data_parallel_group"], [95, 4, 1, "", "set_tensor_parallel_group"], [95, 4, 1, "", "size"]], "modelopt.torch.utils.graph": [[96, 4, 1, "", "match"]], "modelopt.torch.utils.list": [[97, 4, 1, "", "list_closest_to_median"], [97, 4, 1, "", "stats"], [97, 4, 1, "", "val2list"], [97, 4, 1, "", "val2tuple"]], "modelopt.torch.utils.logging": [[98, 8, 1, "", "DeprecatedError"], [98, 4, 1, "", "no_stdout"], [98, 4, 1, "", "num2hrb"], [98, 4, 1, "", "print_rank_0"]], "modelopt.torch.utils.network": [[99, 4, 1, "", "compare_dict"], [99, 4, 1, "", "get_model_attributes"], [99, 4, 1, "", "get_module_device"], [99, 4, 1, "", "get_same_padding"], [99, 4, 1, "", "init_model_from_model_like"], [99, 4, 1, "", "is_channels_last"], [99, 4, 1, "", "is_parallel"], [99, 4, 1, "", "make_divisible"], [99, 4, 1, "", "model_to"], [99, 4, 1, "", "param_num"], [99, 4, 1, "", "param_num_from_forward"], [99, 4, 1, "", "remove_bn"], [99, 4, 1, "", "run_forward_loop"], [99, 4, 1, "", "set_submodule"], [99, 4, 1, "", "standardize_constructor_args"], [99, 4, 1, "", "standardize_model_args"], [99, 4, 1, "", "standardize_model_like_tuple"], [99, 4, 1, "", "standardize_named_model_args"], [99, 4, 1, "", "unwrap_model"], [99, 4, 1, "", "zero_grad"]], "modelopt.torch.utils.perf": [[100, 1, 1, "", "Timer"], [100, 4, 1, "", "clear_cuda_cache"], [100, 4, 1, "", "get_cuda_memory_stats"], [100, 4, 1, "", "report_memory"]], "modelopt.torch.utils.perf.Timer": [[100, 2, 1, "", "__init__"], [100, 2, 1, "", "start"], [100, 2, 1, "", "stop"]], "modelopt.torch.utils.random": [[101, 4, 1, "", "centroid"], [101, 4, 1, "", "choice"], [101, 4, 1, "", "original"], [101, 4, 1, "", "random"], [101, 4, 1, "", "sample"], [101, 4, 1, "", "shuffle"]], "modelopt.torch.utils.tensor": [[102, 4, 1, "", "numpy_to_torch"], [102, 4, 1, "", "torch_detach"], [102, 4, 1, "", "torch_to"], [102, 4, 1, "", "torch_to_numpy"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:function", "5": "py:attribute", "6": "py:pydantic_model", "7": "py:pydantic_field", "8": "py:exception"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "function", "Python function"], "5": ["py", "attribute", "Python attribute"], "6": ["py", "pydantic_model", "Python model"], "7": ["py", "pydantic_field", "Python field"], "8": ["py", "exception", "Python exception"]}, "titleterms": {"tensorrt": [0, 2], "llm": [0, 16], "deploy": [0, 4, 12], "export": [0, 36], "quantiz": [0, 2, 4, 6, 8, 9, 10, 11, 22, 33, 55, 60], "model": [0, 2, 3, 4, 5, 7, 10, 11, 12, 13], "support": [0, 12], "matrix": 0, "checkpoint": 0, "convert": 0, "all": 1, "modelopt": [1, 12, 14], "exampl": [1, 12], "overview": 2, "nvidia": 2, "optim": [2, 3, 12, 13, 78], "techniqu": 2, "sparsiti": [2, 5, 7, 83], "instal": 3, "system": 3, "requir": [3, 10], "check": 3, "quick": [4, 5], "start": [4, 5, 12], "ptq": [4, 10, 11], "pytorch": [4, 5, 11], "post": [5, 7, 10, 11], "train": [5, 7, 8, 10, 11], "sparsif": [5, 7, 91], "pt": 5, "introduct": 7, "save": 7, "restor": 7, "spars": 7, "concept": [7, 8], "structur": 7, "unstructur": 7, "n": 7, "m": 7, "algorithm": [7, 8], "basic": 8, "precis": 8, "format": [8, 60], "scale": 8, "factor": 8, "block": 8, "calibr": [8, 10, 57], "awar": [8, 11], "qat": [8, 11], "more": 8, "read": 8, "best": 9, "practic": 9, "choos": 9, "right": 9, "method": 9, "onnx": [10, 20], "beta": 10, "appli": [10, 11], "prepar": 10, "dataset": 10, "call": 10, "function": [10, 67], "deploi": [10, 15], "compar": 10, "perform": 10, "store": 11, "load": 11, "advanc": 11, "topic": 11, "tensorquant": 11, "custom": 11, "config": [11, 47, 60, 84], "modul": [11, 68, 87], "placement": 11, "fast": 11, "evalu": 11, "welcom": 12, "document": 12, "get": 12, "guid": 12, "refer": 12, "changelog": 13, "0": 13, "11": 13, "2024": 13, "05": 13, "07": 13, "api": 14, "gener": 17, "model_config_trt": 18, "nemo_util": 19, "op_typ": 21, "calib_util": 23, "graph_util": 24, "gs_patch": 25, "int4": 26, "oper": 27, "ort_patch": 28, "ort_util": 29, "partit": 30, "qdq_util": 31, "quant_util": 32, "util": [34, 54, 82, 92], "torch": 35, "distribut": [37, 95], "layer_util": 38, "model_config": 39, "model_config_export": 40, "model_config_util": 41, "postprocess": 42, "scaling_factor_util": 43, "tensorrt_llm_util": 44, "transformer_engin": 45, "opt": 46, "convers": [48, 61], "dynam": 49, "hparam": 50, "mode": [51, 63, 86], "plugin": [52, 79, 88], "searcher": [53, 89], "calib": 56, "histogram": 58, "max": 59, "extens": 62, "model_calib": 64, "model_qu": 65, "nn": 66, "clip": 69, "quant_activ": 70, "quant_batchnorm": 71, "quant_conv": 72, "quant_instancenorm": 73, "quant_linear": 74, "quant_modul": [75, 80], "quant_pool": 76, "tensor_quant": 77, "tensor_qu": 81, "magnitud": 85, "sparsegpt": 90, "cpp_extens": 93, "dataset_util": 94, "graph": 96, "list": 97, "log": 98, "network": 99, "perf": 100, "random": 101, "tensor": 102, "contact": 103, "u": 103, "faq": 104, "1": 104, "potenti": 104, "memori": 104, "leak": 104, "fsdp": 104, "use_orig_param": 104, "true": 104}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 60}, "alltitles": {"TensorRT-LLM Deployment": [[0, "tensorrt-llm-deployment"]], "Export Quantized Model": [[0, "export-quantized-model"]], "Model support matrix for the TensorRT-LLM checkpoint export": [[0, "id1"]], "Convert to TensorRT-LLM": [[0, "convert-to-tensorrt-llm"]], "All ModelOpt Examples": [[1, "all-modelopt-examples"]], "Overview": [[2, "overview"]], "NVIDIA TensorRT Model Optimizer": [[2, "nvidia-tensorrt-model-optimizer"]], "Techniques": [[2, "techniques"]], "Quantization": [[2, "quantization"], [4, "quantization"], [6, "quantization"]], "Sparsity": [[2, "sparsity"], [5, "sparsity"], [7, "sparsity"]], "Installation": [[3, "installation"]], "System requirements": [[3, "system-requirements"]], "Install Model Optimizer": [[3, "install-model-optimizer"]], "Check installation": [[3, "check-installation"]], "Quick Start: Quantization": [[4, "quick-start-quantization"]], "PTQ for PyTorch models": [[4, "ptq-for-pytorch-models"]], "Deployment": [[4, "deployment"], [12, null]], "Quick Start: Sparsity": [[5, "quick-start-sparsity"]], "Post-Training Sparsification (PTS) for PyTorch models": [[5, "post-training-sparsification-pts-for-pytorch-models"]], "Introduction": [[7, "introduction"]], "Post-Training Sparsification": [[7, "post-training-sparsification"]], "Save and restore the sparse model": [[7, "save-and-restore-the-sparse-model"]], "Sparsity Concepts": [[7, "sparsity-concepts"]], "Structured and Unstructured Sparsity": [[7, "structured-and-unstructured-sparsity"]], "N:M Sparsity": [[7, "n-m-sparsity"]], "Sparsification algorithm": [[7, "sparsification-algorithm"]], "Basic Concepts": [[8, "basic-concepts"]], "Precision format": [[8, "precision-format"]], "Scaling factor": [[8, "scaling-factor"]], "Block format": [[8, "block-format"]], "Calibration algorithm": [[8, "calibration-algorithm"]], "Quantization-aware training (QAT)": [[8, "quantization-aware-training-qat"]], "More Readings": [[8, "more-readings"]], "Best practices to choose the right quantization methods": [[9, "best-practices-to-choose-the-right-quantization-methods"]], "ONNX Quantization (Beta)": [[10, "onnx-quantization-beta"]], "Requirements": [[10, "requirements"]], "Apply Post Training Quantization (PTQ)": [[10, "apply-post-training-quantization-ptq"], [11, "apply-post-training-quantization-ptq"]], "Prepare calibration dataset": [[10, "prepare-calibration-dataset"]], "Call PTQ function": [[10, "call-ptq-function"]], "Deploy Quantized ONNX Model": [[10, "deploy-quantized-onnx-model"]], "Compare the performance": [[10, "compare-the-performance"]], "PyTorch Quantization": [[11, "pytorch-quantization"]], "Quantization-aware Training (QAT)": [[11, "quantization-aware-training-qat"]], "Storing and loading quantized model": [[11, "storing-and-loading-quantized-model"]], "Advanced Topics": [[11, "advanced-topics"]], "TensorQuantizer": [[11, "tensorquantizer"]], "Customize quantizer config": [[11, "customize-quantizer-config"]], "Custom quantized module and quantizer placement": [[11, "custom-quantized-module-and-quantizer-placement"]], "Fast evaluation": [[11, "fast-evaluation"]], "Welcome to Model Optimizer (ModelOpt) documentation!": [[12, "welcome-to-model-optimizer-modelopt-documentation"]], "Getting Started": [[12, null]], "Optimization Guides": [[12, null]], "Examples": [[12, null]], "Reference": [[12, null]], "Support": [[12, null]], "Model Optimizer Changelog": [[13, "model-optimizer-changelog"]], "0.11 (2024-05-07)": [[13, "id1"]], "modelopt API": [[14, "modelopt-api"]], "deploy": [[15, "deploy"]], "llm": [[16, "llm"]], "generate": [[17, "generate"]], "model_config_trt": [[18, "model-config-trt"]], "nemo_utils": [[19, "nemo-utils"]], "onnx": [[20, "onnx"]], "op_types": [[21, "op-types"]], "quantization": [[22, "quantization"], [55, "quantization"]], "calib_utils": [[23, "calib-utils"]], "graph_utils": [[24, "graph-utils"]], "gs_patching": [[25, "gs-patching"]], "int4": [[26, "int4"]], "operators": [[27, "operators"]], "ort_patching": [[28, "ort-patching"]], "ort_utils": [[29, "ort-utils"]], "partitioning": [[30, "partitioning"]], "qdq_utils": [[31, "qdq-utils"]], "quant_utils": [[32, "quant-utils"]], "quantize": [[33, "quantize"]], "utils": [[34, "utils"], [54, "utils"], [82, "utils"], [92, "utils"]], "torch": [[35, "torch"]], "export": [[36, "export"]], "distribute": [[37, "distribute"]], "layer_utils": [[38, "layer-utils"]], "model_config": [[39, "model-config"]], "model_config_export": [[40, "model-config-export"]], "model_config_utils": [[41, "model-config-utils"]], "postprocess": [[42, "postprocess"]], "scaling_factor_utils": [[43, "scaling-factor-utils"]], "tensorrt_llm_utils": [[44, "tensorrt-llm-utils"]], "transformer_engine": [[45, "transformer-engine"]], "opt": [[46, "opt"]], "config": [[47, "config"], [60, "config"], [84, "config"]], "conversion": [[48, "conversion"], [61, "conversion"]], "dynamic": [[49, "dynamic"]], "hparam": [[50, "hparam"]], "mode": [[51, "mode"], [63, "mode"], [86, "mode"]], "plugins": [[52, "plugins"], [79, "plugins"], [88, "plugins"]], "searcher": [[53, "searcher"], [89, "searcher"]], "calib": [[56, "calib"]], "calibrator": [[57, "calibrator"]], "histogram": [[58, "histogram"]], "max": [[59, "max"]], "Quantization Formats": [[60, "quantization-formats"]], "Quantization Configs": [[60, "quantization-configs"]], "extensions": [[62, "extensions"]], "model_calib": [[64, "model-calib"]], "model_quant": [[65, "model-quant"]], "nn": [[66, "nn"]], "functional": [[67, "functional"]], "modules": [[68, "modules"]], "clip": [[69, "clip"]], "quant_activations": [[70, "quant-activations"]], "quant_batchnorm": [[71, "quant-batchnorm"]], "quant_conv": [[72, "quant-conv"]], "quant_instancenorm": [[73, "quant-instancenorm"]], "quant_linear": [[74, "quant-linear"]], "quant_module": [[75, "quant-module"]], "quant_pooling": [[76, "quant-pooling"]], "tensor_quantizer": [[77, "tensor-quantizer"]], "optim": [[78, "optim"]], "quant_modules": [[80, "quant-modules"]], "tensor_quant": [[81, "tensor-quant"]], "sparsity": [[83, "sparsity"]], "magnitude": [[85, "magnitude"]], "module": [[87, "module"]], "sparsegpt": [[90, "sparsegpt"]], "sparsification": [[91, "sparsification"]], "cpp_extension": [[93, "cpp-extension"]], "dataset_utils": [[94, "dataset-utils"]], "distributed": [[95, "distributed"]], "graph": [[96, "graph"]], "list": [[97, "list"]], "logging": [[98, "logging"]], "network": [[99, "network"]], "perf": [[100, "perf"]], "random": [[101, "random"]], "tensor": [[102, "tensor"]], "Contact us": [[103, "contact-us"]], "FAQs": [[104, "faqs"]], "1. Potential memory leak for FSDP with use_orig_params=True": [[104, "potential-memory-leak-for-fsdp-with-use-orig-params-true"]]}, "indexentries": {"modelopt.deploy": [[15, "module-modelopt.deploy"]], "module": [[15, "module-modelopt.deploy"], [16, "module-modelopt.deploy.llm"], [17, "module-modelopt.deploy.llm.generate"], [18, "module-modelopt.deploy.llm.model_config_trt"], [19, "module-modelopt.deploy.llm.nemo_utils"], [20, "module-modelopt.onnx"], [21, "module-modelopt.onnx.op_types"], [22, "module-modelopt.onnx.quantization"], [23, "module-modelopt.onnx.quantization.calib_utils"], [24, "module-modelopt.onnx.quantization.graph_utils"], [25, "module-modelopt.onnx.quantization.gs_patching"], [26, "module-modelopt.onnx.quantization.int4"], [27, "module-modelopt.onnx.quantization.operators"], [28, "module-modelopt.onnx.quantization.ort_patching"], [29, "module-modelopt.onnx.quantization.ort_utils"], [30, "module-modelopt.onnx.quantization.partitioning"], [31, "module-modelopt.onnx.quantization.qdq_utils"], [32, "module-modelopt.onnx.quantization.quant_utils"], [33, "module-modelopt.onnx.quantization.quantize"], [34, "module-modelopt.onnx.utils"], [35, "module-modelopt.torch"], [36, "module-modelopt.torch.export"], [37, "module-modelopt.torch.export.distribute"], [38, "module-modelopt.torch.export.layer_utils"], [39, "module-modelopt.torch.export.model_config"], [40, "module-modelopt.torch.export.model_config_export"], [41, "module-modelopt.torch.export.model_config_utils"], [42, "module-modelopt.torch.export.postprocess"], [43, "module-modelopt.torch.export.scaling_factor_utils"], [44, "module-modelopt.torch.export.tensorrt_llm_utils"], [45, "module-modelopt.torch.export.transformer_engine"], [46, "module-modelopt.torch.opt"], [47, "module-modelopt.torch.opt.config"], [48, "module-modelopt.torch.opt.conversion"], [49, "module-modelopt.torch.opt.dynamic"], [50, "module-modelopt.torch.opt.hparam"], [51, "module-modelopt.torch.opt.mode"], [52, "module-modelopt.torch.opt.plugins"], [53, "module-modelopt.torch.opt.searcher"], [54, "module-modelopt.torch.opt.utils"], [55, "module-modelopt.torch.quantization"], [56, "module-modelopt.torch.quantization.calib"], [57, "module-modelopt.torch.quantization.calib.calibrator"], [58, "module-modelopt.torch.quantization.calib.histogram"], [59, "module-modelopt.torch.quantization.calib.max"], [60, "module-modelopt.torch.quantization.config"], [61, "module-modelopt.torch.quantization.conversion"], [62, "module-modelopt.torch.quantization.extensions"], [63, "module-modelopt.torch.quantization.mode"], [64, "module-modelopt.torch.quantization.model_calib"], [65, "module-modelopt.torch.quantization.model_quant"], [66, "module-modelopt.torch.quantization.nn"], [67, "module-modelopt.torch.quantization.nn.functional"], [68, "module-modelopt.torch.quantization.nn.modules"], [69, "module-modelopt.torch.quantization.nn.modules.clip"], [70, "module-modelopt.torch.quantization.nn.modules.quant_activations"], [71, "module-modelopt.torch.quantization.nn.modules.quant_batchnorm"], [72, "module-modelopt.torch.quantization.nn.modules.quant_conv"], [73, "module-modelopt.torch.quantization.nn.modules.quant_instancenorm"], [74, "module-modelopt.torch.quantization.nn.modules.quant_linear"], [75, "module-modelopt.torch.quantization.nn.modules.quant_module"], [76, "module-modelopt.torch.quantization.nn.modules.quant_pooling"], [77, "module-modelopt.torch.quantization.nn.modules.tensor_quantizer"], [78, "module-modelopt.torch.quantization.optim"], [79, "module-modelopt.torch.quantization.plugins"], [80, "module-modelopt.torch.quantization.quant_modules"], [81, "module-modelopt.torch.quantization.tensor_quant"], [82, "module-modelopt.torch.quantization.utils"], [83, "module-modelopt.torch.sparsity"], [84, "module-modelopt.torch.sparsity.config"], [85, "module-modelopt.torch.sparsity.magnitude"], [86, "module-modelopt.torch.sparsity.mode"], [87, "module-modelopt.torch.sparsity.module"], [88, "module-modelopt.torch.sparsity.plugins"], [89, "module-modelopt.torch.sparsity.searcher"], [90, "module-modelopt.torch.sparsity.sparsegpt"], [91, "module-modelopt.torch.sparsity.sparsification"], [92, "module-modelopt.torch.utils"], [93, "module-modelopt.torch.utils.cpp_extension"], [94, "module-modelopt.torch.utils.dataset_utils"], [95, "module-modelopt.torch.utils.distributed"], [96, "module-modelopt.torch.utils.graph"], [97, "module-modelopt.torch.utils.list"], [98, "module-modelopt.torch.utils.logging"], [99, "module-modelopt.torch.utils.network"], [100, "module-modelopt.torch.utils.perf"], [101, "module-modelopt.torch.utils.random"], [102, "module-modelopt.torch.utils.tensor"]], "modelopt.deploy.llm": [[16, "module-modelopt.deploy.llm"]], "llm (class in modelopt.deploy.llm.generate)": [[17, "modelopt.deploy.llm.generate.LLM"]], "__init__() (llm method)": [[17, "modelopt.deploy.llm.generate.LLM.__init__"]], "generate_text() (llm method)": [[17, "modelopt.deploy.llm.generate.LLM.generate_text"]], "max_beam_width (llm property)": [[17, "modelopt.deploy.llm.generate.LLM.max_beam_width"]], "max_input_len (llm property)": [[17, "modelopt.deploy.llm.generate.LLM.max_input_len"]], "modelopt.deploy.llm.generate": [[17, "module-modelopt.deploy.llm.generate"]], "build_tensorrt_llm() (in module modelopt.deploy.llm.model_config_trt)": [[18, "modelopt.deploy.llm.model_config_trt.build_tensorrt_llm"]], "build_tensorrt_llm_rank() (in module modelopt.deploy.llm.model_config_trt)": [[18, "modelopt.deploy.llm.model_config_trt.build_tensorrt_llm_rank"]], "modelopt.deploy.llm.model_config_trt": [[18, "module-modelopt.deploy.llm.model_config_trt"]], "customsentencepiecetokenizer (class in modelopt.deploy.llm.nemo_utils)": [[19, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer"]], "__init__() (customsentencepiecetokenizer method)": [[19, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.__init__"]], "batch_decode() (customsentencepiecetokenizer method)": [[19, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.batch_decode"]], "batch_encode_plus() (customsentencepiecetokenizer method)": [[19, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.batch_encode_plus"]], "decode() (customsentencepiecetokenizer method)": [[19, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.decode"]], "encode() (customsentencepiecetokenizer method)": [[19, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.encode"]], "eos_token (customsentencepiecetokenizer property)": [[19, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.eos_token"]], "eos_token_id (customsentencepiecetokenizer property)": [[19, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.eos_token_id"]], "get_nemo_tokenizer() (in module modelopt.deploy.llm.nemo_utils)": [[19, "modelopt.deploy.llm.nemo_utils.get_nemo_tokenizer"]], "get_tokenzier() (in module modelopt.deploy.llm.nemo_utils)": [[19, "modelopt.deploy.llm.nemo_utils.get_tokenzier"]], "modelopt.deploy.llm.nemo_utils": [[19, "module-modelopt.deploy.llm.nemo_utils"]], "pad_token (customsentencepiecetokenizer property)": [[19, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.pad_token"]], "pad_token_id (customsentencepiecetokenizer property)": [[19, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.pad_token_id"]], "modelopt.onnx": [[20, "module-modelopt.onnx"]], "get_quantizable_op_types() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.get_quantizable_op_types"]], "is_binary_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_binary_op"]], "is_control_flow_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_control_flow_op"]], "is_conversion_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_conversion_op"]], "is_copy_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_copy_op"]], "is_default_quantizable_op_by_ort() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_default_quantizable_op_by_ort"]], "is_fusible_reduction_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_fusible_reduction_op"]], "is_generator_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_generator_op"]], "is_irregular_mem_access_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_irregular_mem_access_op"]], "is_linear_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_linear_op"]], "is_modifier_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_modifier_op"]], "is_multiclass_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_multiclass_op"]], "is_non_reshape_copy_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_non_reshape_copy_op"]], "is_normalization_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_normalization_op"]], "is_pointwise_or_elementwise_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_pointwise_or_elementwise_op"]], "is_pooling_or_window_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_pooling_or_window_op"]], "is_recurrent_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_recurrent_op"]], "is_selection_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_selection_op"]], "is_sequence_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_sequence_op"]], "is_shape_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_shape_op"]], "is_unary_op() (in module modelopt.onnx.op_types)": [[21, "modelopt.onnx.op_types.is_unary_op"]], "modelopt.onnx.op_types": [[21, "module-modelopt.onnx.op_types"]], "modelopt.onnx.quantization": [[22, "module-modelopt.onnx.quantization"]], "calibrationdataprovider (class in modelopt.onnx.quantization.calib_utils)": [[23, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider"]], "randomdataprovider (class in modelopt.onnx.quantization.calib_utils)": [[23, "modelopt.onnx.quantization.calib_utils.RandomDataProvider"]], "__init__() (calibrationdataprovider method)": [[23, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider.__init__"]], "__init__() (randomdataprovider method)": [[23, "modelopt.onnx.quantization.calib_utils.RandomDataProvider.__init__"]], "get_next() (calibrationdataprovider method)": [[23, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider.get_next"]], "get_next() (randomdataprovider method)": [[23, "modelopt.onnx.quantization.calib_utils.RandomDataProvider.get_next"]], "modelopt.onnx.quantization.calib_utils": [[23, "module-modelopt.onnx.quantization.calib_utils"]], "build_non_residual_input_map() (in module modelopt.onnx.quantization.graph_utils)": [[24, "modelopt.onnx.quantization.graph_utils.build_non_residual_input_map"]], "classify_partition_nodes() (in module modelopt.onnx.quantization.graph_utils)": [[24, "modelopt.onnx.quantization.graph_utils.classify_partition_nodes"]], "filter_quantizable_kgen_heads() (in module modelopt.onnx.quantization.graph_utils)": [[24, "modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads"]], "get_fusible_backbone() (in module modelopt.onnx.quantization.graph_utils)": [[24, "modelopt.onnx.quantization.graph_utils.get_fusible_backbone"]], "has_const_input() (in module modelopt.onnx.quantization.graph_utils)": [[24, "modelopt.onnx.quantization.graph_utils.has_const_input"]], "has_path_type() (in module modelopt.onnx.quantization.graph_utils)": [[24, "modelopt.onnx.quantization.graph_utils.has_path_type"]], "is_const_input() (in module modelopt.onnx.quantization.graph_utils)": [[24, "modelopt.onnx.quantization.graph_utils.is_const_input"]], "modelopt.onnx.quantization.graph_utils": [[24, "module-modelopt.onnx.quantization.graph_utils"]], "print_stat() (in module modelopt.onnx.quantization.graph_utils)": [[24, "modelopt.onnx.quantization.graph_utils.print_stat"]], "remove_partial_input_qdq() (in module modelopt.onnx.quantization.graph_utils)": [[24, "modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq"]], "modelopt.onnx.quantization.gs_patching": [[25, "module-modelopt.onnx.quantization.gs_patching"]], "patch_gs_modules() (in module modelopt.onnx.quantization.gs_patching)": [[25, "modelopt.onnx.quantization.gs_patching.patch_gs_modules"]], "awqcliphelper (class in modelopt.onnx.quantization.int4)": [[26, "modelopt.onnx.quantization.int4.AWQClipHelper"]], "__init__() (awqcliphelper method)": [[26, "modelopt.onnx.quantization.int4.AWQClipHelper.__init__"]], "alpha_step (awqcliphelper attribute)": [[26, "modelopt.onnx.quantization.int4.AWQClipHelper.alpha_step"]], "alphas (awqcliphelper attribute)": [[26, "modelopt.onnx.quantization.int4.AWQClipHelper.alphas"]], "dq_tensor() (in module modelopt.onnx.quantization.int4)": [[26, "modelopt.onnx.quantization.int4.dq_tensor"]], "find_scales() (in module modelopt.onnx.quantization.int4)": [[26, "modelopt.onnx.quantization.int4.find_scales"]], "min_alpha (awqcliphelper attribute)": [[26, "modelopt.onnx.quantization.int4.AWQClipHelper.min_alpha"]], "modelopt.onnx.quantization.int4": [[26, "module-modelopt.onnx.quantization.int4"]], "quant_tensor() (in module modelopt.onnx.quantization.int4)": [[26, "modelopt.onnx.quantization.int4.quant_tensor"]], "quantize_int4() (in module modelopt.onnx.quantization.int4)": [[26, "modelopt.onnx.quantization.int4.quantize_int4"]], "quantize_int4_awq_clip() (in module modelopt.onnx.quantization.int4)": [[26, "modelopt.onnx.quantization.int4.quantize_int4_awq_clip"]], "quantize_int4_rtn() (in module modelopt.onnx.quantization.int4)": [[26, "modelopt.onnx.quantization.int4.quantize_int4_rtn"]], "rtn() (in module modelopt.onnx.quantization.int4)": [[26, "modelopt.onnx.quantization.int4.rtn"]], "update_best_params() (awqcliphelper method)": [[26, "modelopt.onnx.quantization.int4.AWQClipHelper.update_best_params"]], "qdqconvtranspose (class in modelopt.onnx.quantization.operators)": [[27, "modelopt.onnx.quantization.operators.QDQConvTranspose"]], "qdqnormalization (class in modelopt.onnx.quantization.operators)": [[27, "modelopt.onnx.quantization.operators.QDQNormalization"]], "__init__() (qdqconvtranspose method)": [[27, "modelopt.onnx.quantization.operators.QDQConvTranspose.__init__"]], "__init__() (qdqnormalization method)": [[27, "modelopt.onnx.quantization.operators.QDQNormalization.__init__"]], "modelopt.onnx.quantization.operators": [[27, "module-modelopt.onnx.quantization.operators"]], "quantize() (qdqconvtranspose method)": [[27, "modelopt.onnx.quantization.operators.QDQConvTranspose.quantize"]], "quantize() (qdqnormalization method)": [[27, "modelopt.onnx.quantization.operators.QDQNormalization.quantize"]], "modelopt.onnx.quantization.ort_patching": [[28, "module-modelopt.onnx.quantization.ort_patching"]], "patch_ort_modules() (in module modelopt.onnx.quantization.ort_patching)": [[28, "modelopt.onnx.quantization.ort_patching.patch_ort_modules"]], "create_inference_session() (in module modelopt.onnx.quantization.ort_utils)": [[29, "modelopt.onnx.quantization.ort_utils.create_inference_session"]], "modelopt.onnx.quantization.ort_utils": [[29, "module-modelopt.onnx.quantization.ort_utils"]], "find_fusible_partitions() (in module modelopt.onnx.quantization.partitioning)": [[30, "modelopt.onnx.quantization.partitioning.find_fusible_partitions"]], "find_hardcoded_patterns() (in module modelopt.onnx.quantization.partitioning)": [[30, "modelopt.onnx.quantization.partitioning.find_hardcoded_patterns"]], "find_layer_norm_partitions() (in module modelopt.onnx.quantization.partitioning)": [[30, "modelopt.onnx.quantization.partitioning.find_layer_norm_partitions"]], "find_mha_partitions() (in module modelopt.onnx.quantization.partitioning)": [[30, "modelopt.onnx.quantization.partitioning.find_mha_partitions"]], "find_non_quantizable_partitions_from_patterns() (in module modelopt.onnx.quantization.partitioning)": [[30, "modelopt.onnx.quantization.partitioning.find_non_quantizable_partitions_from_patterns"]], "find_quantizable_nodes() (in module modelopt.onnx.quantization.partitioning)": [[30, "modelopt.onnx.quantization.partitioning.find_quantizable_nodes"]], "get_skiped_output_layers() (in module modelopt.onnx.quantization.partitioning)": [[30, "modelopt.onnx.quantization.partitioning.get_skiped_output_layers"]], "modelopt.onnx.quantization.partitioning": [[30, "module-modelopt.onnx.quantization.partitioning"]], "insert_dq_nodes() (in module modelopt.onnx.quantization.qdq_utils)": [[31, "modelopt.onnx.quantization.qdq_utils.insert_dq_nodes"]], "insert_qdq_nodes() (in module modelopt.onnx.quantization.qdq_utils)": [[31, "modelopt.onnx.quantization.qdq_utils.insert_qdq_nodes"]], "make_gs_dequantize_node() (in module modelopt.onnx.quantization.qdq_utils)": [[31, "modelopt.onnx.quantization.qdq_utils.make_gs_dequantize_node"]], "make_gs_dequantize_output() (in module modelopt.onnx.quantization.qdq_utils)": [[31, "modelopt.onnx.quantization.qdq_utils.make_gs_dequantize_output"]], "make_gs_quantize_node() (in module modelopt.onnx.quantization.qdq_utils)": [[31, "modelopt.onnx.quantization.qdq_utils.make_gs_quantize_node"]], "make_gs_quantize_output() (in module modelopt.onnx.quantization.qdq_utils)": [[31, "modelopt.onnx.quantization.qdq_utils.make_gs_quantize_output"]], "make_gs_quantized_weight() (in module modelopt.onnx.quantization.qdq_utils)": [[31, "modelopt.onnx.quantization.qdq_utils.make_gs_quantized_weight"]], "make_gs_scale() (in module modelopt.onnx.quantization.qdq_utils)": [[31, "modelopt.onnx.quantization.qdq_utils.make_gs_scale"]], "make_gs_zp() (in module modelopt.onnx.quantization.qdq_utils)": [[31, "modelopt.onnx.quantization.qdq_utils.make_gs_zp"]], "modelopt.onnx.quantization.qdq_utils": [[31, "module-modelopt.onnx.quantization.qdq_utils"]], "use_trt_qdq_ops() (in module modelopt.onnx.quantization.qdq_utils)": [[31, "modelopt.onnx.quantization.qdq_utils.use_trt_qdq_ops"]], "modelopt.onnx.quantization.quant_utils": [[32, "module-modelopt.onnx.quantization.quant_utils"]], "pack_float32_to_4bit_optimized() (in module modelopt.onnx.quantization.quant_utils)": [[32, "modelopt.onnx.quantization.quant_utils.pack_float32_to_4bit_optimized"]], "modelopt.onnx.quantization.quantize": [[33, "module-modelopt.onnx.quantization.quantize"]], "quantize() (in module modelopt.onnx.quantization.quantize)": [[33, "modelopt.onnx.quantization.quantize.quantize"]], "duplicate_shared_linear_weights() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.duplicate_shared_linear_weights"]], "find_lowest_common_ancestor() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.find_lowest_common_ancestor"]], "gen_random_inputs() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.gen_random_inputs"]], "get_all_input_names() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_all_input_names"]], "get_batch_size() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_batch_size"]], "get_batch_size_from_bytes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_batch_size_from_bytes"]], "get_child_nodes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_child_nodes"]], "get_input_names() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_input_names"]], "get_input_names_from_bytes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_input_names_from_bytes"]], "get_input_shapes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_input_shapes"]], "get_input_shapes_from_bytes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_input_shapes_from_bytes"]], "get_node_names() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_node_names"]], "get_node_names_from_bytes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_node_names_from_bytes"]], "get_output_names() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_output_names"]], "get_output_names_from_bytes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_output_names_from_bytes"]], "get_output_shapes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_output_shapes"]], "get_parent_nodes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_parent_nodes"]], "get_variable_inputs() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.get_variable_inputs"]], "is_valid_onnx_model() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.is_valid_onnx_model"]], "modelopt.onnx.utils": [[34, "module-modelopt.onnx.utils"]], "name_onnx_nodes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.name_onnx_nodes"]], "randomize_weights() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.randomize_weights"]], "randomize_weights_onnx_bytes() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.randomize_weights_onnx_bytes"]], "remove_weights_data() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.remove_weights_data"]], "save_onnx() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.save_onnx"]], "save_onnx_bytes_to_dir() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.save_onnx_bytes_to_dir"]], "validate_batch_size() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.validate_batch_size"]], "validate_onnx() (in module modelopt.onnx.utils)": [[34, "modelopt.onnx.utils.validate_onnx"]], "modelopt.torch": [[35, "module-modelopt.torch"]], "modelopt.torch.export": [[36, "module-modelopt.torch.export"]], "nfsworkspace (class in modelopt.torch.export.distribute)": [[37, "modelopt.torch.export.distribute.NFSWorkspace"]], "__init__() (nfsworkspace method)": [[37, "modelopt.torch.export.distribute.NFSWorkspace.__init__"]], "barrier() (in module modelopt.torch.export.distribute)": [[37, "modelopt.torch.export.distribute.barrier"]], "get_configs_parallel() (in module modelopt.torch.export.distribute)": [[37, "modelopt.torch.export.distribute.get_configs_parallel"]], "get_group() (in module modelopt.torch.export.distribute)": [[37, "modelopt.torch.export.distribute.get_group"]], "get_rank() (in module modelopt.torch.export.distribute)": [[37, "modelopt.torch.export.distribute.get_rank"]], "get_tensors_parallel() (in module modelopt.torch.export.distribute)": [[37, "modelopt.torch.export.distribute.get_tensors_parallel"]], "get_world_size() (in module modelopt.torch.export.distribute)": [[37, "modelopt.torch.export.distribute.get_world_size"]], "is_initialized (nfsworkspace property)": [[37, "modelopt.torch.export.distribute.NFSWorkspace.is_initialized"]], "modelopt.torch.export.distribute": [[37, "module-modelopt.torch.export.distribute"]], "read_configs_and_weights_from_rank() (nfsworkspace method)": [[37, "modelopt.torch.export.distribute.NFSWorkspace.read_configs_and_weights_from_rank"]], "write_configs_and_weights() (nfsworkspace method)": [[37, "modelopt.torch.export.distribute.NFSWorkspace.write_configs_and_weights"]], "build_attention_config() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.build_attention_config"]], "build_decoder_config() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.build_decoder_config"]], "build_embedding_config() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.build_embedding_config"]], "build_layernorm_config() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.build_layernorm_config"]], "build_linear_config() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.build_linear_config"]], "build_mlp_config() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.build_mlp_config"]], "build_moe_config() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.build_moe_config"]], "build_qkv() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.build_qkv"]], "build_stacked_experts() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.build_stacked_experts"]], "check_model_compatibility() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.check_model_compatibility"]], "get_activation_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.get_activation_scaling_factor"]], "get_kv_cache_dtype() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.get_kv_cache_dtype"]], "get_kv_cache_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.get_kv_cache_scaling_factor"]], "get_prequant_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.get_prequant_scaling_factor"]], "get_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.get_scaling_factor"]], "get_transformer_layers() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.get_transformer_layers"]], "get_weight_block_size() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.get_weight_block_size"]], "get_weight_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.get_weight_scaling_factor"]], "get_weight_scaling_factor_2() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.get_weight_scaling_factor_2"]], "is_attention() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.is_attention"]], "is_decoder_list() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.is_decoder_list"]], "is_embedding() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.is_embedding"]], "is_layernorm() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.is_layernorm"]], "is_linear() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.is_linear"]], "is_mlp() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.is_mlp"]], "is_moe() (in module modelopt.torch.export.layer_utils)": [[38, "modelopt.torch.export.layer_utils.is_moe"]], "modelopt.torch.export.layer_utils": [[38, "module-modelopt.torch.export.layer_utils"]], "attentionconfig (class in modelopt.torch.export.model_config)": [[39, "modelopt.torch.export.model_config.AttentionConfig"]], "decoderlayerconfig (class in modelopt.torch.export.model_config)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig"]], "embeddingconfig (class in modelopt.torch.export.model_config)": [[39, "modelopt.torch.export.model_config.EmbeddingConfig"]], "expertconfig (class in modelopt.torch.export.model_config)": [[39, "modelopt.torch.export.model_config.ExpertConfig"]], "layernormconfig (class in modelopt.torch.export.model_config)": [[39, "modelopt.torch.export.model_config.LayernormConfig"]], "linearconfig (class in modelopt.torch.export.model_config)": [[39, "modelopt.torch.export.model_config.LinearConfig"]], "mlpconfig (class in modelopt.torch.export.model_config)": [[39, "modelopt.torch.export.model_config.MLPConfig"]], "moeconfig (class in modelopt.torch.export.model_config)": [[39, "modelopt.torch.export.model_config.MOEConfig"]], "modelconfig (class in modelopt.torch.export.model_config)": [[39, "modelopt.torch.export.model_config.ModelConfig"]], "qkvconfig (class in modelopt.torch.export.model_config)": [[39, "modelopt.torch.export.model_config.QKVConfig"]], "__init__() (attentionconfig method)": [[39, "modelopt.torch.export.model_config.AttentionConfig.__init__"]], "__init__() (decoderlayerconfig method)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.__init__"]], "__init__() (embeddingconfig method)": [[39, "modelopt.torch.export.model_config.EmbeddingConfig.__init__"]], "__init__() (expertconfig method)": [[39, "modelopt.torch.export.model_config.ExpertConfig.__init__"]], "__init__() (layernormconfig method)": [[39, "modelopt.torch.export.model_config.LayernormConfig.__init__"]], "__init__() (linearconfig method)": [[39, "modelopt.torch.export.model_config.LinearConfig.__init__"]], "__init__() (mlpconfig method)": [[39, "modelopt.torch.export.model_config.MLPConfig.__init__"]], "__init__() (moeconfig method)": [[39, "modelopt.torch.export.model_config.MOEConfig.__init__"]], "__init__() (modelconfig method)": [[39, "modelopt.torch.export.model_config.ModelConfig.__init__"]], "__init__() (qkvconfig method)": [[39, "modelopt.torch.export.model_config.QKVConfig.__init__"]], "activation_scaling_factor (linearconfig attribute)": [[39, "modelopt.torch.export.model_config.LinearConfig.activation_scaling_factor"]], "activation_scaling_factor (qkvconfig property)": [[39, "modelopt.torch.export.model_config.QKVConfig.activation_scaling_factor"]], "alibi_bias_max (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.alibi_bias_max"]], "apply_residual_connection_post_layernorm (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.apply_residual_connection_post_layernorm"]], "attention (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.attention"]], "attention_head_size (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.attention_head_size"]], "awq_block_size (linearconfig attribute)": [[39, "modelopt.torch.export.model_config.LinearConfig.awq_block_size"]], "awq_block_size (qkvconfig property)": [[39, "modelopt.torch.export.model_config.QKVConfig.awq_block_size"]], "bias (layernormconfig attribute)": [[39, "modelopt.torch.export.model_config.LayernormConfig.bias"]], "bias (linearconfig attribute)": [[39, "modelopt.torch.export.model_config.LinearConfig.bias"]], "bias (qkvconfig property)": [[39, "modelopt.torch.export.model_config.QKVConfig.bias"]], "clip_qkv (attentionconfig attribute)": [[39, "modelopt.torch.export.model_config.AttentionConfig.clip_qkv"]], "decoder_type (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.decoder_type"]], "dense (attentionconfig attribute)": [[39, "modelopt.torch.export.model_config.AttentionConfig.dense"]], "dtype (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.dtype"]], "eps (layernormconfig attribute)": [[39, "modelopt.torch.export.model_config.LayernormConfig.eps"]], "experts (moeconfig attribute)": [[39, "modelopt.torch.export.model_config.MOEConfig.experts"]], "fc (expertconfig attribute)": [[39, "modelopt.torch.export.model_config.ExpertConfig.fc"]], "fc (mlpconfig attribute)": [[39, "modelopt.torch.export.model_config.MLPConfig.fc"]], "fc (moeconfig property)": [[39, "modelopt.torch.export.model_config.MOEConfig.fc"]], "ffn_hidden_size_local (decoderlayerconfig property)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.ffn_hidden_size_local"]], "gate (mlpconfig attribute)": [[39, "modelopt.torch.export.model_config.MLPConfig.gate"]], "hidden_act (mlpconfig attribute)": [[39, "modelopt.torch.export.model_config.MLPConfig.hidden_act"]], "hidden_act (moeconfig attribute)": [[39, "modelopt.torch.export.model_config.MOEConfig.hidden_act"]], "hidden_act (modelconfig property)": [[39, "modelopt.torch.export.model_config.ModelConfig.hidden_act"]], "hidden_size (decoderlayerconfig property)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.hidden_size"]], "hidden_size (embeddingconfig property)": [[39, "modelopt.torch.export.model_config.EmbeddingConfig.hidden_size"]], "hidden_size (modelconfig property)": [[39, "modelopt.torch.export.model_config.ModelConfig.hidden_size"]], "input_layernorm (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.input_layernorm"]], "k (qkvconfig attribute)": [[39, "modelopt.torch.export.model_config.QKVConfig.k"]], "kv_cache_dtype (attentionconfig attribute)": [[39, "modelopt.torch.export.model_config.AttentionConfig.kv_cache_dtype"]], "kv_cache_scaling_factor (attentionconfig attribute)": [[39, "modelopt.torch.export.model_config.AttentionConfig.kv_cache_scaling_factor"]], "layernorm_type (layernormconfig attribute)": [[39, "modelopt.torch.export.model_config.LayernormConfig.layernorm_type"]], "layers (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.layers"]], "linear_type (linearconfig attribute)": [[39, "modelopt.torch.export.model_config.LinearConfig.linear_type"]], "lm_head (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.lm_head"]], "ln_embed (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.ln_embed"]], "ln_f (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.ln_f"]], "local_vocab_size (embeddingconfig property)": [[39, "modelopt.torch.export.model_config.EmbeddingConfig.local_vocab_size"]], "max_position_embeddings (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.max_position_embeddings"]], "max_position_embeddings (modelconfig property)": [[39, "modelopt.torch.export.model_config.ModelConfig.max_position_embeddings"]], "merged_fc1_gate (mlpconfig attribute)": [[39, "modelopt.torch.export.model_config.MLPConfig.merged_fc1_gate"]], "mlp (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.mlp"]], "mlp_layernorm (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.mlp_layernorm"]], "model_name (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.model_name"]], "modelopt.torch.export.model_config": [[39, "module-modelopt.torch.export.model_config"]], "moe_num_experts (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_num_experts"]], "moe_renorm_mode (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_renorm_mode"]], "moe_top_k (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_top_k"]], "moe_tp_mode (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_tp_mode"]], "new_decoder_architecture (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.new_decoder_architecture"]], "num_attention_heads (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.num_attention_heads"]], "num_attention_heads (modelconfig property)": [[39, "modelopt.torch.export.model_config.ModelConfig.num_attention_heads"]], "num_kv_heads (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.num_kv_heads"]], "num_kv_heads (modelconfig property)": [[39, "modelopt.torch.export.model_config.ModelConfig.num_kv_heads"]], "parallel_attention (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.parallel_attention"]], "partial_rotary_factor (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.partial_rotary_factor"]], "pipeline_parallel (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.pipeline_parallel"]], "position_embedding (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.position_embedding"]], "post_layernorm (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.post_layernorm"]], "prequant_scaling_factor (linearconfig attribute)": [[39, "modelopt.torch.export.model_config.LinearConfig.prequant_scaling_factor"]], "prequant_scaling_factor (qkvconfig property)": [[39, "modelopt.torch.export.model_config.QKVConfig.prequant_scaling_factor"]], "proj (expertconfig attribute)": [[39, "modelopt.torch.export.model_config.ExpertConfig.proj"]], "proj (mlpconfig attribute)": [[39, "modelopt.torch.export.model_config.MLPConfig.proj"]], "q (qkvconfig attribute)": [[39, "modelopt.torch.export.model_config.QKVConfig.q"]], "qkv (attentionconfig attribute)": [[39, "modelopt.torch.export.model_config.AttentionConfig.qkv"]], "quantization (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.quantization"]], "quantization (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.quantization"]], "rank (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.rank"]], "residual_layernorm (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.residual_layernorm"]], "residual_mlp (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.residual_mlp"]], "rope_ratio (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.rope_ratio"]], "rotary_base (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.rotary_base"]], "rotary_dim (attentionconfig attribute)": [[39, "modelopt.torch.export.model_config.AttentionConfig.rotary_dim"]], "rotary_pct (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.rotary_pct"]], "router (moeconfig attribute)": [[39, "modelopt.torch.export.model_config.MOEConfig.router"]], "seq_length (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.seq_length"]], "share_embedding_table (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.share_embedding_table"]], "tensor_parallel (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.tensor_parallel"]], "use_alibi (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.use_alibi"]], "use_cache (decoderlayerconfig attribute)": [[39, "modelopt.torch.export.model_config.DecoderLayerConfig.use_cache"]], "v (qkvconfig attribute)": [[39, "modelopt.torch.export.model_config.QKVConfig.v"]], "version (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.version"]], "vocab_embedding (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.vocab_embedding"]], "vocab_size (modelconfig attribute)": [[39, "modelopt.torch.export.model_config.ModelConfig.vocab_size"]], "vocab_size_padded (modelconfig property)": [[39, "modelopt.torch.export.model_config.ModelConfig.vocab_size_padded"]], "weight (embeddingconfig attribute)": [[39, "modelopt.torch.export.model_config.EmbeddingConfig.weight"]], "weight (layernormconfig attribute)": [[39, "modelopt.torch.export.model_config.LayernormConfig.weight"]], "weight (linearconfig attribute)": [[39, "modelopt.torch.export.model_config.LinearConfig.weight"]], "weight (qkvconfig property)": [[39, "modelopt.torch.export.model_config.QKVConfig.weight"]], "weights_scaling_factor (linearconfig attribute)": [[39, "modelopt.torch.export.model_config.LinearConfig.weights_scaling_factor"]], "weights_scaling_factor (qkvconfig property)": [[39, "modelopt.torch.export.model_config.QKVConfig.weights_scaling_factor"]], "weights_scaling_factor_2 (linearconfig attribute)": [[39, "modelopt.torch.export.model_config.LinearConfig.weights_scaling_factor_2"]], "weights_scaling_factor_2 (qkvconfig property)": [[39, "modelopt.torch.export.model_config.QKVConfig.weights_scaling_factor_2"]], "export_tensorrt_llm_checkpoint() (in module modelopt.torch.export.model_config_export)": [[40, "modelopt.torch.export.model_config_export.export_tensorrt_llm_checkpoint"]], "modelopt.torch.export.model_config_export": [[40, "module-modelopt.torch.export.model_config_export"]], "torch_to_tensorrt_llm_checkpoint() (in module modelopt.torch.export.model_config_export)": [[40, "modelopt.torch.export.model_config_export.torch_to_tensorrt_llm_checkpoint"]], "from_quantized_weight() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.from_quantized_weight"]], "merge_fc1_gate() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.merge_fc1_gate"]], "merge_qkv() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.merge_qkv"]], "model_config_from_dict() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.model_config_from_dict"]], "model_config_to_dict() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.model_config_to_dict"]], "modelopt.torch.export.model_config_utils": [[41, "module-modelopt.torch.export.model_config_utils"]], "naive_quantization() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.naive_quantization"]], "pack_linear_weights() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.pack_linear_weights"]], "pad_weights() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.pad_weights"]], "restore_model_config() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.restore_model_config"]], "split_config_and_weights() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.split_config_and_weights"]], "to_quantized_weight() (in module modelopt.torch.export.model_config_utils)": [[41, "modelopt.torch.export.model_config_utils.to_quantized_weight"]], "check_weight_shape_valid() (in module modelopt.torch.export.postprocess)": [[42, "modelopt.torch.export.postprocess.check_weight_shape_valid"]], "modelopt.torch.export.postprocess": [[42, "module-modelopt.torch.export.postprocess"]], "pad_embedding_lm_head() (in module modelopt.torch.export.postprocess)": [[42, "modelopt.torch.export.postprocess.pad_embedding_lm_head"]], "postprocess_model_config() (in module modelopt.torch.export.postprocess)": [[42, "modelopt.torch.export.postprocess.postprocess_model_config"]], "postprocess_tensors() (in module modelopt.torch.export.postprocess)": [[42, "modelopt.torch.export.postprocess.postprocess_tensors"]], "get_weights_scaling_factor() (in module modelopt.torch.export.scaling_factor_utils)": [[43, "modelopt.torch.export.scaling_factor_utils.get_weights_scaling_factor"]], "modelopt.torch.export.scaling_factor_utils": [[43, "module-modelopt.torch.export.scaling_factor_utils"]], "resmooth_and_get_scale() (in module modelopt.torch.export.scaling_factor_utils)": [[43, "modelopt.torch.export.scaling_factor_utils.resmooth_and_get_scale"]], "convert_to_tensorrt_llm_config() (in module modelopt.torch.export.tensorrt_llm_utils)": [[44, "modelopt.torch.export.tensorrt_llm_utils.convert_to_tensorrt_llm_config"]], "is_tensorrt_llm_0_8_or_9() (in module modelopt.torch.export.tensorrt_llm_utils)": [[44, "modelopt.torch.export.tensorrt_llm_utils.is_tensorrt_llm_0_8_or_9"]], "modelopt.torch.export.tensorrt_llm_utils": [[44, "module-modelopt.torch.export.tensorrt_llm_utils"]], "weights_to_npz() (in module modelopt.torch.export.tensorrt_llm_utils)": [[44, "modelopt.torch.export.tensorrt_llm_utils.weights_to_npz"]], "convert_to_transformer_engine() (in module modelopt.torch.export.transformer_engine)": [[45, "modelopt.torch.export.transformer_engine.convert_to_transformer_engine"]], "modelopt.torch.export.transformer_engine": [[45, "module-modelopt.torch.export.transformer_engine"]], "modelopt.torch.opt": [[46, "module-modelopt.torch.opt"]], "modeloptfield() (in module modelopt.torch.opt.config)": [[47, "modelopt.torch.opt.config.ModeloptField"]], "customize_rule() (modeloptbaserule class method)": [[47, "modelopt.torch.opt.config.ModeloptBaseRule.customize_rule"]], "get() (modeloptbaseconfig method)": [[47, "modelopt.torch.opt.config.ModeloptBaseConfig.get"]], "get_field_name_from_key() (modeloptbaseconfig method)": [[47, "modelopt.torch.opt.config.ModeloptBaseConfig.get_field_name_from_key"]], "get_kwargs_for_create_model_with_rules() (in module modelopt.torch.opt.config)": [[47, "modelopt.torch.opt.config.get_kwargs_for_create_model_with_rules"]], "get_rule_type() (modeloptbaserule class method)": [[47, "modelopt.torch.opt.config.ModeloptBaseRule.get_rule_type"]], "items() (modeloptbaseconfig method)": [[47, "modelopt.torch.opt.config.ModeloptBaseConfig.items"]], "keys() (modeloptbaseconfig method)": [[47, "modelopt.torch.opt.config.ModeloptBaseConfig.keys"]], "model_dump() (modeloptbaseconfig method)": [[47, "modelopt.torch.opt.config.ModeloptBaseConfig.model_dump"]], "model_dump_json() (modeloptbaseconfig method)": [[47, "modelopt.torch.opt.config.ModeloptBaseConfig.model_dump_json"]], "modelopt.torch.opt.config": [[47, "module-modelopt.torch.opt.config"]], "register_default() (modeloptbaseruleconfig class method)": [[47, "modelopt.torch.opt.config.ModeloptBaseRuleConfig.register_default"]], "unregister_default() (modeloptbaseruleconfig class method)": [[47, "modelopt.torch.opt.config.ModeloptBaseRuleConfig.unregister_default"]], "update() (modeloptbaseconfig method)": [[47, "modelopt.torch.opt.config.ModeloptBaseConfig.update"]], "validate_rule() (modeloptbaserule class method)": [[47, "modelopt.torch.opt.config.ModeloptBaseRule.validate_rule"]], "values() (modeloptbaseconfig method)": [[47, "modelopt.torch.opt.config.ModeloptBaseConfig.values"]], "modeloptstatemanager (class in modelopt.torch.opt.conversion)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager"]], "__init__() (modeloptstatemanager method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.__init__"]], "add_mode() (modeloptstatemanager method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.add_mode"]], "apply_mode() (in module modelopt.torch.opt.conversion)": [[48, "modelopt.torch.opt.conversion.apply_mode"]], "check_mode() (modeloptstatemanager method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.check_mode"]], "get_config_class() (modeloptstatemanager static method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.get_config_class"]], "has_state (modeloptstatemanager property)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.has_state"]], "is_converted() (modeloptstatemanager class method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.is_converted"]], "last_mode (modeloptstatemanager property)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.last_mode"]], "load_state_dict() (modeloptstatemanager method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.load_state_dict"]], "modelopt.torch.opt.conversion": [[48, "module-modelopt.torch.opt.conversion"]], "modelopt_state() (in module modelopt.torch.opt.conversion)": [[48, "modelopt.torch.opt.conversion.modelopt_state"]], "modes_with_states() (modeloptstatemanager method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.modes_with_states"]], "restore() (in module modelopt.torch.opt.conversion)": [[48, "modelopt.torch.opt.conversion.restore"]], "restore_from_modelopt_state() (in module modelopt.torch.opt.conversion)": [[48, "modelopt.torch.opt.conversion.restore_from_modelopt_state"]], "save() (in module modelopt.torch.opt.conversion)": [[48, "modelopt.torch.opt.conversion.save"]], "state_dict() (modeloptstatemanager method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.state_dict"]], "transfer_state_dict() (modeloptstatemanager class method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.transfer_state_dict"]], "update_last_state_before_new_mode() (modeloptstatemanager method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.update_last_state_before_new_mode"]], "update_last_state_before_save() (modeloptstatemanager method)": [[48, "modelopt.torch.opt.conversion.ModeloptStateManager.update_last_state_before_save"]], "dynamicmodule (class in modelopt.torch.opt.dynamic)": [[49, "modelopt.torch.opt.dynamic.DynamicModule"]], "dynamicspace (class in modelopt.torch.opt.dynamic)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace"]], "__init__() (dynamicmodule method)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.__init__"]], "__init__() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.__init__"]], "config() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.config"]], "convert() (dynamicmodule class method)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.convert"]], "convert_to_dynamic() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.convert_to_dynamic"]], "export() (dynamicmodule method)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.export"]], "export() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.export"]], "extra_repr() (dynamicmodule method)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.extra_repr"]], "force_assign() (dynamicmodule method)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.force_assign"]], "freeze() (dynamicmodule method)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.freeze"]], "get_hparam() (dynamicmodule method)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.get_hparam"]], "get_hparam() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.get_hparam"]], "is_configurable() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.is_configurable"]], "is_dynamic() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.is_dynamic"]], "modelopt.torch.opt.dynamic": [[49, "module-modelopt.torch.opt.dynamic"]], "modify() (dynamicmodule method)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.modify"]], "named_dynamic_modules() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.named_dynamic_modules"]], "named_hparams() (dynamicmodule method)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.named_hparams"]], "named_hparams() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.named_hparams"]], "original_cls (dynamicmodule property)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.original_cls"]], "reset_dynamic_attributes() (dynamicmodule method)": [[49, "modelopt.torch.opt.dynamic.DynamicModule.reset_dynamic_attributes"]], "select() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.select"]], "size() (dynamicspace method)": [[49, "modelopt.torch.opt.dynamic.DynamicSpace.size"]], "activeslice (hparam attribute)": [[50, "modelopt.torch.opt.hparam.Hparam.ActiveSlice"]], "hparam (class in modelopt.torch.opt.hparam)": [[50, "modelopt.torch.opt.hparam.Hparam"]], "importance (hparam attribute)": [[50, "modelopt.torch.opt.hparam.Hparam.Importance"]], "importanceestimator (hparam attribute)": [[50, "modelopt.torch.opt.hparam.Hparam.ImportanceEstimator"]], "__init__() (hparam method)": [[50, "modelopt.torch.opt.hparam.Hparam.__init__"]], "active (hparam property)": [[50, "modelopt.torch.opt.hparam.Hparam.active"]], "active_slice (hparam property)": [[50, "modelopt.torch.opt.hparam.Hparam.active_slice"]], "choices (hparam property)": [[50, "modelopt.torch.opt.hparam.Hparam.choices"]], "enforce_order() (hparam method)": [[50, "modelopt.torch.opt.hparam.Hparam.enforce_order"]], "importance (hparam property)": [[50, "modelopt.torch.opt.hparam.Hparam.importance"]], "is_configurable (hparam property)": [[50, "modelopt.torch.opt.hparam.Hparam.is_configurable"]], "is_sortable (hparam property)": [[50, "modelopt.torch.opt.hparam.Hparam.is_sortable"]], "max (hparam property)": [[50, "modelopt.torch.opt.hparam.Hparam.max"]], "min (hparam property)": [[50, "modelopt.torch.opt.hparam.Hparam.min"]], "modelopt.torch.opt.hparam": [[50, "module-modelopt.torch.opt.hparam"]], "original (hparam property)": [[50, "modelopt.torch.opt.hparam.Hparam.original"]], "register_importance() (hparam method)": [[50, "modelopt.torch.opt.hparam.Hparam.register_importance"]], "modelopt.torch.opt.mode": [[51, "module-modelopt.torch.opt.mode"]], "modelopt.torch.opt.plugins": [[52, "module-modelopt.torch.opt.plugins"]], "basesearcher (class in modelopt.torch.opt.searcher)": [[53, "modelopt.torch.opt.searcher.BaseSearcher"]], "__init__() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.__init__"]], "after_search() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.after_search"]], "before_search() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.before_search"]], "config (basesearcher attribute)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.config"]], "constraints (basesearcher attribute)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.constraints"]], "construct_forward_loop() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.construct_forward_loop"]], "default_search_config (basesearcher property)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.default_search_config"]], "default_state_dict (basesearcher property)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.default_state_dict"]], "dummy_input (basesearcher attribute)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.dummy_input"]], "eval_score() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.eval_score"]], "forward_loop (basesearcher attribute)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.forward_loop"]], "has_score (basesearcher property)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.has_score"]], "load_search_checkpoint() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.load_search_checkpoint"]], "model (basesearcher attribute)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.model"]], "modelopt.torch.opt.searcher": [[53, "module-modelopt.torch.opt.searcher"]], "reset_search() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.reset_search"]], "run_search() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.run_search"]], "sanitize_search_config() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.sanitize_search_config"]], "save_search_checkpoint() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.save_search_checkpoint"]], "search() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.search"]], "state_dict() (basesearcher method)": [[53, "modelopt.torch.opt.searcher.BaseSearcher.state_dict"]], "is_configurable() (in module modelopt.torch.opt.utils)": [[54, "modelopt.torch.opt.utils.is_configurable"]], "is_dynamic() (in module modelopt.torch.opt.utils)": [[54, "modelopt.torch.opt.utils.is_dynamic"]], "modelopt.torch.opt.utils": [[54, "module-modelopt.torch.opt.utils"]], "named_hparams() (in module modelopt.torch.opt.utils)": [[54, "modelopt.torch.opt.utils.named_hparams"]], "search_space_size() (in module modelopt.torch.opt.utils)": [[54, "modelopt.torch.opt.utils.search_space_size"]], "modelopt.torch.quantization": [[55, "module-modelopt.torch.quantization"]], "modelopt.torch.quantization.calib": [[56, "module-modelopt.torch.quantization.calib"]], "modelopt.torch.quantization.calib.calibrator": [[57, "module-modelopt.torch.quantization.calib.calibrator"]], "histogramcalibrator (class in modelopt.torch.quantization.calib.histogram)": [[58, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator"]], "__init__() (histogramcalibrator method)": [[58, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.__init__"]], "calibrate_weights() (in module modelopt.torch.quantization.calib.histogram)": [[58, "modelopt.torch.quantization.calib.histogram.calibrate_weights"]], "collect() (histogramcalibrator method)": [[58, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.collect"]], "compute_amax() (histogramcalibrator method)": [[58, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.compute_amax"]], "modelopt.torch.quantization.calib.histogram": [[58, "module-modelopt.torch.quantization.calib.histogram"]], "reset() (histogramcalibrator method)": [[58, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.reset"]], "maxcalibrator (class in modelopt.torch.quantization.calib.max)": [[59, "modelopt.torch.quantization.calib.max.MaxCalibrator"]], "__init__() (maxcalibrator method)": [[59, "modelopt.torch.quantization.calib.max.MaxCalibrator.__init__"]], "amaxs (maxcalibrator property)": [[59, "modelopt.torch.quantization.calib.max.MaxCalibrator.amaxs"]], "collect() (maxcalibrator method)": [[59, "modelopt.torch.quantization.calib.max.MaxCalibrator.collect"]], "compute_amax() (maxcalibrator method)": [[59, "modelopt.torch.quantization.calib.max.MaxCalibrator.compute_amax"]], "modelopt.torch.quantization.calib.max": [[59, "module-modelopt.torch.quantization.calib.max"]], "reset() (maxcalibrator method)": [[59, "modelopt.torch.quantization.calib.max.MaxCalibrator.reset"]], "algorithm (quantizeconfig attribute)": [[60, "modelopt.torch.quantization.config.QuantizeConfig.algorithm"]], "modelopt.torch.quantization.config": [[60, "module-modelopt.torch.quantization.config"]], "quant_cfg (quantizeconfig attribute)": [[60, "modelopt.torch.quantization.config.QuantizeConfig.quant_cfg"]], "modelopt.torch.quantization.conversion": [[61, "module-modelopt.torch.quantization.conversion"]], "register() (in module modelopt.torch.quantization.conversion)": [[61, "modelopt.torch.quantization.conversion.register"]], "replace_quant_module() (in module modelopt.torch.quantization.conversion)": [[61, "modelopt.torch.quantization.conversion.replace_quant_module"]], "set_quantizer_attribute() (in module modelopt.torch.quantization.conversion)": [[61, "modelopt.torch.quantization.conversion.set_quantizer_attribute"]], "set_quantizer_by_cfg() (in module modelopt.torch.quantization.conversion)": [[61, "modelopt.torch.quantization.conversion.set_quantizer_by_cfg"]], "unregister() (in module modelopt.torch.quantization.conversion)": [[61, "modelopt.torch.quantization.conversion.unregister"]], "modelopt.torch.quantization.extensions": [[62, "module-modelopt.torch.quantization.extensions"]], "quantizeexportmodedescriptor (class in modelopt.torch.quantization.mode)": [[63, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor"]], "quantizemodedescriptor (class in modelopt.torch.quantization.mode)": [[63, "modelopt.torch.quantization.mode.QuantizeModeDescriptor"]], "config_class (quantizeexportmodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.config_class"]], "config_class (quantizemodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.config_class"]], "convert (quantizeexportmodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.convert"]], "convert (quantizemodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.convert"]], "export_mode (quantizemodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.export_mode"]], "is_export_mode (quantizeexportmodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.is_export_mode"]], "modelopt.torch.quantization.mode": [[63, "module-modelopt.torch.quantization.mode"]], "name (quantizeexportmodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.name"]], "name (quantizemodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.name"]], "next_modes (quantizemodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.next_modes"]], "restore (quantizeexportmodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.restore"]], "restore (quantizemodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.restore"]], "update_for_new_mode (quantizemodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.update_for_new_mode"]], "update_for_save (quantizemodedescriptor property)": [[63, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.update_for_save"]], "calibrate() (in module modelopt.torch.quantization.model_calib)": [[64, "modelopt.torch.quantization.model_calib.calibrate"]], "modelopt.torch.quantization.model_calib": [[64, "module-modelopt.torch.quantization.model_calib"]], "postprocess_amax() (in module modelopt.torch.quantization.model_calib)": [[64, "modelopt.torch.quantization.model_calib.postprocess_amax"]], "disable_quantizer() (in module modelopt.torch.quantization.model_quant)": [[65, "modelopt.torch.quantization.model_quant.disable_quantizer"]], "enable_quantizer() (in module modelopt.torch.quantization.model_quant)": [[65, "modelopt.torch.quantization.model_quant.enable_quantizer"]], "fold_weight() (in module modelopt.torch.quantization.model_quant)": [[65, "modelopt.torch.quantization.model_quant.fold_weight"]], "modelopt.torch.quantization.model_quant": [[65, "module-modelopt.torch.quantization.model_quant"]], "print_quant_summary() (in module modelopt.torch.quantization.model_quant)": [[65, "modelopt.torch.quantization.model_quant.print_quant_summary"]], "quantize() (in module modelopt.torch.quantization.model_quant)": [[65, "modelopt.torch.quantization.model_quant.quantize"]], "modelopt.torch.quantization.nn": [[66, "module-modelopt.torch.quantization.nn"]], "clipfunction (class in modelopt.torch.quantization.nn.functional)": [[67, "modelopt.torch.quantization.nn.functional.ClipFunction"]], "backward() (clipfunction static method)": [[67, "modelopt.torch.quantization.nn.functional.ClipFunction.backward"]], "forward() (clipfunction static method)": [[67, "modelopt.torch.quantization.nn.functional.ClipFunction.forward"]], "modelopt.torch.quantization.nn.functional": [[67, "module-modelopt.torch.quantization.nn.functional"]], "modelopt.torch.quantization.nn.modules": [[68, "module-modelopt.torch.quantization.nn.modules"]], "clip (class in modelopt.torch.quantization.nn.modules.clip)": [[69, "modelopt.torch.quantization.nn.modules.clip.Clip"]], "__init__() (clip method)": [[69, "modelopt.torch.quantization.nn.modules.clip.Clip.__init__"]], "forward() (clip method)": [[69, "modelopt.torch.quantization.nn.modules.clip.Clip.forward"]], "modelopt.torch.quantization.nn.modules.clip": [[69, "module-modelopt.torch.quantization.nn.modules.clip"]], "modelopt.torch.quantization.nn.modules.quant_activations": [[70, "module-modelopt.torch.quantization.nn.modules.quant_activations"]], "modelopt.torch.quantization.nn.modules.quant_batchnorm": [[71, "module-modelopt.torch.quantization.nn.modules.quant_batchnorm"]], "conv1d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.Conv1d"]], "conv2d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.Conv2d"]], "conv3d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.Conv3d"]], "convtranspose1d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose1d"]], "convtranspose2d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose2d"]], "convtranspose3d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose3d"]], "quantconv1d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d"]], "quantconv2d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d"]], "quantconv3d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d"]], "quantconvtranspose1d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d"]], "quantconvtranspose2d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d"]], "quantconvtranspose3d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d"]], "default_quant_desc_weight (quantconv1d attribute)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconv2d attribute)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconv3d attribute)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose1d attribute)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose2d attribute)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose3d attribute)": [[72, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d.default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv": [[72, "module-modelopt.torch.quantization.nn.modules.quant_conv"]], "quantinstancenorm1d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[73, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm1d"]], "quantinstancenorm2d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[73, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm2d"]], "quantinstancenorm3d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[73, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm3d"]], "modelopt.torch.quantization.nn.modules.quant_instancenorm": [[73, "module-modelopt.torch.quantization.nn.modules.quant_instancenorm"]], "linear (in module modelopt.torch.quantization.nn.modules.quant_linear)": [[74, "modelopt.torch.quantization.nn.modules.quant_linear.Linear"]], "quantlinear (class in modelopt.torch.quantization.nn.modules.quant_linear)": [[74, "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear"]], "default_quant_desc_weight (quantlinear attribute)": [[74, "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear.default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_linear": [[74, "module-modelopt.torch.quantization.nn.modules.quant_linear"]], "quantinputbase (class in modelopt.torch.quantization.nn.modules.quant_module)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase"]], "quantlinearconvbase (class in modelopt.torch.quantization.nn.modules.quant_module)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase"]], "default_quant_desc_input (quantinputbase attribute)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.default_quant_desc_input"]], "default_quant_desc_output (quantinputbase attribute)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.default_quant_desc_output"]], "default_quant_desc_weight (quantlinearconvbase attribute)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.default_quant_desc_weight"]], "forward() (quantinputbase method)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.forward"]], "forward() (quantlinearconvbase method)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.forward"]], "initialize_quantizer_with_dummy_states() (quantlinearconvbase static method)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.initialize_quantizer_with_dummy_states"]], "input_quantizer (quantinputbase attribute)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.input_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_module": [[75, "module-modelopt.torch.quantization.nn.modules.quant_module"]], "output_quantizer (quantinputbase attribute)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.output_quantizer"]], "quantize_weight() (quantlinearconvbase method)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.quantize_weight"]], "weight_quantizer (quantlinearconvbase attribute)": [[75, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.weight_quantizer"]], "adaptiveavgpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool1d"]], "adaptiveavgpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool2d"]], "adaptiveavgpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool3d"]], "avgpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool1d"]], "avgpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool2d"]], "avgpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool3d"]], "maxpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool1d"]], "maxpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool2d"]], "maxpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool3d"]], "quantadaptiveavgpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool1d"]], "quantadaptiveavgpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool2d"]], "quantadaptiveavgpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool3d"]], "quantavgpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool1d"]], "quantavgpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool2d"]], "quantavgpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool3d"]], "quantmaxpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool1d"]], "quantmaxpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool2d"]], "quantmaxpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[76, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool3d"]], "modelopt.torch.quantization.nn.modules.quant_pooling": [[76, "module-modelopt.torch.quantization.nn.modules.quant_pooling"]], "sequentialquantizer (class in modelopt.torch.quantization.nn.modules.tensor_quantizer)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer"]], "tensorquantizer (class in modelopt.torch.quantization.nn.modules.tensor_quantizer)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer"]], "__init__() (sequentialquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.__init__"]], "__init__() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.__init__"]], "amax (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.amax"]], "axis (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.axis"]], "block_sizes (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.block_sizes"]], "clean_up_after_set_from_modelopt_state() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.clean_up_after_set_from_modelopt_state"]], "disable() (sequentialquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.disable"]], "disable() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable"]], "disable_calib() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_calib"]], "disable_clip() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_clip"]], "disable_quant() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_quant"]], "enable() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable"]], "enable_calib() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_calib"]], "enable_clip() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_clip"]], "enable_quant() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_quant"]], "export_amax() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.export_amax"]], "extra_repr() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.extra_repr"]], "fake_quant (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.fake_quant"]], "forward() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.forward"]], "get_modelopt_state() (sequentialquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.get_modelopt_state"]], "get_modelopt_state() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.get_modelopt_state"]], "init_learn_amax() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.init_learn_amax"]], "is_enabled (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.is_enabled"]], "load_calib_amax() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.load_calib_amax"]], "maxbound (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.maxbound"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer": [[77, "module-modelopt.torch.quantization.nn.modules.tensor_quantizer"]], "narrow_range (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.narrow_range"]], "num_bits (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.num_bits"]], "pre_quant_scale (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.pre_quant_scale"]], "replace_sequential_quantizer_with_single_quantizer() (sequentialquantizer static method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.replace_sequential_quantizer_with_single_quantizer"]], "reset_amax() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.reset_amax"]], "scale (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.scale"]], "set_from_attribute_dict() (sequentialquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.set_from_attribute_dict"]], "set_from_attribute_dict() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.set_from_attribute_dict"]], "set_from_modelopt_state() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.set_from_modelopt_state"]], "step_size (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.step_size"]], "sync_amax_across_distributed_group() (tensorquantizer method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.sync_amax_across_distributed_group"]], "tensor_quantizer_iterator() (sequentialquantizer static method)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.tensor_quantizer_iterator"]], "unsigned (tensorquantizer property)": [[77, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.unsigned"]], "freeze_parameters() (in module modelopt.torch.quantization.optim)": [[78, "modelopt.torch.quantization.optim.freeze_parameters"]], "group_parameters() (in module modelopt.torch.quantization.optim)": [[78, "modelopt.torch.quantization.optim.group_parameters"]], "match_parameters() (in module modelopt.torch.quantization.optim)": [[78, "modelopt.torch.quantization.optim.match_parameters"]], "modelopt.torch.quantization.optim": [[78, "module-modelopt.torch.quantization.optim"]], "quant_weight_inplace() (in module modelopt.torch.quantization.optim)": [[78, "modelopt.torch.quantization.optim.quant_weight_inplace"]], "modelopt.torch.quantization.plugins": [[79, "module-modelopt.torch.quantization.plugins"]], "deactivate() (in module modelopt.torch.quantization.quant_modules)": [[80, "modelopt.torch.quantization.quant_modules.deactivate"]], "enable_onnx_export() (in module modelopt.torch.quantization.quant_modules)": [[80, "modelopt.torch.quantization.quant_modules.enable_onnx_export"]], "initialize() (in module modelopt.torch.quantization.quant_modules)": [[80, "modelopt.torch.quantization.quant_modules.initialize"]], "modelopt.torch.quantization.quant_modules": [[80, "module-modelopt.torch.quantization.quant_modules"]], "fakeaffinetensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[81, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction"]], "faketensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[81, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction"]], "legacyfaketensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[81, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction"]], "quantdescriptor (in module modelopt.torch.quantization.tensor_quant)": [[81, "modelopt.torch.quantization.tensor_quant.QuantDescriptor"]], "scalede4m3function (class in modelopt.torch.quantization.tensor_quant)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function"]], "scaledquantdescriptor (class in modelopt.torch.quantization.tensor_quant)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor"]], "tensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[81, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction"]], "__init__() (scaledquantdescriptor method)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.__init__"]], "amax (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.amax"]], "axis (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.axis"]], "backward() (fakeaffinetensorquantfunction static method)": [[81, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction.backward"]], "backward() (faketensorquantfunction static method)": [[81, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.backward"]], "backward() (legacyfaketensorquantfunction static method)": [[81, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction.backward"]], "backward() (scalede4m3function static method)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.backward"]], "backward() (tensorquantfunction static method)": [[81, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.backward"]], "block_sizes (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.block_sizes"]], "calib_method (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.calib_method"]], "dict() (scaledquantdescriptor method)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.dict"]], "fake_quant (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.fake_quant"]], "forward() (fakeaffinetensorquantfunction static method)": [[81, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction.forward"]], "forward() (faketensorquantfunction static method)": [[81, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.forward"]], "forward() (legacyfaketensorquantfunction static method)": [[81, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction.forward"]], "forward() (scalede4m3function static method)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.forward"]], "forward() (tensorquantfunction static method)": [[81, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.forward"]], "get_block_quant_axes_and_sizes() (scaledquantdescriptor static method)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.get_block_quant_axes_and_sizes"]], "learn_amax (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.learn_amax"]], "modelopt.torch.quantization.tensor_quant": [[81, "module-modelopt.torch.quantization.tensor_quant"]], "name (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.name"]], "narrow_range (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.narrow_range"]], "num_bits (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.num_bits"]], "scale_amax (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.scale_amax"]], "scaled_e4m3_abstract() (in module modelopt.torch.quantization.tensor_quant)": [[81, "modelopt.torch.quantization.tensor_quant.scaled_e4m3_abstract"]], "symbolic() (faketensorquantfunction static method)": [[81, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.symbolic"]], "symbolic() (scalede4m3function static method)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.symbolic"]], "symbolic() (tensorquantfunction static method)": [[81, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.symbolic"]], "unsigned (scaledquantdescriptor property)": [[81, "modelopt.torch.quantization.tensor_quant.ScaledQuantDescriptor.unsigned"]], "export_torch_mode() (in module modelopt.torch.quantization.utils)": [[82, "modelopt.torch.quantization.utils.export_torch_mode"]], "is_quantized() (in module modelopt.torch.quantization.utils)": [[82, "modelopt.torch.quantization.utils.is_quantized"]], "is_quantized_column_parallel_linear() (in module modelopt.torch.quantization.utils)": [[82, "modelopt.torch.quantization.utils.is_quantized_column_parallel_linear"]], "is_quantized_layer_with_weight() (in module modelopt.torch.quantization.utils)": [[82, "modelopt.torch.quantization.utils.is_quantized_layer_with_weight"]], "is_quantized_row_parallel_linear() (in module modelopt.torch.quantization.utils)": [[82, "modelopt.torch.quantization.utils.is_quantized_row_parallel_linear"]], "is_torch_library_supported() (in module modelopt.torch.quantization.utils)": [[82, "modelopt.torch.quantization.utils.is_torch_library_supported"]], "modelopt.torch.quantization.utils": [[82, "module-modelopt.torch.quantization.utils"]], "reduce_amax() (in module modelopt.torch.quantization.utils)": [[82, "modelopt.torch.quantization.utils.reduce_amax"]], "replace_function() (in module modelopt.torch.quantization.utils)": [[82, "modelopt.torch.quantization.utils.replace_function"]], "modelopt.torch.sparsity": [[83, "module-modelopt.torch.sparsity"]], "modelopt.torch.sparsity.config": [[84, "module-modelopt.torch.sparsity.config"]], "nn_conv2d (sparsegptconfig attribute)": [[84, "modelopt.torch.sparsity.config.SparseGPTConfig.nn_conv2d"]], "nn_conv2d (sparsemagnitudeconfig attribute)": [[84, "modelopt.torch.sparsity.config.SparseMagnitudeConfig.nn_conv2d"]], "nn_linear (sparsegptconfig attribute)": [[84, "modelopt.torch.sparsity.config.SparseGPTConfig.nn_linear"]], "nn_linear (sparsemagnitudeconfig attribute)": [[84, "modelopt.torch.sparsity.config.SparseMagnitudeConfig.nn_linear"]], "magnitudesearcher (class in modelopt.torch.sparsity.magnitude)": [[85, "modelopt.torch.sparsity.magnitude.MagnitudeSearcher"]], "compute_valid_1d_patterns() (in module modelopt.torch.sparsity.magnitude)": [[85, "modelopt.torch.sparsity.magnitude.compute_valid_1d_patterns"]], "create_asp_mask() (in module modelopt.torch.sparsity.magnitude)": [[85, "modelopt.torch.sparsity.magnitude.create_asp_mask"]], "fill() (in module modelopt.torch.sparsity.magnitude)": [[85, "modelopt.torch.sparsity.magnitude.fill"]], "get_nmprune_info() (in module modelopt.torch.sparsity.magnitude)": [[85, "modelopt.torch.sparsity.magnitude.get_nmprune_info"]], "m4n2_1d() (in module modelopt.torch.sparsity.magnitude)": [[85, "modelopt.torch.sparsity.magnitude.m4n2_1d"]], "mn_1d_best() (in module modelopt.torch.sparsity.magnitude)": [[85, "modelopt.torch.sparsity.magnitude.mn_1d_best"]], "modelopt.torch.sparsity.magnitude": [[85, "module-modelopt.torch.sparsity.magnitude"]], "reshape_1d() (in module modelopt.torch.sparsity.magnitude)": [[85, "modelopt.torch.sparsity.magnitude.reshape_1d"]], "exportsparsemodedescriptor (class in modelopt.torch.sparsity.mode)": [[86, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor"]], "sparsegptmodedescriptor (class in modelopt.torch.sparsity.mode)": [[86, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor"]], "sparsemagnitudemodedescriptor (class in modelopt.torch.sparsity.mode)": [[86, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor"]], "config_class (exportsparsemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.config_class"]], "config_class (sparsegptmodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.config_class"]], "config_class (sparsemagnitudemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.config_class"]], "convert (exportsparsemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.convert"]], "convert (sparsemagnitudemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.convert"]], "convert_sparse_model() (in module modelopt.torch.sparsity.mode)": [[86, "modelopt.torch.sparsity.mode.convert_sparse_model"]], "export_mode (sparsemagnitudemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.export_mode"]], "export_sparse() (in module modelopt.torch.sparsity.mode)": [[86, "modelopt.torch.sparsity.mode.export_sparse"]], "is_export_mode (exportsparsemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.is_export_mode"]], "modelopt.torch.sparsity.mode": [[86, "module-modelopt.torch.sparsity.mode"]], "name (exportsparsemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.name"]], "name (sparsegptmodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.name"]], "name (sparsemagnitudemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.name"]], "next_modes (sparsemagnitudemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.next_modes"]], "restore (exportsparsemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.restore"]], "restore (sparsemagnitudemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.restore"]], "restore_export_sparse() (in module modelopt.torch.sparsity.mode)": [[86, "modelopt.torch.sparsity.mode.restore_export_sparse"]], "restore_sparse_model() (in module modelopt.torch.sparsity.mode)": [[86, "modelopt.torch.sparsity.mode.restore_sparse_model"]], "search_algorithm (sparsegptmodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.search_algorithm"]], "search_algorithm (sparsemagnitudemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.search_algorithm"]], "update_for_new_mode (sparsemagnitudemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.update_for_new_mode"]], "update_for_save (sparsemagnitudemodedescriptor property)": [[86, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.update_for_save"]], "update_sparse_metadata() (in module modelopt.torch.sparsity.mode)": [[86, "modelopt.torch.sparsity.mode.update_sparse_metadata"]], "sparsemodule (class in modelopt.torch.sparsity.module)": [[87, "modelopt.torch.sparsity.module.SparseModule"]], "modelopt.torch.sparsity.module": [[87, "module-modelopt.torch.sparsity.module"]], "modify() (sparsemodule method)": [[87, "modelopt.torch.sparsity.module.SparseModule.modify"]], "set_mask() (sparsemodule method)": [[87, "modelopt.torch.sparsity.module.SparseModule.set_mask"]], "modelopt.torch.sparsity.plugins": [[88, "module-modelopt.torch.sparsity.plugins"]], "basesparsesearcher (class in modelopt.torch.sparsity.searcher)": [[89, "modelopt.torch.sparsity.searcher.BaseSparseSearcher"]], "default_search_config (basesparsesearcher property)": [[89, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.default_search_config"]], "default_state_dict (basesparsesearcher property)": [[89, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.default_state_dict"]], "modelopt.torch.sparsity.searcher": [[89, "module-modelopt.torch.sparsity.searcher"]], "run_search() (basesparsesearcher method)": [[89, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.run_search"]], "sanitize_search_config() (basesparsesearcher method)": [[89, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.sanitize_search_config"]], "sparsegptsearcher (class in modelopt.torch.sparsity.sparsegpt)": [[90, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher"]], "after_search() (sparsegptsearcher method)": [[90, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.after_search"]], "before_search() (sparsegptsearcher method)": [[90, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.before_search"]], "create_sgpt_mask() (in module modelopt.torch.sparsity.sparsegpt)": [[90, "modelopt.torch.sparsity.sparsegpt.create_sgpt_mask"]], "default_search_config (sparsegptsearcher property)": [[90, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.default_search_config"]], "invert() (in module modelopt.torch.sparsity.sparsegpt)": [[90, "modelopt.torch.sparsity.sparsegpt.invert"]], "modelopt.torch.sparsity.sparsegpt": [[90, "module-modelopt.torch.sparsity.sparsegpt"]], "prepare() (in module modelopt.torch.sparsity.sparsegpt)": [[90, "modelopt.torch.sparsity.sparsegpt.prepare"]], "export() (in module modelopt.torch.sparsity.sparsification)": [[91, "modelopt.torch.sparsity.sparsification.export"]], "modelopt.torch.sparsity.sparsification": [[91, "module-modelopt.torch.sparsity.sparsification"]], "sparsify() (in module modelopt.torch.sparsity.sparsification)": [[91, "modelopt.torch.sparsity.sparsification.sparsify"]], "modelopt.torch.utils": [[92, "module-modelopt.torch.utils"]], "load_cpp_extension() (in module modelopt.torch.utils.cpp_extension)": [[93, "modelopt.torch.utils.cpp_extension.load_cpp_extension"]], "modelopt.torch.utils.cpp_extension": [[93, "module-modelopt.torch.utils.cpp_extension"]], "create_forward_loop() (in module modelopt.torch.utils.dataset_utils)": [[94, "modelopt.torch.utils.dataset_utils.create_forward_loop"]], "get_dataset_dataloader() (in module modelopt.torch.utils.dataset_utils)": [[94, "modelopt.torch.utils.dataset_utils.get_dataset_dataloader"]], "modelopt.torch.utils.dataset_utils": [[94, "module-modelopt.torch.utils.dataset_utils"]], "backend() (in module modelopt.torch.utils.distributed)": [[95, "modelopt.torch.utils.distributed.backend"]], "barrier() (in module modelopt.torch.utils.distributed)": [[95, "modelopt.torch.utils.distributed.barrier"]], "get_data_parallel_group() (in module modelopt.torch.utils.distributed)": [[95, "modelopt.torch.utils.distributed.get_data_parallel_group"]], "get_tensor_parallel_group() (in module modelopt.torch.utils.distributed)": [[95, "modelopt.torch.utils.distributed.get_tensor_parallel_group"]], "is_master() (in module modelopt.torch.utils.distributed)": [[95, "modelopt.torch.utils.distributed.is_master"]], "modelopt.torch.utils.distributed": [[95, "module-modelopt.torch.utils.distributed"]], "rank() (in module modelopt.torch.utils.distributed)": [[95, "modelopt.torch.utils.distributed.rank"]], "set_data_parallel_group() (in module modelopt.torch.utils.distributed)": [[95, "modelopt.torch.utils.distributed.set_data_parallel_group"]], "set_tensor_parallel_group() (in module modelopt.torch.utils.distributed)": [[95, "modelopt.torch.utils.distributed.set_tensor_parallel_group"]], "size() (in module modelopt.torch.utils.distributed)": [[95, "modelopt.torch.utils.distributed.size"]], "match() (in module modelopt.torch.utils.graph)": [[96, "modelopt.torch.utils.graph.match"]], "modelopt.torch.utils.graph": [[96, "module-modelopt.torch.utils.graph"]], "list_closest_to_median() (in module modelopt.torch.utils.list)": [[97, "modelopt.torch.utils.list.list_closest_to_median"]], "modelopt.torch.utils.list": [[97, "module-modelopt.torch.utils.list"]], "stats() (in module modelopt.torch.utils.list)": [[97, "modelopt.torch.utils.list.stats"]], "val2list() (in module modelopt.torch.utils.list)": [[97, "modelopt.torch.utils.list.val2list"]], "val2tuple() (in module modelopt.torch.utils.list)": [[97, "modelopt.torch.utils.list.val2tuple"]], "deprecatederror": [[98, "modelopt.torch.utils.logging.DeprecatedError"]], "modelopt.torch.utils.logging": [[98, "module-modelopt.torch.utils.logging"]], "no_stdout() (in module modelopt.torch.utils.logging)": [[98, "modelopt.torch.utils.logging.no_stdout"]], "num2hrb() (in module modelopt.torch.utils.logging)": [[98, "modelopt.torch.utils.logging.num2hrb"]], "print_rank_0() (in module modelopt.torch.utils.logging)": [[98, "modelopt.torch.utils.logging.print_rank_0"]], "compare_dict() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.compare_dict"]], "get_model_attributes() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.get_model_attributes"]], "get_module_device() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.get_module_device"]], "get_same_padding() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.get_same_padding"]], "init_model_from_model_like() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.init_model_from_model_like"]], "is_channels_last() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.is_channels_last"]], "is_parallel() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.is_parallel"]], "make_divisible() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.make_divisible"]], "model_to() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.model_to"]], "modelopt.torch.utils.network": [[99, "module-modelopt.torch.utils.network"]], "param_num() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.param_num"]], "param_num_from_forward() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.param_num_from_forward"]], "remove_bn() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.remove_bn"]], "run_forward_loop() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.run_forward_loop"]], "set_submodule() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.set_submodule"]], "standardize_constructor_args() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.standardize_constructor_args"]], "standardize_model_args() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.standardize_model_args"]], "standardize_model_like_tuple() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.standardize_model_like_tuple"]], "standardize_named_model_args() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.standardize_named_model_args"]], "unwrap_model() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.unwrap_model"]], "zero_grad() (in module modelopt.torch.utils.network)": [[99, "modelopt.torch.utils.network.zero_grad"]], "timer (class in modelopt.torch.utils.perf)": [[100, "modelopt.torch.utils.perf.Timer"]], "__init__() (timer method)": [[100, "modelopt.torch.utils.perf.Timer.__init__"]], "clear_cuda_cache() (in module modelopt.torch.utils.perf)": [[100, "modelopt.torch.utils.perf.clear_cuda_cache"]], "get_cuda_memory_stats() (in module modelopt.torch.utils.perf)": [[100, "modelopt.torch.utils.perf.get_cuda_memory_stats"]], "modelopt.torch.utils.perf": [[100, "module-modelopt.torch.utils.perf"]], "report_memory() (in module modelopt.torch.utils.perf)": [[100, "modelopt.torch.utils.perf.report_memory"]], "start() (timer method)": [[100, "modelopt.torch.utils.perf.Timer.start"]], "stop() (timer method)": [[100, "modelopt.torch.utils.perf.Timer.stop"]], "centroid() (in module modelopt.torch.utils.random)": [[101, "modelopt.torch.utils.random.centroid"]], "choice() (in module modelopt.torch.utils.random)": [[101, "modelopt.torch.utils.random.choice"]], "modelopt.torch.utils.random": [[101, "module-modelopt.torch.utils.random"]], "original() (in module modelopt.torch.utils.random)": [[101, "modelopt.torch.utils.random.original"]], "random() (in module modelopt.torch.utils.random)": [[101, "modelopt.torch.utils.random.random"]], "sample() (in module modelopt.torch.utils.random)": [[101, "modelopt.torch.utils.random.sample"]], "shuffle() (in module modelopt.torch.utils.random)": [[101, "modelopt.torch.utils.random.shuffle"]], "modelopt.torch.utils.tensor": [[102, "module-modelopt.torch.utils.tensor"]], "numpy_to_torch() (in module modelopt.torch.utils.tensor)": [[102, "modelopt.torch.utils.tensor.numpy_to_torch"]], "torch_detach() (in module modelopt.torch.utils.tensor)": [[102, "modelopt.torch.utils.tensor.torch_detach"]], "torch_to() (in module modelopt.torch.utils.tensor)": [[102, "modelopt.torch.utils.tensor.torch_to"]], "torch_to_numpy() (in module modelopt.torch.utils.tensor)": [[102, "modelopt.torch.utils.tensor.torch_to_numpy"]]}})